{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e395f097",
   "metadata": {},
   "source": [
    "# PDAC Adaptive Modules — DepMap & Clinical Cohorts (Notebook)\n",
    "This notebook reproduces the final two **Results** analyses:\n",
    "\n",
    "1) **DepMap integration** — module scores vs. CRISPR **Chronos** gene dependencies and **PRISM** drug AUC.\n",
    "2) **Clinical validation** — module scores across patient cohorts (COMPASS, Puleo, TCGA-PAAD), subtype comparisons, and survival.\n",
    "\n",
    "> If you use this code, please acknowledge: *“Analysis notebook scaffold generated with assistance from ChatGPT.”*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "59f3c8c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/mh/r2nrb73509z0t_wjbx9r5fg00000gn/T/ipykernel_92012/2470016835.py:39: DtypeWarning: Columns (14,15) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  return pd.read_csv(path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PRISM (drugs x cell_lines): (1449, 33) -> out_modules_notebook/PRISM_AUC_PDAC_drugs_by_celllines.csv\n",
      "Expression: (51, 19099) from /Users/scottpowers/Library/CloudStorage/GoogleDrive-Scott.Powers@stonybrook.edu/My Drive/Imputed Folder/PDAC_celllines_expression.csv\n",
      "Dependencies: (45, 17917) from /Users/scottpowers/Library/CloudStorage/GoogleDrive-Scott.Powers@stonybrook.edu/My Drive/Imputed Folder/PDAC_gene_dependencies.csv\n",
      "COMPASS expr MISSING -> /path/to/clin/COMPASS_expr.csv\n",
      "COMPASS meta MISSING -> /path/to/clin/COMPASS_meta.csv\n",
      "Puleo expr MISSING -> /path/to/clin/Puleo_expr.csv\n",
      "Puleo meta MISSING -> /path/to/clin/Puleo_meta.csv\n",
      "TCGA expr MISSING -> /path/to/clin/TCGA_expr.csv\n",
      "TCGA meta MISSING -> /path/to/clin/TCGA_meta.csv\n",
      "\n",
      "Preview AUC (first 5 drugs × 5 lines):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>ccle_name</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>compound</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ccle_name</th>\n",
       "      <td>ASPC1_PANCREAS</td>\n",
       "      <td>BXPC3_PANCREAS</td>\n",
       "      <td>CAPAN2_PANCREAS</td>\n",
       "      <td>CFPAC1_PANCREAS</td>\n",
       "      <td>DANG_PANCREAS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1-azakenpaullone</th>\n",
       "      <td>1.422871</td>\n",
       "      <td>1.442328</td>\n",
       "      <td>1.1974</td>\n",
       "      <td>1.143525</td>\n",
       "      <td>0.847678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1-naphthyl-PP1</th>\n",
       "      <td>0.868061</td>\n",
       "      <td>1.004497</td>\n",
       "      <td>0.865685</td>\n",
       "      <td>0.861098</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1-phenylbiguanide</th>\n",
       "      <td>0.943366</td>\n",
       "      <td>1.345432</td>\n",
       "      <td>0.884344</td>\n",
       "      <td>0.954388</td>\n",
       "      <td>0.907823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10-deacetylbaccatin</th>\n",
       "      <td>0.887246</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.858276</td>\n",
       "      <td>0.889449</td>\n",
       "      <td>0.747788</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "ccle_name                         0               1                2  \\\n",
       "compound                                                               \n",
       "ccle_name            ASPC1_PANCREAS  BXPC3_PANCREAS  CAPAN2_PANCREAS   \n",
       "1-azakenpaullone           1.422871        1.442328           1.1974   \n",
       "1-naphthyl-PP1             0.868061        1.004497         0.865685   \n",
       "1-phenylbiguanide          0.943366        1.345432         0.884344   \n",
       "10-deacetylbaccatin        0.887246             NaN         0.858276   \n",
       "\n",
       "ccle_name                          3              4  \n",
       "compound                                             \n",
       "ccle_name            CFPAC1_PANCREAS  DANG_PANCREAS  \n",
       "1-azakenpaullone            1.143525       0.847678  \n",
       "1-naphthyl-PP1              0.861098            NaN  \n",
       "1-phenylbiguanide           0.954388       0.907823  \n",
       "10-deacetylbaccatin         0.889449       0.747788  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Preview annotations (first 10):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>moa</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>compound</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>cytarabine</th>\n",
       "      <td>POLA1, POLB, POLD1, POLE</td>\n",
       "      <td>ribonucleotide reductase inhibitor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>epinastine</th>\n",
       "      <td>ADRA1A, ADRA2A, HRH1, HRH2, HTR2A, HTR7</td>\n",
       "      <td>histamine receptor antagonist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>floxuridine</th>\n",
       "      <td>TYMS</td>\n",
       "      <td>DNA synthesis inhibitor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>valrubicin</th>\n",
       "      <td>TOP2A</td>\n",
       "      <td>DNA inhibitor, topoisomerase inhibitor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>adapalene</th>\n",
       "      <td>RARA, RARB, RARG, RXRA, RXRB, RXRG</td>\n",
       "      <td>retinoid receptor agonist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>colforsin-daproate</th>\n",
       "      <td>NaN</td>\n",
       "      <td>adenylyl cyclase activator</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sulfamethazine</th>\n",
       "      <td>NaN</td>\n",
       "      <td>PABA antagonist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>niridazole</th>\n",
       "      <td>NaN</td>\n",
       "      <td>phosphofructokinase inhibitor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>amprolium</th>\n",
       "      <td>NaN</td>\n",
       "      <td>thiamine uptake blocker</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>methylphenidate</th>\n",
       "      <td>SLC6A2, SLC6A3, SLC6A4</td>\n",
       "      <td>dopamine-norepinephrine reuptake inhibitor</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     target  \\\n",
       "compound                                                      \n",
       "cytarabine                         POLA1, POLB, POLD1, POLE   \n",
       "epinastine          ADRA1A, ADRA2A, HRH1, HRH2, HTR2A, HTR7   \n",
       "floxuridine                                            TYMS   \n",
       "valrubicin                                            TOP2A   \n",
       "adapalene                RARA, RARB, RARG, RXRA, RXRB, RXRG   \n",
       "colforsin-daproate                                      NaN   \n",
       "sulfamethazine                                          NaN   \n",
       "niridazole                                              NaN   \n",
       "amprolium                                               NaN   \n",
       "methylphenidate                      SLC6A2, SLC6A3, SLC6A4   \n",
       "\n",
       "                                                           moa  \n",
       "compound                                                        \n",
       "cytarabine                  ribonucleotide reductase inhibitor  \n",
       "epinastine                       histamine receptor antagonist  \n",
       "floxuridine                            DNA synthesis inhibitor  \n",
       "valrubicin              DNA inhibitor, topoisomerase inhibitor  \n",
       "adapalene                            retinoid receptor agonist  \n",
       "colforsin-daproate                  adenylyl cyclase activator  \n",
       "sulfamethazine                                 PABA antagonist  \n",
       "niridazole                       phosphofructokinase inhibitor  \n",
       "amprolium                              thiamine uptake blocker  \n",
       "methylphenidate     dopamine-norepinephrine reuptake inhibitor  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "# ---------------- paths ----------------\n",
    "# Your Google Drive base\n",
    "BASE = Path(\"/Users/scottpowers/Library/CloudStorage/GoogleDrive-Scott.Powers@stonybrook.edu/My Drive/Imputed Folder\")\n",
    "\n",
    "# DepMap (update these two if you’ve moved them)\n",
    "DEP_EXP   = BASE / \"PDAC_celllines_expression.csv\"      # genes x cell_lines\n",
    "DEP_CHRON = BASE / \"PDAC_gene_dependencies.csv\"         # genes x cell_lines\n",
    "\n",
    "# Use the outputs we just generated on Desktop\n",
    "PRISM_LONG   = Path(\"~/Desktop/PRISM_AUC_PDAC_long.csv\").expanduser()     # depmap_id, ccle_name, compound, auc\n",
    "PRISM_MATRIX = Path(\"~/Desktop/PRISM_AUC_PDAC_matrix.csv\").expanduser()   # rows=cell_lines, cols=compounds\n",
    "PRISM_PARAMS = Path(\"~/Desktop/secondary-screen-dose-response-curve-parameters.csv\").expanduser()  # for target/MOA\n",
    "\n",
    "# Clinical cohorts (leave as-is until you point them to real files)\n",
    "COMPASS_EXPR = Path(\"/path/to/clin/COMPASS_expr.csv\")\n",
    "COMPASS_META = Path(\"/path/to/clin/COMPASS_meta.csv\")\n",
    "\n",
    "PULEO_EXPR   = Path(\"/path/to/clin/Puleo_expr.csv\")\n",
    "PULEO_META   = Path(\"/path/to/clin/Puleo_meta.csv\")\n",
    "\n",
    "TCGA_EXPR    = Path(\"/path/to/clin/TCGA_expr.csv\")\n",
    "TCGA_META    = Path(\"/path/to/clin/TCGA_meta.csv\")\n",
    "\n",
    "# Output dir\n",
    "OUTDIR = Path(\"./out_modules_notebook\")\n",
    "OUTDIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# ---------------- helpers ----------------\n",
    "def read_any(path: Path) -> pd.DataFrame:\n",
    "    \"\"\"Smart CSV/TSV reader with header guess; returns DataFrame.\"\"\"\n",
    "    path = Path(path)\n",
    "    if not path.exists():\n",
    "        raise FileNotFoundError(f\"Missing file: {path}\")\n",
    "    try:\n",
    "        return pd.read_csv(path)\n",
    "    except Exception:\n",
    "        try:\n",
    "            return pd.read_csv(path, sep=\"\\t\")\n",
    "        except Exception:\n",
    "            return pd.read_csv(path, sep=None, engine=\"python\")\n",
    "\n",
    "# ---------------- load PRISM ----------------\n",
    "# Matrix we made is cell_lines x compounds; your code wants drugs x cell_lines\n",
    "A = read_any(PRISM_MATRIX)\n",
    "# Ensure the first column is the index if it got saved with an unnamed index\n",
    "if A.columns[0].lower() in {\"unnamed: 0\", \"\"}:\n",
    "    A = A.set_index(A.columns[0])\n",
    "\n",
    "# A: rows = cell_lines, cols = compounds\n",
    "# Convert to drugs x cell_lines\n",
    "DEP_PRISM = A.T.copy()\n",
    "DEP_PRISM.index.name = \"compound\"     # drugs\n",
    "DEP_PRISM.columns.name = \"ccle_name\"  # cell lines\n",
    "\n",
    "# Optional: build annotation from the params file (target/MOA)\n",
    "annot = None\n",
    "if PRISM_PARAMS.exists():\n",
    "    params = read_any(PRISM_PARAMS)\n",
    "    # normalize headers\n",
    "    params.columns = [str(c).strip().lower() for c in params.columns]\n",
    "    # In your file drug name is 'name'; align to 'compound'\n",
    "    cols_to_keep = [c for c in [\"name\", \"compound\", \"target\", \"moa\"] if c in params.columns]\n",
    "    if \"name\" in cols_to_keep and \"compound\" not in cols_to_keep:\n",
    "        params = params.rename(columns={\"name\": \"compound\"})\n",
    "    annot = params[[\"compound\"] + [c for c in [\"target\", \"moa\"] if c in params.columns]].drop_duplicates()\n",
    "    # Keep only drugs present in the matrix\n",
    "    annot = annot[annot[\"compound\"].isin(DEP_PRISM.index)].set_index(\"compound\")\n",
    "    annot.to_csv(OUTDIR / \"PRISM_drug_annotations.csv\")\n",
    "\n",
    "# Save the drug x cell_lines AUC matrix for downstream code expecting that orientation\n",
    "DEP_PRISM_PATH = OUTDIR / \"PRISM_AUC_PDAC_drugs_by_celllines.csv\"\n",
    "DEP_PRISM.to_csv(DEP_PRISM_PATH)\n",
    "\n",
    "print(\"PRISM (drugs x cell_lines):\", DEP_PRISM.shape, \"->\", DEP_PRISM_PATH)\n",
    "\n",
    "# ---------------- load expression/dependency (optional, if paths are real) ---\n",
    "def try_load(label, p: Path):\n",
    "    try:\n",
    "        df = read_any(p)\n",
    "        print(f\"{label}:\", df.shape, \"from\", p)\n",
    "        return df\n",
    "    except FileNotFoundError:\n",
    "        print(f\"{label}: MISSING -> {p}\")\n",
    "        return None\n",
    "\n",
    "EXP   = try_load(\"Expression\", DEP_EXP)\n",
    "CHRON = try_load(\"Dependencies\", DEP_CHRON)\n",
    "\n",
    "# ---------------- stubs for clinical cohorts ----------------\n",
    "for label, p in [\n",
    "    (\"COMPASS expr\", COMPASS_EXPR),\n",
    "    (\"COMPASS meta\", COMPASS_META),\n",
    "    (\"Puleo expr\",   PULEO_EXPR),\n",
    "    (\"Puleo meta\",   PULEO_META),\n",
    "    (\"TCGA expr\",    TCGA_EXPR),\n",
    "    (\"TCGA meta\",    TCGA_META),\n",
    "]:\n",
    "    if Path(p).exists():\n",
    "        print(label, \"OK:\", p)\n",
    "    else:\n",
    "        print(label, \"MISSING ->\", p)\n",
    "\n",
    "# ---------------- quick preview ----------------\n",
    "print(\"\\nPreview AUC (first 5 drugs × 5 lines):\")\n",
    "display(DEP_PRISM.iloc[:5, :5])\n",
    "\n",
    "if annot is not None:\n",
    "    print(\"\\nPreview annotations (first 10):\")\n",
    "    display(annot.head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29827f18",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "a8001242",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing: /Users/scottpowers/Desktop/GSE71729_series_matrix.txt.gz\n",
      "✅ Saved:\n",
      "  - /Users/scottpowers/Desktop/Puleo_expr.csv (shape: (19749, 357))\n",
      "  - /Users/scottpowers/Desktop/Puleo_meta.csv (shape: (357, 4))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>sample</th>\n",
       "      <th>GSM1843893</th>\n",
       "      <th>GSM1843894</th>\n",
       "      <th>GSM1843895</th>\n",
       "      <th>GSM1843896</th>\n",
       "      <th>GSM1843897</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID_REF</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>A1BG</th>\n",
       "      <td>1.685</td>\n",
       "      <td>1.540</td>\n",
       "      <td>1.541</td>\n",
       "      <td>1.641</td>\n",
       "      <td>1.744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A1CF</th>\n",
       "      <td>1.373</td>\n",
       "      <td>1.109</td>\n",
       "      <td>1.402</td>\n",
       "      <td>1.379</td>\n",
       "      <td>1.468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A2BP1</th>\n",
       "      <td>0.926</td>\n",
       "      <td>1.294</td>\n",
       "      <td>0.933</td>\n",
       "      <td>0.828</td>\n",
       "      <td>1.043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A2LD1</th>\n",
       "      <td>2.950</td>\n",
       "      <td>4.954</td>\n",
       "      <td>4.645</td>\n",
       "      <td>3.691</td>\n",
       "      <td>3.814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A2M</th>\n",
       "      <td>3.090</td>\n",
       "      <td>2.536</td>\n",
       "      <td>2.731</td>\n",
       "      <td>3.141</td>\n",
       "      <td>2.905</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "sample  GSM1843893  GSM1843894  GSM1843895  GSM1843896  GSM1843897\n",
       "ID_REF                                                            \n",
       "A1BG         1.685       1.540       1.541       1.641       1.744\n",
       "A1CF         1.373       1.109       1.402       1.379       1.468\n",
       "A2BP1        0.926       1.294       0.933       0.828       1.043\n",
       "A2LD1        2.950       4.954       4.645       3.691       3.814\n",
       "A2M          3.090       2.536       2.731       3.141       2.905"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>source_name_ch1</th>\n",
       "      <th>organism_ch1</th>\n",
       "      <th>geo_accession</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sample</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>GSM1843893</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GSM1843894</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GSM1843895</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GSM1843896</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GSM1843897</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           title source_name_ch1 organism_ch1 geo_accession\n",
       "sample                                                     \n",
       "GSM1843893                                                 \n",
       "GSM1843894                                                 \n",
       "GSM1843895                                                 \n",
       "GSM1843896                                                 \n",
       "GSM1843897                                                 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# --- GSE71729 Series Matrix → Puleo_expr.csv + Puleo_meta.csv (robust) ---\n",
    "import io, gzip, re, shutil, requests\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "DESKTOP = Path(\"~/Desktop\").expanduser()\n",
    "DESKTOP.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "MATRIX_URL = \"https://ftp.ncbi.nlm.nih.gov/geo/series/GSE71nnn/GSE71729/matrix/GSE71729_series_matrix.txt.gz\"\n",
    "matrix_gz_path = DESKTOP / \"GSE71729_series_matrix.txt.gz\"\n",
    "\n",
    "# ---------- Download with requests (uses certifi CA) ----------\n",
    "if not matrix_gz_path.exists():\n",
    "    print(\"Downloading:\", MATRIX_URL)\n",
    "    with requests.get(MATRIX_URL, stream=True, timeout=180) as r:\n",
    "        r.raise_for_status()\n",
    "        with open(matrix_gz_path, \"wb\") as f:\n",
    "            shutil.copyfileobj(r.raw, f)\n",
    "else:\n",
    "    print(\"Found existing:\", matrix_gz_path)\n",
    "\n",
    "# ---------- Read all lines ----------\n",
    "with gzip.open(matrix_gz_path, \"rt\", encoding=\"utf-8\", errors=\"ignore\") as fh:\n",
    "    lines = fh.readlines()\n",
    "\n",
    "# ---------- Helper: parse \"!Sample_<field> = ...\" arrays ----------\n",
    "def parse_field_to_list(s, field):\n",
    "    s = s.strip()\n",
    "    prefix = f\"!Sample_{field} = \"\n",
    "    if not s.startswith(prefix):\n",
    "        return None\n",
    "    val = s[len(prefix):].strip()\n",
    "    # Standard format is quoted list: \"v1\" \"v2\" \"v3\" ...\n",
    "    if val.startswith('\"') and val.endswith('\"'):\n",
    "        return re.findall(r'\"(.*?)\"', val)\n",
    "    # Fallback: split on tabs/semicolons/commas if unquoted\n",
    "    for sep in (\"\\t\", \";\", \",\"):\n",
    "        if sep in val:\n",
    "            return [x.strip().strip('\"') for x in val.split(sep)]\n",
    "    return [val]\n",
    "\n",
    "# ---------- Try to collect sample arrays from header lines ----------\n",
    "fields_wanted = [\"geo_accession\", \"title\", \"characteristics_ch1\", \"source_name_ch1\", \"organism_ch1\"]\n",
    "arrays = {}\n",
    "for line in lines:\n",
    "    if not line.startswith(\"!Sample_\"):\n",
    "        continue\n",
    "    for f in fields_wanted:\n",
    "        parts = parse_field_to_list(line, f)\n",
    "        if parts is not None:\n",
    "            arrays[f] = parts  # last one wins (GEO consolidates per field)\n",
    "\n",
    "# ---------- Extract the expression table block ----------\n",
    "try:\n",
    "    begin_idx = next(i for i, s in enumerate(lines) if s.startswith(\"!series_matrix_table_begin\"))\n",
    "    end_idx   = next(i for i, s in enumerate(lines) if s.startswith(\"!series_matrix_table_end\"))\n",
    "except StopIteration:\n",
    "    raise ValueError(\"Could not find matrix begin/end markers in the series matrix file.\")\n",
    "\n",
    "table_block = \"\".join(lines[begin_idx+1 : end_idx])\n",
    "expr_df = pd.read_csv(io.StringIO(table_block), sep=\"\\t\", dtype=str)\n",
    "gene_col = expr_df.columns[0]\n",
    "expr_df = expr_df.set_index(gene_col)\n",
    "expr_df = expr_df.apply(pd.to_numeric, errors=\"coerce\")\n",
    "\n",
    "# ---------- Clean gene index ----------\n",
    "idx = expr_df.index.astype(str)\n",
    "mask_junk = idx.str.startswith(\"?\") | (idx.str.strip() == \"\") | (idx.str.lower() == \"na\")\n",
    "expr_df = expr_df[~mask_junk]\n",
    "expr_df = expr_df[~expr_df.index.duplicated(keep=\"first\")]\n",
    "\n",
    "# ---------- Build rich metadata (handles multiple characteristics lines) ----------\n",
    "import re\n",
    "\n",
    "# 1) Get core sample arrays\n",
    "fields_wanted = [\"geo_accession\", \"title\", \"source_name_ch1\", \"organism_ch1\"]\n",
    "arrays = {}\n",
    "for line in lines:\n",
    "    if not line.startswith(\"!Sample_\"):\n",
    "        continue\n",
    "    for f in fields_wanted:\n",
    "        parts = parse_field_to_list(line, f)\n",
    "        if parts is not None:\n",
    "            arrays[f] = parts  # last one wins (ok: these are single-occurrence fields)\n",
    "\n",
    "# 2) Collect ALL characteristics lines (can be many; each with \"key: value\")\n",
    "char_arrays = []\n",
    "for line in lines:\n",
    "    if line.startswith(\"!Sample_characteristics_ch1\"):\n",
    "        parts = parse_field_to_list(line, \"characteristics_ch1\")\n",
    "        if parts is not None:\n",
    "            char_arrays.append(parts)\n",
    "\n",
    "# Figure out N samples (prefer geo_accession length; else expression column count)\n",
    "if \"geo_accession\" in arrays:\n",
    "    N = len(arrays[\"geo_accession\"])\n",
    "else:\n",
    "    N = expr_df.shape[1]\n",
    "\n",
    "def get_array(name, default=\"\"):\n",
    "    arr = arrays.get(name, [])\n",
    "    if len(arr) == N:\n",
    "        return arr\n",
    "    if len(arr) == 0:\n",
    "        return [default] * N\n",
    "    # pad/trim\n",
    "    return (arr + [default] * N)[:N]\n",
    "\n",
    "# 3) Parse key:value per sample across all characteristics lines\n",
    "def norm_key(k: str) -> str:\n",
    "    k = k.strip().strip(':').lower()\n",
    "    k = re.sub(r\"[^0-9a-zA-Z]+\", \"_\", k)\n",
    "    k = re.sub(r\"(^_+|_+$)\", \"\", k)\n",
    "    return k or \"characteristic\"\n",
    "\n",
    "meta_rows = []\n",
    "for i in range(N):\n",
    "    row = {\n",
    "        \"geo_accession\": get_array(\"geo_accession\", \"\")[i],\n",
    "        \"title\": get_array(\"title\", \"\")[i],\n",
    "        \"source_name_ch1\": get_array(\"source_name_ch1\", \"\")[i],\n",
    "        \"organism_ch1\": get_array(\"organism_ch1\", \"\")[i],\n",
    "    }\n",
    "    # accumulate characteristics\n",
    "    for arr in char_arrays:\n",
    "        if i >= len(arr):\n",
    "            continue\n",
    "        txt = (arr[i] or \"\").strip().strip('\"')\n",
    "        if not txt:\n",
    "            continue\n",
    "        if \":\" in txt:\n",
    "            key, val = txt.split(\":\", 1)\n",
    "            key = norm_key(key)\n",
    "            val = val.strip()\n",
    "        else:\n",
    "            # no explicit key -> put into a generic bucket (or append)\n",
    "            key = \"characteristic\"\n",
    "            val = txt\n",
    "        if key in row and row[key] and val:\n",
    "            row[key] = f\"{row[key]}; {val}\"\n",
    "        else:\n",
    "            row[key] = val\n",
    "    meta_rows.append(row)\n",
    "\n",
    "meta_df = pd.DataFrame(meta_rows)\n",
    "\n",
    "# 4) Index by geo_accession when available; otherwise by expression column headers\n",
    "if \"geo_accession\" in meta_df.columns and meta_df[\"geo_accession\"].notna().all() and (meta_df[\"geo_accession\"] != \"\").all():\n",
    "    meta_df = meta_df.set_index(\"geo_accession\")\n",
    "else:\n",
    "    meta_df.index = expr_df.columns\n",
    "    meta_df.index.name = \"sample\"\n",
    "\n",
    "# If expression columns are GSM IDs, reindex metadata to match their order\n",
    "if all(re.match(r\"^GSM\\d+$\", str(c)) for c in expr_df.columns):\n",
    "    meta_df = meta_df.reindex(expr_df.columns)\n",
    "\n",
    "# 5) (Optional) tidy column order: core fields first\n",
    "core = [\"title\", \"source_name_ch1\", \"organism_ch1\"]\n",
    "cols = [c for c in core if c in meta_df.columns] + [c for c in meta_df.columns if c not in core]\n",
    "meta_df = meta_df.loc[:, cols]\n",
    "\n",
    "# ---------- Save ----------\n",
    "expr_out = DESKTOP / \"Puleo_expr.csv\"\n",
    "meta_out = DESKTOP / \"Puleo_meta.csv\"\n",
    "expr_df.to_csv(expr_out)\n",
    "meta_df.to_csv(meta_out)\n",
    "\n",
    "print(\"✅ Saved:\")\n",
    "print(\"  -\", expr_out, f\"(shape: {expr_df.shape})\")\n",
    "print(\"  -\", meta_out, f\"(shape: {meta_df.shape})\")\n",
    "\n",
    "# ---------- Preview ----------\n",
    "display(expr_df.iloc[:5, :5])\n",
    "display(meta_df.head(5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "883c2a41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw shape: (20532, 184)\n",
      "First columns: ['Hybridization REF', 'TCGA-2J-AAB1-01A-11R-A41B-07', 'TCGA-2J-AAB4-01A-12R-A41B-07', 'TCGA-2J-AAB6-01A-11R-A41B-07', 'TCGA-2J-AAB8-01A-12R-A41B-07', 'TCGA-2J-AAB9-01A-11R-A41B-07', 'TCGA-2J-AABA-01A-21R-A41B-07', 'TCGA-2J-AABE-01A-12R-A41B-07', 'TCGA-2J-AABF-01A-31R-A41B-07', 'TCGA-2J-AABH-01A-21R-A41B-07']\n",
      "Processed shape: (20532, 183)\n",
      "Saved cleaned CSV to: /Users/scottpowers/Desktop/PAAD.rnaseqv2__illuminahiseq_rnaseqv2__unc_edu__Level_3__RSEM_genes_normalized__data.data.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TCGA-2J-AAB1-01A-11R-A41B-07</th>\n",
       "      <th>TCGA-2J-AAB4-01A-12R-A41B-07</th>\n",
       "      <th>TCGA-2J-AAB6-01A-11R-A41B-07</th>\n",
       "      <th>TCGA-2J-AAB8-01A-12R-A41B-07</th>\n",
       "      <th>TCGA-2J-AAB9-01A-11R-A41B-07</th>\n",
       "      <th>TCGA-2J-AABA-01A-21R-A41B-07</th>\n",
       "      <th>TCGA-2J-AABE-01A-12R-A41B-07</th>\n",
       "      <th>TCGA-2J-AABF-01A-31R-A41B-07</th>\n",
       "      <th>TCGA-2J-AABH-01A-21R-A41B-07</th>\n",
       "      <th>TCGA-2J-AABI-01A-12R-A41B-07</th>\n",
       "      <th>...</th>\n",
       "      <th>TCGA-XD-AAUH-01A-42R-A41B-07</th>\n",
       "      <th>TCGA-XD-AAUI-01A-42R-A41B-07</th>\n",
       "      <th>TCGA-XD-AAUL-01A-21R-A39D-07</th>\n",
       "      <th>TCGA-XN-A8T3-01A-11R-A36G-07</th>\n",
       "      <th>TCGA-XN-A8T5-01A-12R-A36G-07</th>\n",
       "      <th>TCGA-YB-A89D-11A-11R-A36G-07</th>\n",
       "      <th>TCGA-YB-A89D-01A-12R-A36G-07</th>\n",
       "      <th>TCGA-YH-A8SY-01A-11R-A37L-07</th>\n",
       "      <th>TCGA-YY-A8LH-01A-11R-A36G-07</th>\n",
       "      <th>TCGA-Z5-AAPL-01A-12R-A41B-07</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hybridization REF</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>gene_id</th>\n",
       "      <td>normalized_count</td>\n",
       "      <td>normalized_count</td>\n",
       "      <td>normalized_count</td>\n",
       "      <td>normalized_count</td>\n",
       "      <td>normalized_count</td>\n",
       "      <td>normalized_count</td>\n",
       "      <td>normalized_count</td>\n",
       "      <td>normalized_count</td>\n",
       "      <td>normalized_count</td>\n",
       "      <td>normalized_count</td>\n",
       "      <td>...</td>\n",
       "      <td>normalized_count</td>\n",
       "      <td>normalized_count</td>\n",
       "      <td>normalized_count</td>\n",
       "      <td>normalized_count</td>\n",
       "      <td>normalized_count</td>\n",
       "      <td>normalized_count</td>\n",
       "      <td>normalized_count</td>\n",
       "      <td>normalized_count</td>\n",
       "      <td>normalized_count</td>\n",
       "      <td>normalized_count</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>?|100130426</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>?|100133144</th>\n",
       "      <td>8.5512</td>\n",
       "      <td>23.9941</td>\n",
       "      <td>1.7836</td>\n",
       "      <td>3.5159</td>\n",
       "      <td>1.0718</td>\n",
       "      <td>12.5881</td>\n",
       "      <td>6.2957</td>\n",
       "      <td>13.5235</td>\n",
       "      <td>5.3397</td>\n",
       "      <td>14.5972</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>4.7895</td>\n",
       "      <td>6.2661</td>\n",
       "      <td>13.2700</td>\n",
       "      <td>6.5912</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>4.6506</td>\n",
       "      <td>8.4755</td>\n",
       "      <td>6.3411</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>?|100134869</th>\n",
       "      <td>8.5220</td>\n",
       "      <td>8.8342</td>\n",
       "      <td>4.0643</td>\n",
       "      <td>15.2855</td>\n",
       "      <td>15.0054</td>\n",
       "      <td>27.4933</td>\n",
       "      <td>20.8355</td>\n",
       "      <td>13.4101</td>\n",
       "      <td>8.1620</td>\n",
       "      <td>38.7409</td>\n",
       "      <td>...</td>\n",
       "      <td>5.2056</td>\n",
       "      <td>10.0693</td>\n",
       "      <td>13.6923</td>\n",
       "      <td>7.2996</td>\n",
       "      <td>10.6913</td>\n",
       "      <td>9.9059</td>\n",
       "      <td>8.7102</td>\n",
       "      <td>4.3750</td>\n",
       "      <td>24.5265</td>\n",
       "      <td>11.3960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>?|10357</th>\n",
       "      <td>110.7707</td>\n",
       "      <td>81.9234</td>\n",
       "      <td>176.5906</td>\n",
       "      <td>95.2197</td>\n",
       "      <td>84.0622</td>\n",
       "      <td>67.7000</td>\n",
       "      <td>102.3709</td>\n",
       "      <td>119.5535</td>\n",
       "      <td>108.5932</td>\n",
       "      <td>105.2576</td>\n",
       "      <td>...</td>\n",
       "      <td>80.3904</td>\n",
       "      <td>87.0332</td>\n",
       "      <td>131.9252</td>\n",
       "      <td>141.0918</td>\n",
       "      <td>81.4243</td>\n",
       "      <td>96.7013</td>\n",
       "      <td>107.1942</td>\n",
       "      <td>101.8925</td>\n",
       "      <td>118.8888</td>\n",
       "      <td>146.8376</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 183 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  TCGA-2J-AAB1-01A-11R-A41B-07 TCGA-2J-AAB4-01A-12R-A41B-07  \\\n",
       "Hybridization REF                                                             \n",
       "gene_id                       normalized_count             normalized_count   \n",
       "?|100130426                             0.0000                       0.0000   \n",
       "?|100133144                             8.5512                      23.9941   \n",
       "?|100134869                             8.5220                       8.8342   \n",
       "?|10357                               110.7707                      81.9234   \n",
       "\n",
       "                  TCGA-2J-AAB6-01A-11R-A41B-07 TCGA-2J-AAB8-01A-12R-A41B-07  \\\n",
       "Hybridization REF                                                             \n",
       "gene_id                       normalized_count             normalized_count   \n",
       "?|100130426                             0.0000                       0.0000   \n",
       "?|100133144                             1.7836                       3.5159   \n",
       "?|100134869                             4.0643                      15.2855   \n",
       "?|10357                               176.5906                      95.2197   \n",
       "\n",
       "                  TCGA-2J-AAB9-01A-11R-A41B-07 TCGA-2J-AABA-01A-21R-A41B-07  \\\n",
       "Hybridization REF                                                             \n",
       "gene_id                       normalized_count             normalized_count   \n",
       "?|100130426                             0.0000                       0.0000   \n",
       "?|100133144                             1.0718                      12.5881   \n",
       "?|100134869                            15.0054                      27.4933   \n",
       "?|10357                                84.0622                      67.7000   \n",
       "\n",
       "                  TCGA-2J-AABE-01A-12R-A41B-07 TCGA-2J-AABF-01A-31R-A41B-07  \\\n",
       "Hybridization REF                                                             \n",
       "gene_id                       normalized_count             normalized_count   \n",
       "?|100130426                             0.0000                       0.0000   \n",
       "?|100133144                             6.2957                      13.5235   \n",
       "?|100134869                            20.8355                      13.4101   \n",
       "?|10357                               102.3709                     119.5535   \n",
       "\n",
       "                  TCGA-2J-AABH-01A-21R-A41B-07 TCGA-2J-AABI-01A-12R-A41B-07  \\\n",
       "Hybridization REF                                                             \n",
       "gene_id                       normalized_count             normalized_count   \n",
       "?|100130426                             0.0000                       0.0000   \n",
       "?|100133144                             5.3397                      14.5972   \n",
       "?|100134869                             8.1620                      38.7409   \n",
       "?|10357                               108.5932                     105.2576   \n",
       "\n",
       "                   ... TCGA-XD-AAUH-01A-42R-A41B-07  \\\n",
       "Hybridization REF  ...                                \n",
       "gene_id            ...             normalized_count   \n",
       "?|100130426        ...                       0.0000   \n",
       "?|100133144        ...                       0.0000   \n",
       "?|100134869        ...                       5.2056   \n",
       "?|10357            ...                      80.3904   \n",
       "\n",
       "                  TCGA-XD-AAUI-01A-42R-A41B-07 TCGA-XD-AAUL-01A-21R-A39D-07  \\\n",
       "Hybridization REF                                                             \n",
       "gene_id                       normalized_count             normalized_count   \n",
       "?|100130426                             0.0000                       0.0000   \n",
       "?|100133144                             4.7895                       6.2661   \n",
       "?|100134869                            10.0693                      13.6923   \n",
       "?|10357                                87.0332                     131.9252   \n",
       "\n",
       "                  TCGA-XN-A8T3-01A-11R-A36G-07 TCGA-XN-A8T5-01A-12R-A36G-07  \\\n",
       "Hybridization REF                                                             \n",
       "gene_id                       normalized_count             normalized_count   \n",
       "?|100130426                             0.0000                       0.0000   \n",
       "?|100133144                            13.2700                       6.5912   \n",
       "?|100134869                             7.2996                      10.6913   \n",
       "?|10357                               141.0918                      81.4243   \n",
       "\n",
       "                  TCGA-YB-A89D-11A-11R-A36G-07 TCGA-YB-A89D-01A-12R-A36G-07  \\\n",
       "Hybridization REF                                                             \n",
       "gene_id                       normalized_count             normalized_count   \n",
       "?|100130426                             0.0000                       0.0000   \n",
       "?|100133144                             0.0000                       4.6506   \n",
       "?|100134869                             9.9059                       8.7102   \n",
       "?|10357                                96.7013                     107.1942   \n",
       "\n",
       "                  TCGA-YH-A8SY-01A-11R-A37L-07 TCGA-YY-A8LH-01A-11R-A36G-07  \\\n",
       "Hybridization REF                                                             \n",
       "gene_id                       normalized_count             normalized_count   \n",
       "?|100130426                             0.0000                       0.0000   \n",
       "?|100133144                             8.4755                       6.3411   \n",
       "?|100134869                             4.3750                      24.5265   \n",
       "?|10357                               101.8925                     118.8888   \n",
       "\n",
       "                  TCGA-Z5-AAPL-01A-12R-A41B-07  \n",
       "Hybridization REF                               \n",
       "gene_id                       normalized_count  \n",
       "?|100130426                             0.0000  \n",
       "?|100133144                             0.0000  \n",
       "?|100134869                            11.3960  \n",
       "?|10357                               146.8376  \n",
       "\n",
       "[5 rows x 183 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "# --- point to your file on Desktop ---\n",
    "TCGA_EXPR = Path(\"~/Desktop/PAAD.rnaseqv2__illuminahiseq_rnaseqv2__unc_edu__Level_3__RSEM_genes_normalized__data.data.txt\").expanduser()\n",
    "\n",
    "# --- load it ---\n",
    "df_tcga = pd.read_csv(TCGA_EXPR, sep=\"\\t\", low_memory=False)\n",
    "print(\"Raw shape:\", df_tcga.shape)\n",
    "print(\"First columns:\", list(df_tcga.columns[:10]))\n",
    "\n",
    "# often TCGA files have a column named \"gene_id\" or \"Hybridization REF\" or similar\n",
    "# detect automatically:\n",
    "gene_col = None\n",
    "for c in df_tcga.columns:\n",
    "    if \"gene\" in c.lower() or \"hybridization\" in c.lower():\n",
    "        gene_col = c\n",
    "        break\n",
    "\n",
    "if gene_col is None:\n",
    "    raise ValueError(\"Couldn't find gene column — check file header.\")\n",
    "\n",
    "# set gene column as index\n",
    "df_tcga = df_tcga.set_index(gene_col)\n",
    "print(\"Processed shape:\", df_tcga.shape)\n",
    "\n",
    "# --- optional: save as clean CSV for future quick loading ---\n",
    "out_csv = TCGA_EXPR.with_suffix(\".csv\")\n",
    "df_tcga.to_csv(out_csv)\n",
    "print(\"Saved cleaned CSV to:\", out_csv)\n",
    "\n",
    "# quick preview\n",
    "display(df_tcga.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "e3ed2cd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Cleaned expression matrix saved to: /Users/scottpowers/Desktop/PAAD_RSEM_genes_normalized_CLEAN.csv\n",
      "New shape: (20503, 183)\n",
      "Example rows after cleanup:\n",
      "                  TCGA-2J-AAB1-01A-11R-A41B-07 TCGA-2J-AAB4-01A-12R-A41B-07  \\\n",
      "Hybridization REF                                                             \n",
      "gene_id                       normalized_count             normalized_count   \n",
      "A1BG|1                                 81.9122                      56.7551   \n",
      "A1CF|29974                             25.3659                      53.4512   \n",
      "A2BP1|54715                             0.4878                       2.1044   \n",
      "A2LD1|87769                           180.4976                     111.0774   \n",
      "\n",
      "                  TCGA-2J-AAB6-01A-11R-A41B-07 TCGA-2J-AAB8-01A-12R-A41B-07  \\\n",
      "Hybridization REF                                                             \n",
      "gene_id                       normalized_count             normalized_count   \n",
      "A1BG|1                                 82.5497                      56.9307   \n",
      "A1CF|29974                              8.1871                      33.8425   \n",
      "A2BP1|54715                             0.0000                       0.0000   \n",
      "A2LD1|87769                           163.1228                     185.8143   \n",
      "\n",
      "                  TCGA-2J-AAB9-01A-11R-A41B-07 TCGA-2J-AABA-01A-21R-A41B-07  \\\n",
      "Hybridization REF                                                             \n",
      "gene_id                       normalized_count             normalized_count   \n",
      "A1BG|1                                105.7878                      99.3455   \n",
      "A1CF|29974                             21.4362                      18.7882   \n",
      "A2BP1|54715                             1.0718                       0.0000   \n",
      "A2LD1|87769                           166.7095                      99.2767   \n",
      "\n",
      "                  TCGA-2J-AABE-01A-12R-A41B-07 TCGA-2J-AABF-01A-31R-A41B-07  \\\n",
      "Hybridization REF                                                             \n",
      "gene_id                       normalized_count             normalized_count   \n",
      "A1BG|1                                 79.4019                      92.7368   \n",
      "A1CF|29974                              3.0831                     112.3416   \n",
      "A2BP1|54715                             0.0000                       3.1895   \n",
      "A2LD1|87769                           134.5645                     112.9760   \n",
      "\n",
      "                  TCGA-2J-AABH-01A-21R-A41B-07 TCGA-2J-AABI-01A-12R-A41B-07  \\\n",
      "Hybridization REF                                                             \n",
      "gene_id                       normalized_count             normalized_count   \n",
      "A1BG|1                                 52.5740                      76.3316   \n",
      "A1CF|29974                             62.2822                       0.0000   \n",
      "A2BP1|54715                             1.3066                       0.3628   \n",
      "A2LD1|87769                           261.8772                      56.9993   \n",
      "\n",
      "                   ... TCGA-XD-AAUH-01A-42R-A41B-07  \\\n",
      "Hybridization REF  ...                                \n",
      "gene_id            ...             normalized_count   \n",
      "A1BG|1             ...                     135.0495   \n",
      "A1CF|29974         ...                      42.6861   \n",
      "A2BP1|54715        ...                      10.9318   \n",
      "A2LD1|87769        ...                      88.4279   \n",
      "\n",
      "                  TCGA-XD-AAUI-01A-42R-A41B-07 TCGA-XD-AAUL-01A-21R-A39D-07  \\\n",
      "Hybridization REF                                                             \n",
      "gene_id                       normalized_count             normalized_count   \n",
      "A1BG|1                                141.4958                     101.9751   \n",
      "A1CF|29974                             85.6860                      89.3971   \n",
      "A2BP1|54715                             2.4765                       0.8316   \n",
      "A2LD1|87769                           158.4200                      67.4304   \n",
      "\n",
      "                  TCGA-XN-A8T3-01A-11R-A36G-07 TCGA-XN-A8T5-01A-12R-A36G-07  \\\n",
      "Hybridization REF                                                             \n",
      "gene_id                       normalized_count             normalized_count   \n",
      "A1BG|1                                132.0253                     122.8427   \n",
      "A1CF|29974                             21.0970                       9.5352   \n",
      "A2BP1|54715                             0.0000                       4.1716   \n",
      "A2LD1|87769                           104.5200                      89.0226   \n",
      "\n",
      "                  TCGA-YB-A89D-11A-11R-A36G-07 TCGA-YB-A89D-01A-12R-A36G-07  \\\n",
      "Hybridization REF                                                             \n",
      "gene_id                       normalized_count             normalized_count   \n",
      "A1BG|1                                140.5795                     156.8859   \n",
      "A1CF|29974                             12.3824                      73.9979   \n",
      "A2BP1|54715                             3.9624                       1.0277   \n",
      "A2LD1|87769                           103.3779                     104.0904   \n",
      "\n",
      "                  TCGA-YH-A8SY-01A-11R-A37L-07 TCGA-YY-A8LH-01A-11R-A36G-07  \\\n",
      "Hybridization REF                                                             \n",
      "gene_id                       normalized_count             normalized_count   \n",
      "A1BG|1                                239.3867                      65.8274   \n",
      "A1CF|29974                              2.3364                      29.9857   \n",
      "A2BP1|54715                             0.0000                       3.9687   \n",
      "A2LD1|87769                            87.4533                     120.9525   \n",
      "\n",
      "                  TCGA-Z5-AAPL-01A-12R-A41B-07  \n",
      "Hybridization REF                               \n",
      "gene_id                       normalized_count  \n",
      "A1BG|1                                120.8775  \n",
      "A1CF|29974                              3.9886  \n",
      "A2BP1|54715                             0.0000  \n",
      "A2LD1|87769                           106.7749  \n",
      "\n",
      "[5 rows x 183 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "# --- Load file ---\n",
    "TCGA_EXPR = Path(\"~/Desktop/PAAD.rnaseqv2__illuminahiseq_rnaseqv2__unc_edu__Level_3__RSEM_genes_normalized__data.data.txt\").expanduser()\n",
    "df = pd.read_csv(TCGA_EXPR, sep=\"\\t\", low_memory=False)\n",
    "\n",
    "# --- Set gene column as index ---\n",
    "df = df.set_index(\"Hybridization REF\")\n",
    "\n",
    "# --- Remove rows with junk IDs ---\n",
    "# 1. Drop rows starting with '?'\n",
    "df = df[~df.index.str.startswith(\"?\")]\n",
    "\n",
    "# 2. Drop empty or whitespace-only gene names\n",
    "df = df[df.index.str.strip() != \"\"]\n",
    "\n",
    "# 3. Drop duplicate gene names (if any, keep first occurrence)\n",
    "df = df[~df.index.duplicated(keep=\"first\")]\n",
    "\n",
    "# --- Save cleaned file ---\n",
    "CLEAN_PATH = TCGA_EXPR.with_name(\"PAAD_RSEM_genes_normalized_CLEAN.csv\")\n",
    "df.to_csv(CLEAN_PATH)\n",
    "\n",
    "print(f\"✅ Cleaned expression matrix saved to: {CLEAN_PATH}\")\n",
    "print(f\"New shape: {df.shape}\")\n",
    "print(\"Example rows after cleanup:\")\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "790aa69c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (1321, 186)\n",
      "Columns: ['admin.batch_number', '424.43.0', '424.43.0.1', '392.47.0', '410.44.0', '392.47.0.1', '284.60.0', '424.43.0.2', '106.60.0', '284.60.0.1', '195.62.0', '284.60.0.2', '369.51.0', '369.51.0.1', '195.62.0.1']\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "# point to your file on Desktop\n",
    "TCGA_META = Path(\"~/Desktop/PAAD.clin.merged.txt\").expanduser()\n",
    "\n",
    "# load\n",
    "meta = pd.read_csv(TCGA_META, sep=\"\\t\", low_memory=False)\n",
    "print(\"Shape:\", meta.shape)\n",
    "print(\"Columns:\", list(meta.columns[:15]))\n",
    "\n",
    "# optional: save as clean CSV\n",
    "meta.to_csv(TCGA_META.with_suffix(\".csv\"), index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ccdbfa4",
   "metadata": {},
   "source": [
    "## 2) Define module gene sets\n",
    "Replace the placeholders with your finalized core gene lists. You can also load from CSVs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "3e20f29a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TCGA_EXPR: /Users/scottpowers/Desktop/PAAD_RSEM_genes_normalized_CLEAN.csv\n",
      "PULEO_EXPR: /Users/scottpowers/Desktop/Puleo_expr.csv\n",
      "Loaded TCGA (raw): (20503, 183)\n",
      "TCGA after gene normalization: (20502, 183)\n",
      "Loaded Puleo (raw): (19749, 357)\n",
      "Puleo after gene normalization: (19736, 357)\n",
      "✅ TCGA: 20502 genes × 183 samples\n",
      "   Saved: TCGA_IGE_signed_scores.csv, TCGA_IGE_signed_scores_Z.csv\n",
      "   Coverage: UP 102/118 | DOWN 19/26\n",
      "✅ Puleo: 19736 genes × 357 samples\n",
      "   Saved: Puleo_IGE_signed_scores.csv, Puleo_IGE_signed_scores_Z.csv\n",
      "   Coverage: UP 100/118 | DOWN 18/26\n"
     ]
    }
   ],
   "source": [
    "# === Fix loading, set paths, rescore TCGA + Puleo ============================\n",
    "import pandas as pd, numpy as np, gzip, io, re\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "DESKTOP = Path(\"~/Desktop\").expanduser()\n",
    "OUTDIR  = Path(\"./out_modules_notebook\"); OUTDIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# ---- 1) Locate TCGA file on Desktop (prefer CLEAN CSV, else raw Firehose txt) ----\n",
    "def find_tcga_expr():\n",
    "    # Prefer a cleaned CSV you saved earlier\n",
    "    cand = list(DESKTOP.glob(\"*RSEM*normalized*_*CLEAN*.csv\")) + list(DESKTOP.glob(\"*RSEM*normalized*data*.csv\"))\n",
    "    if cand: return cand[0]\n",
    "    # Fall back to the raw Level_3 text\n",
    "    cand = list(DESKTOP.glob(\"*RSEM*normalized*data*.txt\"))\n",
    "    return cand[0] if cand else None\n",
    "\n",
    "TCGA_EXPR = find_tcga_expr()\n",
    "PULEO_EXPR = DESKTOP / \"Puleo_expr.csv\"  # produced earlier by the download/parse step\n",
    "\n",
    "print(\"TCGA_EXPR:\", TCGA_EXPR)\n",
    "print(\"PULEO_EXPR:\", PULEO_EXPR if PULEO_EXPR.exists() else \"NOT FOUND\")\n",
    "\n",
    "# ---- 2) Robust loader for expression matrices (genes x samples) ----\n",
    "def smart_read_expr(path: Path) -> pd.DataFrame:\n",
    "    \"\"\"Load CSV/TSV/GEO matrix; set gene column correctly; numeric; no samples→retry.\"\"\"\n",
    "    if path is None or not Path(path).exists():\n",
    "        raise FileNotFoundError(f\"Missing expression file: {path}\")\n",
    "    p = Path(path)\n",
    "    # handle gz\n",
    "    if p.suffix == \".gz\":\n",
    "        with gzip.open(p, \"rt\", encoding=\"utf-8\", errors=\"ignore\") as fh:\n",
    "            txt = fh.read()\n",
    "        # If this is a GEO series matrix block (has begin/end markers)\n",
    "        if \"!series_matrix_table_begin\" in txt:\n",
    "            beg = txt.index(\"!series_matrix_table_begin\") + len(\"!series_matrix_table_begin\")\n",
    "            end = txt.index(\"!series_matrix_table_end\")\n",
    "            tab = txt[beg:end].lstrip(\"\\n\")\n",
    "            df = pd.read_csv(io.StringIO(tab), sep=\"\\t\", dtype=str)\n",
    "        else:\n",
    "            df = pd.read_csv(io.StringIO(txt), sep=None, engine=\"python\", dtype=str, comment=\"!\")\n",
    "    else:\n",
    "        # try csv, then tsv, then auto\n",
    "        try:\n",
    "            df = pd.read_csv(p, dtype=str)\n",
    "        except Exception:\n",
    "            try:\n",
    "                df = pd.read_csv(p, sep=\"\\t\", dtype=str)\n",
    "            except Exception:\n",
    "                df = pd.read_csv(p, sep=None, engine=\"python\", dtype=str, comment=\"!\")\n",
    "\n",
    "    # If a standard gene column exists, set it as index\n",
    "    gene_like = [c for c in df.columns if c.lower() in {\"hybridization ref\",\"hybridization_ref\",\"gene\",\"gene_symbol\",\"genes\",\"id_ref\",\"symbol\"}]\n",
    "    if gene_like:\n",
    "        df = df.set_index(gene_like[0])\n",
    "    else:\n",
    "        # If first column looks like gene keys and others look like samples, use first col\n",
    "        if df.shape[1] > 1:\n",
    "            df = df.set_index(df.columns[0])\n",
    "\n",
    "    # Drop completely empty columns (just in case)\n",
    "    df = df.dropna(axis=1, how=\"all\")\n",
    "    # Convert to numeric where possible\n",
    "    df = df.apply(pd.to_numeric, errors=\"coerce\")\n",
    "\n",
    "    # If we still ended up with 0 samples because of separator issues, re-read with the other sep\n",
    "    if df.shape[1] == 0:\n",
    "        # try the opposite separator quickly\n",
    "        raw = Path(path).read_text(errors=\"ignore\") if p.suffix != \".gz\" else txt\n",
    "        sep = \"\\t\" if \",\" in raw.splitlines()[0] else \",\"\n",
    "        df = pd.read_csv(io.StringIO(raw), sep=sep, dtype=str)\n",
    "        if df.shape[1] > 1:\n",
    "            df = df.set_index(df.columns[0])\n",
    "            df = df.apply(pd.to_numeric, errors=\"coerce\")\n",
    "\n",
    "    return df\n",
    "\n",
    "# ---- 3) Normalize gene index (SYMBOL|ENTREZ → SYMBOL; uppercase; collapse dups) ----\n",
    "def normalize_gene_index(expr: pd.DataFrame) -> pd.DataFrame:\n",
    "    idx = expr.index.astype(str).str.strip()\n",
    "    idx = idx.str.replace(r\"\\|.*$\", \"\", regex=True)     # keep before '|'\n",
    "    idx = idx.str.replace(r\"\\.\\d+$\", \"\", regex=True)    # drop .version\n",
    "    idx = idx.str.upper()\n",
    "    out = expr.copy(); out.index = idx\n",
    "    return out.groupby(out.index).mean()\n",
    "\n",
    "# ---- 4) IGE gene sets ----\n",
    "IGE_UP = [\n",
    "    \"PFN2\",\"SET\",\"LGALS1\",\"PDLIM4\",\"EIF5A\",\"F8A1\",\"BANF1\",\"CTDNEP1\",\"TRAPPC1\",\"AMZ2\",\"PTGES3\",\"ST13\",\n",
    "    \"FTH1\",\"PCBP1\",\"NAA10\",\"ARPC5L\",\"ETFB\",\"CCDC124\",\"SSR2\",\"PGLS\",\"SELENOH\",\"GSTP1\",\"NDUFB7\",\"AURKAIP1\",\n",
    "    \"GCHFR\",\"MYL6\",\"AP2S1\",\"S100A13\",\"C9ORF16\",\"KRT8\",\"PRKCSH\",\"CST3\",\"PET100\",\"DNAJA2\",\"VPS35\",\"VDAC1\",\n",
    "    \"MGST3\",\"PRR13\",\"OCIAD2\",\"FUOM\",\"MIA\",\"RPN1\",\"FUCA2\",\"TMED4\",\"ERGIC3\",\"DDOST\",\"NAXE\",\"SNRPD1\",\"SKP1\",\n",
    "    \"CNBP\",\"ATP5MC3\",\"SLC25A5\",\"LSM4\",\"NDUFAB1\",\"PCBD1\",\"HINT1\",\"ADI1\",\"NENF\",\"MRPL43\",\"VKORC1\",\"EMC4\",\n",
    "    \"COA3\",\"NEDD8\",\"CHCHD2\",\"PRDX5\",\"WDR83OS\",\"NDUFA4\",\"GABARAP\",\"PHPT1\",\"UFC1\",\"MDH1\",\"ATP5F1E\",\"MRPL41\",\n",
    "    \"UBL5\",\"COX5B\",\"ELOB\",\"ATP5ME\",\"UQCRB\",\"SEM1\",\"NDUFB1\",\"COX6C\",\"ATP6V1F\",\"HNRNPA1\",\"HIGD2A\",\"POLR2I\",\n",
    "    \"METTL26\",\"NDUFB4\",\"OST4\",\"C19ORF53\",\"RPL36AL\",\"PPIA\",\"COPS9\",\"COX8A\",\"COX5A\",\"RPL36\",\"RPS15\",\"RPS27\",\n",
    "    \"RPS11\",\"FTL\",\"SNHG29\",\"NACA\",\"RPS17\",\"RPL23\",\"RPL39\",\"RPS21\",\"RPL9\",\"RPL15\",\"RPL34\",\"RPL27A\",\"RPL36A\",\n",
    "    \"RPL38\",\"RPS26\",\"RPS14\",\"RPL35\",\"RPL37A\",\"RPL37\",\"RPL12\",\"RPS29\"\n",
    "]\n",
    "IGE_DOWN = [\n",
    "    \"STT3A\",\"SGPP1\",\"LINGO1\",\"ASS1\",\"CETN2\",\"HNRNPH1\",\"STN1\",\"NRG4\",\"IQSEC2\",\"IYD\",\"CHD9\",\"APBB1IP\",\n",
    "    \"TMEM238\",\"REX1BD\",\"IFI27\",\"CYBA\",\"METRNL\",\"AKR7A2\",\"SULT1A1\",\"ARHGEF35\",\"AC008397.1\",\"KLK11\",\n",
    "    \"DELE1\",\"MISP\",\"FAM234A\",\"CMBL\"\n",
    "]\n",
    "\n",
    "# ---- 5) Scoring helpers ----\n",
    "def zscore_by_gene(expr):\n",
    "    mu = expr.mean(axis=1)\n",
    "    sd = expr.std(axis=1, ddof=0).replace(0, np.nan)\n",
    "    return (expr.sub(mu, axis=0)).div(sd, axis=0)\n",
    "\n",
    "def score_signed_module(expr, up_genes, down_genes, min_genes=10):\n",
    "    expr = expr.copy()\n",
    "    expr.index = expr.index.astype(str).str.upper()\n",
    "    UP   = pd.Index(map(str.upper, up_genes))\n",
    "    DOWN = pd.Index(map(str.upper, down_genes))\n",
    "    up_present   = expr.index.intersection(UP)\n",
    "    down_present = expr.index.intersection(DOWN)\n",
    "    Z = zscore_by_gene(expr)\n",
    "    up_mean   = Z.loc[up_present].mean(axis=0)   if len(up_present)   else pd.Series(0.0, index=Z.columns)\n",
    "    down_mean = Z.loc[down_present].mean(axis=0) if len(down_present) else pd.Series(0.0, index=Z.columns)\n",
    "    scores = (up_mean - down_mean).astype(float)\n",
    "    cov = {\"up_total\": len(UP), \"up_used\": len(up_present), \"down_total\": len(DOWN), \"down_used\": len(down_present)}\n",
    "    if cov[\"up_used\"] < min_genes or cov[\"down_used\"] < min_genes:\n",
    "        print(f\"[warn] coverage: UP {cov['up_used']}/{cov['up_total']} | DOWN {cov['down_used']}/{cov['down_total']}\")\n",
    "    if cov[\"up_used\"] == 0 and cov[\"down_used\"] == 0:\n",
    "        scores[:] = np.nan\n",
    "    return scores, cov\n",
    "\n",
    "def zscore_series(s):\n",
    "    mu, sd = s.mean(), s.std(ddof=0)\n",
    "    return (s - mu) / sd if sd and not np.isnan(sd) else s*0\n",
    "\n",
    "# ---- 6) Load cohorts robustly ----\n",
    "cohorts = []\n",
    "if TCGA_EXPR:  # TCGA\n",
    "    try:\n",
    "        tcga = smart_read_expr(TCGA_EXPR)\n",
    "        print(\"Loaded TCGA (raw):\", tcga.shape)\n",
    "        tcga = normalize_gene_index(tcga)\n",
    "        print(\"TCGA after gene normalization:\", tcga.shape)\n",
    "        cohorts.append((\"TCGA\", tcga))\n",
    "    except Exception as e:\n",
    "        print(\"TCGA load failed:\", e)\n",
    "\n",
    "if PULEO_EXPR.exists():\n",
    "    try:\n",
    "        puleo = smart_read_expr(PULEO_EXPR)\n",
    "        print(\"Loaded Puleo (raw):\", puleo.shape)\n",
    "        puleo = normalize_gene_index(puleo)\n",
    "        print(\"Puleo after gene normalization:\", puleo.shape)\n",
    "        cohorts.append((\"Puleo\", puleo))\n",
    "    except Exception as e:\n",
    "        print(\"Puleo load failed:\", e)\n",
    "else:\n",
    "    print(\"⚠️ Puleo_expr.csv not found on Desktop. Run the earlier download/parse step.\")\n",
    "\n",
    "# ---- 7) Score & save ----\n",
    "for label, expr in cohorts:\n",
    "    scores, cov = score_signed_module(expr, IGE_UP, IGE_DOWN, min_genes=10)\n",
    "    raw_path = OUTDIR / f\"{label}_IGE_signed_scores.csv\"\n",
    "    z_path   = OUTDIR / f\"{label}_IGE_signed_scores_Z.csv\"\n",
    "    scores.rename(\"IGE_signed_score\").to_csv(raw_path)\n",
    "    z = zscore_series(scores).rename(\"IGE_signed_score_Z\")\n",
    "    z.to_csv(z_path)\n",
    "    print(f\"✅ {label}: {expr.shape[0]} genes × {expr.shape[1]} samples\")\n",
    "    print(f\"   Saved: {raw_path.name}, {z_path.name}\")\n",
    "    print(f\"   Coverage: UP {cov['up_used']}/{cov['up_total']} | DOWN {cov['down_used']}/{cov['down_total']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "2001bdeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     Unnamed: 0  IGE_signed_score_Z\n",
      "0  TCGA-2J-AAB1-01A-11R-A41B-07           -0.243979\n",
      "1  TCGA-2J-AAB4-01A-12R-A41B-07           -0.496232\n",
      "2  TCGA-2J-AAB6-01A-11R-A41B-07            0.600294\n",
      "3  TCGA-2J-AAB8-01A-12R-A41B-07            0.012602\n",
      "4  TCGA-2J-AAB9-01A-11R-A41B-07            0.222417\n",
      "shape: (183, 2)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "ige = pd.read_csv(\"out_modules_notebook/TCGA_IGE_signed_scores_Z.csv\")\n",
    "print(ige.head())\n",
    "print(\"shape:\", ige.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "bf7222a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SURV-AUTO] discovered columns:\n",
      "  vital: []\n",
      "  death: []\n",
      "  last follow-up: []\n",
      "[SURV-AUTO] rows: 184\n",
      "[SURV-AUTO] OS_event counts:\n",
      " OS_event\n",
      "NaN    184\n",
      "Name: count, dtype: int64\n",
      "[SURV-AUTO] OS_time appears all NA\n"
     ]
    }
   ],
   "source": [
    "import re, numpy as np, pandas as pd\n",
    "\n",
    "def _num(s):\n",
    "    return pd.to_numeric(s, errors=\"coerce\")\n",
    "\n",
    "def _rowmax(df, cols):\n",
    "    cols = [c for c in cols if c in df.columns]\n",
    "    if not cols:\n",
    "        return pd.Series(np.nan, index=df.index)\n",
    "    return pd.concat([_num(df[c]) for c in cols], axis=1).max(axis=1)\n",
    "\n",
    "def derive_tcga_survival_auto(clin_df: pd.DataFrame, barcode_col_guess=(\"patient.bcr_patient_barcode\", \"bcr_patient_barcode\"), verbose=True):\n",
    "    df = clin_df.copy()\n",
    "    # index to patient barcode (12-char)\n",
    "    bc = None\n",
    "    for col in barcode_col_guess:\n",
    "        if col in df.columns:\n",
    "            bc = col; break\n",
    "    if bc is None:\n",
    "        # fall back: if index looks like TCGA barcodes, use it\n",
    "        df.index = df.index.astype(str)\n",
    "    else:\n",
    "        df = df.set_index(bc)\n",
    "    df.index = df.index.astype(str).str[:12]\n",
    "\n",
    "    cols = df.columns.astype(str)\n",
    "\n",
    "    # discover candidate columns\n",
    "    vital_cols = [c for c in cols if re.search(r'vital[\\s_]*status', c, re.I)]\n",
    "    death_cols = [c for c in cols if re.search(r'days?\\s*_?\\s*to\\s*_?.*death', c, re.I)]\n",
    "    lfu_cols   = [c for c in cols if re.search(r'days?\\s*_?\\s*to\\s*_?.*(last|lst).*follow', c, re.I)]\n",
    "\n",
    "    if verbose:\n",
    "        print(\"[SURV-AUTO] discovered columns:\")\n",
    "        print(\"  vital:\", vital_cols[:10])\n",
    "        print(\"  death:\", death_cols[:10])\n",
    "        print(\"  last follow-up:\", lfu_cols[:10])\n",
    "\n",
    "    # event from vital if present\n",
    "    OS_event = pd.Series(np.nan, index=df.index, dtype=\"float\")\n",
    "    if vital_cols:\n",
    "        v = df[vital_cols[0]].astype(str).str.strip().str.lower()\n",
    "        OS_event = v.replace({\n",
    "            \"dead\":1, \"deceased\":1, \"1\":1, \"true\":1, \"yes\":1,\n",
    "            \"alive\":0, \"living\":0, \"0\":0, \"false\":0, \"no\":0\n",
    "        })\n",
    "        OS_event = pd.to_numeric(OS_event, errors=\"coerce\")\n",
    "\n",
    "    # if still all NA, infer from days_to_death presence\n",
    "    dtd = _rowmax(df, death_cols)\n",
    "    lfu = _rowmax(df, lfu_cols)\n",
    "\n",
    "    if OS_event.isna().all():\n",
    "        OS_event = pd.Series(np.nan, index=df.index, dtype=\"float\")\n",
    "        # event=1 if any death days present and >0\n",
    "        OS_event[(~dtd.isna()) & (dtd > 0)] = 1\n",
    "        # event=0 if no death, but has follow-up time\n",
    "        OS_event[(dtd.isna() | (dtd <= 0)) & (~lfu.isna()) & (lfu >= 0)] = 0\n",
    "\n",
    "    # time = death if event==1 else last follow-up\n",
    "    OS_time = np.where(OS_event == 1, dtd, lfu)\n",
    "    OS_time = pd.to_numeric(OS_time, errors=\"coerce\")\n",
    "\n",
    "    out = pd.DataFrame({\"OS_time\": OS_time, \"OS_event\": OS_event}, index=df.index)\n",
    "\n",
    "    if verbose:\n",
    "        print(\"[SURV-AUTO] rows:\", len(out))\n",
    "        print(\"[SURV-AUTO] OS_event counts:\\n\", out[\"OS_event\"].value_counts(dropna=False))\n",
    "        if out[\"OS_time\"].notna().any():\n",
    "            print(\"[SURV-AUTO] OS_time (days) min/median/max:\",\n",
    "                  np.nanmin(out[\"OS_time\"]), np.nanmedian(out[\"OS_time\"]), np.nanmax(out[\"OS_time\"]))\n",
    "        else:\n",
    "            print(\"[SURV-AUTO] OS_time appears all NA\")\n",
    "\n",
    "    return out\n",
    "\n",
    "# ---- run on your loaded clinical table ----\n",
    "tcga_surv = derive_tcga_survival_auto(clin, verbose=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "362c5cf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SURV] rows: 184\n",
      "[SURV] OS_event counts:\n",
      " OS_event\n",
      "1.0    99\n",
      "0.0    85\n",
      "Name: count, dtype: int64\n",
      "[SURV] OS_time (days): min 0.0 median 466.8144047234375 max 2742.8473386112496\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>OS_time</th>\n",
       "      <th>OS_event</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>patientId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>TCGA-3A-A9IN</th>\n",
       "      <td>2085.404543</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-2J-AAB4</th>\n",
       "      <td>729.491321</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-HV-A5A3</th>\n",
       "      <td>128.086268</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-FZ-5922</th>\n",
       "      <td>1101.742036</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-HZ-7925</th>\n",
       "      <td>614.413815</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  OS_time  OS_event\n",
       "patientId                          \n",
       "TCGA-3A-A9IN  2085.404543       0.0\n",
       "TCGA-2J-AAB4   729.491321       0.0\n",
       "TCGA-HV-A5A3   128.086268       1.0\n",
       "TCGA-FZ-5922  1101.742036       1.0\n",
       "TCGA-HZ-7925   614.413815       1.0"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "# --- load the clinical file ---\n",
    "clin_cbio = pd.read_csv(Path.home() / \"Desktop\" / \"paad_tcga_pan_can_atlas_2018_clinical_data.csv\", low_memory=False)\n",
    "\n",
    "# --- standardize index ---\n",
    "if \"patientId\" in clin_cbio.columns:\n",
    "    clin_cbio = clin_cbio.set_index(\"patientId\")\n",
    "clin_cbio.index = clin_cbio.index.astype(str).str[:12]  # make sure it's 12-char TCGA barcode\n",
    "\n",
    "# --- build OS_event ---\n",
    "# OS_STATUS is typically \"DECEASED\" or \"LIVING\"\n",
    "os_status = clin_cbio[\"OS_STATUS\"].astype(str).str.upper().str.strip()\n",
    "OS_event = os_status.str.contains(\"DECEASED\").astype(float)  # 1 if deceased, 0 if living\n",
    "\n",
    "# --- build OS_time ---\n",
    "# OS_MONTHS is survival time in months; convert to days\n",
    "OS_time = pd.to_numeric(clin_cbio[\"OS_MONTHS\"], errors=\"coerce\") * 30.4375\n",
    "\n",
    "# --- assemble ---\n",
    "tcga_surv = pd.DataFrame({\n",
    "    \"OS_time\": OS_time,\n",
    "    \"OS_event\": OS_event\n",
    "}, index=clin_cbio.index)\n",
    "\n",
    "print(\"[SURV] rows:\", len(tcga_surv))\n",
    "print(\"[SURV] OS_event counts:\\n\", tcga_surv[\"OS_event\"].value_counts(dropna=False))\n",
    "print(\"[SURV] OS_time (days): min\", np.nanmin(OS_time), \"median\", np.nanmedian(OS_time), \"max\", np.nanmax(OS_time))\n",
    "\n",
    "tcga_surv.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "7fa96731",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TCGA] shape (genes x samples): (20503, 183)\n",
      "[TCGA] missing values: 183\n",
      "[PULEO] shape (genes x samples): (19749, 357)\n",
      "[PULEO] missing values: 0\n",
      "[TCGA] coverage preview — UP: 0/118  DOWN: 0/26\n"
     ]
    }
   ],
   "source": [
    "# === Point to your matrices + preflight to ensure genes x samples ============\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "DESKTOP = Path.home() / \"Desktop\"\n",
    "\n",
    "# --- Set paths you actually have ---\n",
    "TCGA_EXPR  = DESKTOP / \"PAAD_RSEM_genes_normalized_CLEAN.csv\"   # TCGA-PAAD expression\n",
    "PULEO_EXPR = DESKTOP / \"Puleo_expr.csv\"                         # Puleo expression\n",
    "# If you also have COMPASS, add it here:\n",
    "# COMPASS_EXPR = DESKTOP / \"COMPASS_expr.csv\"\n",
    "\n",
    "def load_expr_matrix(path: Path, cohort_label: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Loads a matrix and enforces genes x samples orientation,\n",
    "    unique gene symbols, and TCGA barcode normalization where needed.\n",
    "    \"\"\"\n",
    "    if not path.exists():\n",
    "        raise FileNotFoundError(f\"{cohort_label}: file not found -> {path}\")\n",
    "\n",
    "    df = pd.read_csv(path, index_col=0, low_memory=False)\n",
    "\n",
    "    # Heuristics: if there are way more rows than columns, it's probably genes x samples already.\n",
    "    # If not, try transpose.\n",
    "    if df.shape[0] < df.shape[1]:\n",
    "        # If columns look like HGNC symbols, transpose\n",
    "        # (HGNC-ish columns are often uppercase with few digits)\n",
    "        # Safer: check if >60% of index are uppercase-ish gene names;\n",
    "        # if not, transpose.\n",
    "        df = df.T\n",
    "\n",
    "    # Deduplicate gene symbols by averaging duplicates\n",
    "    df.index = df.index.astype(str)\n",
    "    if df.index.duplicated().any():\n",
    "        df = df.groupby(df.index).mean()\n",
    "\n",
    "    # TCGA: normalize sample barcodes to 12-char patient IDs (if columns look like TCGA)\n",
    "    if cohort_label.upper() == \"TCGA\":\n",
    "        df.columns = df.columns.astype(str).str[:12]\n",
    "\n",
    "    # Make sure everything is numeric\n",
    "    df = df.apply(pd.to_numeric, errors=\"coerce\")\n",
    "\n",
    "    # Basic sanity print\n",
    "    print(f\"[{cohort_label}] shape (genes x samples): {df.shape}\")\n",
    "    print(f\"[{cohort_label}] missing values: {df.isna().sum().sum():,}\")\n",
    "    return df\n",
    "\n",
    "expr_tcga  = load_expr_matrix(TCGA_EXPR,  \"TCGA\")\n",
    "expr_puleo = load_expr_matrix(PULEO_EXPR, \"PULEO\")\n",
    "\n",
    "# If you don't have COMPASS, just keep the two cohorts\n",
    "cohorts = [(\"TCGA\", expr_tcga), (\"PULEO\", expr_puleo)]\n",
    "\n",
    "# Optional: quickly check overlap with your gene lists if you've already defined them\n",
    "try:\n",
    "    up_cov  = len(set(IGE_UP) & set(expr_tcga.index))\n",
    "    down_cov= len(set(IGE_DOWN) & set(expr_tcga.index))\n",
    "    print(f\"[TCGA] coverage preview — UP: {up_cov}/{len(IGE_UP)}  DOWN: {down_cov}/{len(IGE_DOWN)}\")\n",
    "except NameError:\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "c7d8c36f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Loaded cohorts: ['TCGA', 'PULEO']\n",
      "✅ TCGA saved:\n",
      "   - raw scores: out_modules_notebook/TCGA_IGE_signed_scores.csv (n=183)\n",
      "   - z scores  : out_modules_notebook/TCGA_IGE_signed_scores_Z.csv (mean=nan, sd=nan)\n",
      "   Coverage: UP 0/118 | DOWN 0/20\n",
      "   - histograms: TCGA_IGE_signed_scores_hist.png, TCGA_IGE_signed_scores_Z_hist.png\n",
      "\n",
      "✅ PULEO saved:\n",
      "   - raw scores: out_modules_notebook/PULEO_IGE_signed_scores.csv (n=357)\n",
      "   - z scores  : out_modules_notebook/PULEO_IGE_signed_scores_Z.csv (mean=-0.000, sd=1.000)\n",
      "   Coverage: UP 98/118 | DOWN 12/20\n",
      "   - histograms: PULEO_IGE_signed_scores_hist.png, PULEO_IGE_signed_scores_Z_hist.png\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# === Setup: scoring function, cohorts, and output dir =========================\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from typing import Dict, List, Tuple\n",
    "\n",
    "# ---- 1) Signed score function (mean of z-scored UP − mean of z-scored DOWN) ---\n",
    "def score_signed_module(expr: pd.DataFrame,\n",
    "                        up_genes: List[str],\n",
    "                        down_genes: List[str],\n",
    "                        min_genes: int = 10) -> Tuple[pd.Series, Dict[str, int]]:\n",
    "    \"\"\"\n",
    "    expr: genes x samples (index=HGNC symbols, columns=samples)\n",
    "    Returns (scores Series indexed by samples, coverage dict).\n",
    "    \"\"\"\n",
    "    # z-score per gene across samples to equalize scale\n",
    "    Z = expr.apply(lambda x: (x - x.mean()) / (x.std(ddof=0) + 1e-9), axis=1)\n",
    "\n",
    "    up = pd.Index(up_genes).intersection(Z.index)\n",
    "    dn = pd.Index(down_genes).intersection(Z.index)\n",
    "\n",
    "    cov = {\n",
    "        \"up_used\": int(up.size), \"up_total\": int(len(up_genes)),\n",
    "        \"down_used\": int(dn.size), \"down_total\": int(len(down_genes))\n",
    "    }\n",
    "\n",
    "    # If insufficient coverage, return NaNs\n",
    "    if up.size < min_genes or dn.size < min_genes:\n",
    "        return pd.Series(np.nan, index=Z.columns), cov\n",
    "\n",
    "    up_score = Z.loc[up].mean(axis=0)\n",
    "    dn_score = Z.loc[dn].mean(axis=0)\n",
    "    scores = (up_score - dn_score).rename(\"IGE_signed_score\")\n",
    "    return scores, cov\n",
    "\n",
    "# ---- 2) Provide your gene lists (or load from files) --------------------------\n",
    "# If you already defined IGE_UP / IGE_DOWN elsewhere, keep them; otherwise:\n",
    "try:\n",
    "    IGE_UP, IGE_DOWN  # do nothing if they already exist\n",
    "except NameError:\n",
    "    # PLACEHOLDER lists — replace with your curated genes or load from CSV\n",
    "    IGE_UP = [\n",
    "    \"PFN2\",\"SET\",\"LGALS1\",\"PDLIM4\",\"EIF5A\",\"F8A1\",\"BANF1\",\"CTDNEP1\",\"TRAPPC1\",\"AMZ2\",\"PTGES3\",\n",
    "    \"ST13\",\"FTH1\",\"PCBP1\",\"NAA10\",\"ARPC5L\",\"ETFB\",\"CCDC124\",\"SSR2\",\"PGLS\",\"SELENOH\",\"GSTP1\",\n",
    "    \"NDUFB7\",\"AURKAIP1\",\"GCHFR\",\"MYL6\",\"AP2S1\",\"S100A13\",\"C9orf16\",\"KRT8\",\"PRKCSH\",\"CST3\",\n",
    "    \"PET100\",\"DNAJA2\",\"VPS35\",\"VDAC1\",\"MGST3\",\"PRR13\",\"OCIAD2\",\"FUOM\",\"MIA\",\"RPN1\",\"FUCA2\",\n",
    "    \"TMED4\",\"ERGIC3\",\"DDOST\",\"NAXE\",\"SNRPD1\",\"SKP1\",\"CNBP\",\"ATP5MC3\",\"SLC25A5\",\"LSM4\",\n",
    "    \"NDUFAB1\",\"PCBD1\",\"HINT1\",\"ADI1\",\"NENF\",\"MRPL43\",\"VKORC1\",\"EMC4\",\"COA3\",\"NEDD8\",\"CHCHD2\",\n",
    "    \"PRDX5\",\"WDR83OS\",\"NDUFA4\",\"GABARAP\",\"PHPT1\",\"UFC1\",\"MDH1\",\"ATP5F1E\",\"MRPL41\",\"UBL5\",\n",
    "    \"COX5B\",\"ELOB\",\"ATP5ME\",\"UQCRB\",\"SEM1\",\"NDUFB1\",\"COX6C\",\"ATP6V1F\",\"HNRNPA1\",\"HIGD2A\",\n",
    "    \"POLR2I\",\"METTL26\",\"NDUFB4\",\"OST4\",\"C19orf53\",\"RPL36AL\",\"PPIA\",\"COPS9\",\"COX8A\",\"COX5A\",\n",
    "    \"RPL36\",\"RPS15\",\"RPS27\",\"RPS11\",\"FTL\",\"SNHG29\",\"NACA\",\"RPS17\",\"RPL23\",\"RPL39\",\"RPS21\",\n",
    "    \"RPL9\",\"RPL15\",\"RPL34\",\"RPL27A\",\"RPL36A\",\"RPL38\",\"RPS26\",\"RPS14\",\"RPL35\",\"RPL37A\",\n",
    "    \"RPL37\",\"RPL12\",\"RPS29\"\n",
    "]\n",
    "\n",
    "IGE_DOWN = [\n",
    "    \"STN1\",\"NRG4\",\"IQSEC2\",\"IYD\",\"CHD9\",\"APBB1IP\",\"TMEM238\",\"REX1BD\",\"IFI27\",\"CYBA\",\"METRNL\",\n",
    "    \"AKR7A2\",\"SULT1A1\",\"ARHGEF35\",\"AC008397.1\",\"KLK11\",\"DELE1\",\"MISP\",\"FAM234A\",\"CMBL\"\n",
    "]\n",
    "# ---- 3) Build 'cohorts' = [(label, expr_df), ...] ----------------------------\n",
    "# If you have variables like COMPASS_EXPR/PULEO_EXPR/TCGA_EXPR pointing to CSVs:\n",
    "def _load_expr_if_exists(path):\n",
    "    return pd.read_csv(path, index_col=0) if (isinstance(path, str) and Path(path).exists()) else None\n",
    "\n",
    "cohorts = [\n",
    "    (\"TCGA\", expr_tcga),\n",
    "    (\"PULEO\", expr_puleo),\n",
    "]\n",
    "print(f\"[INFO] Loaded cohorts: {[label for label, _ in cohorts]}\")\n",
    "# Try common vars from earlier cells; each should be genes x samples\n",
    "for label_var, path_var in [(\"COMPASS\",\"COMPASS_EXPR\"), (\"PULEO\",\"PULEO_EXPR\"), (\"TCGA\",\"TCGA_EXPR\")]:\n",
    "    if path_var in globals():\n",
    "        expr = _load_expr_if_exists(globals()[path_var])\n",
    "        if expr is not None:\n",
    "            cohorts.append((label_var, expr))\n",
    "\n",
    "# If you prefer to specify manually, uncomment and edit:\n",
    "# cohorts = [\n",
    "#     (\"COMPASS\", pd.read_csv(\"/path/to/COMPASS_expr.csv\", index_col=0)),\n",
    "#     (\"PULEO\",   pd.read_csv(\"/path/to/Puleo_expr.csv\",   index_col=0)),\n",
    "#     (\"TCGA\",    pd.read_csv(\"/path/to/TCGA_expr.csv\",    index_col=0)),\n",
    "# ]\n",
    "\n",
    "if len(cohorts) == 0:\n",
    "    raise ValueError(\"No cohorts loaded. Define COMPASS_EXPR/PULEO_EXPR/TCGA_EXPR paths, or build 'cohorts' manually.\")\n",
    "\n",
    "# ---- 4) Output directory ------------------------------------------------------\n",
    "try:\n",
    "    OUTDIR  # keep if already defined\n",
    "except NameError:\n",
    "    OUTDIR = Path(\"./out_IGE_scores\")\n",
    "OUTDIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# === Per-cohort z-normalization + histograms for IGE signed score =============\n",
    "def zscore_series(s: pd.Series) -> pd.Series:\n",
    "    mu = s.mean()\n",
    "    sd = s.std(ddof=0)\n",
    "    if sd == 0 or np.isnan(sd):\n",
    "        return s * 0  # all zeros if no variation\n",
    "    return (s - mu) / sd\n",
    "\n",
    "for label, expr in cohorts:\n",
    "    # compute (or recompute) the signed score\n",
    "    scores, cov = score_signed_module(expr, IGE_UP, IGE_DOWN, min_genes=10)\n",
    "    raw_path = OUTDIR / f\"{label}_IGE_signed_scores.csv\"\n",
    "    z_path   = OUTDIR / f\"{label}_IGE_signed_scores_Z.csv\"\n",
    "    scores.rename(\"IGE_signed_score\").to_csv(raw_path)\n",
    "\n",
    "    scores_z = zscore_series(scores).rename(\"IGE_signed_score_Z\")\n",
    "    scores_z.to_csv(z_path)\n",
    "\n",
    "    print(f\"✅ {label} saved:\")\n",
    "    print(f\"   - raw scores: {raw_path} (n={scores.shape[0]})\")\n",
    "    print(f\"   - z scores  : {z_path} (mean={scores_z.mean():.3f}, sd={scores_z.std(ddof=0):.3f})\")\n",
    "    print(f\"   Coverage: UP {cov['up_used']}/{cov['up_total']} | DOWN {cov['down_used']}/{cov['down_total']}\")\n",
    "\n",
    "    # --- QC histograms (Matplotlib; no seaborn, no explicit colors) ---\n",
    "    # Raw\n",
    "    plt.figure(figsize=(6,4))\n",
    "    plt.hist(scores.dropna().values, bins=30)\n",
    "    plt.title(f\"{label} IGE signed score (raw)\")\n",
    "    plt.xlabel(\"IGE score\")\n",
    "    plt.ylabel(\"Count\")\n",
    "    plt.tight_layout()\n",
    "    raw_png = OUTDIR / f\"{label}_IGE_signed_scores_hist.png\"\n",
    "    plt.savefig(raw_png, dpi=160)\n",
    "    plt.close()\n",
    "\n",
    "    # Z\n",
    "    plt.figure(figsize=(6,4))\n",
    "    plt.hist(scores_z.dropna().values, bins=30)\n",
    "    plt.title(f\"{label} IGE signed score (Z)\")\n",
    "    plt.xlabel(\"IGE score (Z)\")\n",
    "    plt.ylabel(\"Count\")\n",
    "    plt.tight_layout()\n",
    "    z_png = OUTDIR / f\"{label}_IGE_signed_scores_Z_hist.png\"\n",
    "    plt.savefig(z_png, dpi=160)\n",
    "    plt.close()\n",
    "\n",
    "    print(f\"   - histograms: {raw_png.name}, {z_png.name}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "2993f18c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['sample', 'title', 'source_name_ch1', 'organism_ch1', 'geo_accession']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sample</th>\n",
       "      <th>title</th>\n",
       "      <th>source_name_ch1</th>\n",
       "      <th>organism_ch1</th>\n",
       "      <th>geo_accession</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GSM1843893</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GSM1843894</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GSM1843895</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       sample title source_name_ch1 organism_ch1 geo_accession\n",
       "0  GSM1843893   NaN             NaN          NaN           NaN\n",
       "1  GSM1843894   NaN             NaN          NaN           NaN\n",
       "2  GSM1843895   NaN             NaN          NaN           NaN"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "DESKTOP = Path.home() / \"Desktop\"\n",
    "\n",
    "# Load metadata\n",
    "puleo_meta = pd.read_csv(DESKTOP / \"Puleo_meta.csv\", dtype=str)\n",
    "\n",
    "# Inspect columns to find survival fields\n",
    "print(puleo_meta.columns.tolist()[:30])\n",
    "puleo_meta.head(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "2d286bdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: lifelines in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (0.30.0)\n",
      "Requirement already satisfied: numpy>=1.14.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from lifelines) (1.26.2)\n",
      "Requirement already satisfied: scipy>=1.7.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from lifelines) (1.11.3)\n",
      "Requirement already satisfied: pandas>=2.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from lifelines) (2.3.3)\n",
      "Requirement already satisfied: matplotlib>=3.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from lifelines) (3.10.7)\n",
      "Requirement already satisfied: autograd>=1.5 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from lifelines) (1.8.0)\n",
      "Requirement already satisfied: autograd-gamma>=0.3 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from lifelines) (0.5.0)\n",
      "Requirement already satisfied: formulaic>=0.2.2 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from lifelines) (1.2.1)\n",
      "Requirement already satisfied: interface-meta>=1.2.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from formulaic>=0.2.2->lifelines) (1.3.0)\n",
      "Requirement already satisfied: narwhals>=1.17 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from formulaic>=0.2.2->lifelines) (2.9.0)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from formulaic>=0.2.2->lifelines) (4.8.0)\n",
      "Requirement already satisfied: wrapt>=1.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from formulaic>=0.2.2->lifelines) (1.14.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from matplotlib>=3.0->lifelines) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from matplotlib>=3.0->lifelines) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from matplotlib>=3.0->lifelines) (4.44.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from matplotlib>=3.0->lifelines) (1.4.5)\n",
      "Requirement already satisfied: packaging>=20.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from matplotlib>=3.0->lifelines) (23.2)\n",
      "Requirement already satisfied: pillow>=8 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from matplotlib>=3.0->lifelines) (10.1.0)\n",
      "Requirement already satisfied: pyparsing>=3 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from matplotlib>=3.0->lifelines) (3.1.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from matplotlib>=3.0->lifelines) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from pandas>=2.1->lifelines) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from pandas>=2.1->lifelines) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from python-dateutil>=2.7->matplotlib>=3.0->lifelines) (1.16.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip3.11 install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install lifelines\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "bd8c25e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: matplotlib in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (3.10.7)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from matplotlib) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from matplotlib) (4.44.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from matplotlib) (1.4.5)\n",
      "Requirement already satisfied: numpy>=1.23 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from matplotlib) (1.26.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from matplotlib) (23.2)\n",
      "Requirement already satisfied: pillow>=8 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from matplotlib) (10.1.0)\n",
      "Requirement already satisfied: pyparsing>=3 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from matplotlib) (3.1.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip3.11 install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install --upgrade matplotlib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "9bf1713d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TCGA] Loading expression from: PAAD_RSEM_genes_normalized_CLEAN.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/mh/r2nrb73509z0t_wjbx9r5fg00000gn/T/ipykernel_92012/834756978.py:68: FutureWarning: DataFrame.groupby with axis=1 is deprecated. Do `frame.T.groupby(...)` without axis instead.\n",
      "  df = df.groupby(df.columns, axis=1).mean(numeric_only=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TCGA] patient-level shape (genes x patients): (20502, 178)\n",
      "[COVERAGE] UP 102/118 | DOWN 13/20\n",
      "[CLIN] rows with OS: 184\n",
      "[MERGE] N with score+OS: 177\n"
     ]
    }
   ],
   "source": [
    "# --- TCGA PAAD survival with IGE signed score (robust loader) ---\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# lifelines (install once if needed):\n",
    "# %pip install lifelines\n",
    "from lifelines import KaplanMeierFitter\n",
    "from lifelines.statistics import logrank_test\n",
    "\n",
    "# ----------------- INPUTS (edit these two if your paths differ) -----------------\n",
    "DESKTOP = Path.home() / \"Desktop\"\n",
    "\n",
    "# Expression: prefer CLEAN if you have it; else the Level_3 file\n",
    "expr_paths = [\n",
    "    DESKTOP / \"PAAD_RSEM_genes_normalized_CLEAN.csv\",\n",
    "    DESKTOP / \"PAAD.rnaseqv2__illuminahiseq_rnaseqv2__unc_edu__Level_3__RSEM_genes_normalized__data.data.csv\",\n",
    "]\n",
    "clin_path = DESKTOP / \"paad_tcga_pan_can_atlas_2018_clinical_data.csv\"\n",
    "\n",
    "# Your module genes (from your message)\n",
    "IGE_UP = [\n",
    "\"PFN2\",\"SET\",\"LGALS1\",\"PDLIM4\",\"EIF5A\",\"F8A1\",\"BANF1\",\"CTDNEP1\",\"TRAPPC1\",\"AMZ2\",\"PTGES3\",\"ST13\",\"FTH1\",\"PCBP1\",\n",
    "\"NAA10\",\"ARPC5L\",\"ETFB\",\"CCDC124\",\"SSR2\",\"PGLS\",\"SELENOH\",\"GSTP1\",\"NDUFB7\",\"AURKAIP1\",\"GCHFR\",\"MYL6\",\"AP2S1\",\n",
    "\"S100A13\",\"C9orf16\",\"KRT8\",\"PRKCSH\",\"CST3\",\"PET100\",\"DNAJA2\",\"VPS35\",\"VDAC1\",\"MGST3\",\"PRR13\",\"OCIAD2\",\"FUOM\",\"MIA\",\n",
    "\"RPN1\",\"FUCA2\",\"TMED4\",\"ERGIC3\",\"DDOST\",\"NAXE\",\"SNRPD1\",\"SKP1\",\"CNBP\",\"ATP5MC3\",\"SLC25A5\",\"LSM4\",\"NDUFAB1\",\"PCBD1\",\n",
    "\"HINT1\",\"ADI1\",\"NENF\",\"MRPL43\",\"VKORC1\",\"EMC4\",\"COA3\",\"NEDD8\",\"CHCHD2\",\"PRDX5\",\"WDR83OS\",\"NDUFA4\",\"GABARAP\",\"PHPT1\",\n",
    "\"UFC1\",\"MDH1\",\"ATP5F1E\",\"MRPL41\",\"UBL5\",\"COX5B\",\"ELOB\",\"ATP5ME\",\"UQCRB\",\"SEM1\",\"NDUFB1\",\"COX6C\",\"ATP6V1F\",\"HNRNPA1\",\n",
    "\"HIGD2A\",\"POLR2I\",\"METTL26\",\"NDUFB4\",\"OST4\",\"C19orf53\",\"RPL36AL\",\"PPIA\",\"COPS9\",\"COX8A\",\"COX5A\",\"RPL36\",\"RPS15\",\n",
    "\"RPS27\",\"RPS11\",\"FTL\",\"SNHG29\",\"NACA\",\"RPS17\",\"RPL23\",\"RPL39\",\"RPS21\",\"RPL9\",\"RPL15\",\"RPL34\",\"RPL27A\",\"RPL36A\",\n",
    "\"RPL38\",\"RPS26\",\"RPS14\",\"RPL35\",\"RPL37A\",\"RPL37\",\"RPL12\",\"RPS29\"\n",
    "]\n",
    "IGE_DOWN = [\"STN1\",\"NRG4\",\"IQSEC2\",\"IYD\",\"CHD9\",\"APBB1IP\",\"TMEM238\",\"REX1BD\",\"IFI27\",\"CYBA\",\"METRNL\",\"AKR7A2\",\n",
    "            \"SULT1A1\",\"ARHGEF35\",\"AC008397.1\",\"KLK11\",\"DELE1\",\"MISP\",\"FAM234A\",\"CMBL\"]\n",
    "\n",
    "# ----------------- helper functions -----------------\n",
    "def load_tcga_expr(expr_paths):\n",
    "    path = next((p for p in expr_paths if p.exists()), None)\n",
    "    if path is None:\n",
    "        raise FileNotFoundError(\"No TCGA PAAD expression file found on Desktop.\")\n",
    "    print(f\"[TCGA] Loading expression from: {path.name}\")\n",
    "\n",
    "    df = pd.read_csv(path, low_memory=False)\n",
    "    # Heuristics for gene column name\n",
    "    gene_col = None\n",
    "    for c in [\"Hugo_Symbol\", \"gene\", \"Gene\", \"GeneSymbol\", \"gene_name\", df.columns[0]]:\n",
    "        if c in df.columns:\n",
    "            gene_col = c\n",
    "            break\n",
    "    df = df.rename(columns={gene_col: \"Gene\"})\n",
    "    # Split \"A1BG|1\" -> \"A1BG\"\n",
    "    df[\"Gene\"] = df[\"Gene\"].astype(str).str.split(\"|\").str[0]\n",
    "    df = df.set_index(\"Gene\")\n",
    "\n",
    "    # Coerce all values to numeric (cell-wise), keep shape\n",
    "    df = df.apply(pd.to_numeric, errors=\"coerce\")\n",
    "    # Drop rows with no numeric values at all\n",
    "    df = df.dropna(how=\"all\", axis=0)\n",
    "    # Keep columns that have at least one numeric value\n",
    "    df = df.dropna(how=\"all\", axis=1)\n",
    "\n",
    "    # Collapse aliquots to patientId (first 12 chars)\n",
    "    new_cols = pd.Index([str(c)[:12] for c in df.columns], name=\"patientId\")\n",
    "    df.columns = new_cols\n",
    "    # Average duplicated patientId columns\n",
    "    df = df.groupby(df.columns, axis=1).mean(numeric_only=True)\n",
    "\n",
    "    print(f\"[TCGA] patient-level shape (genes x patients): {df.shape}\")\n",
    "    return df\n",
    "\n",
    "def score_signed_module(expr, up_genes, down_genes, min_genes=10):\n",
    "    # z-score per gene across patients\n",
    "    Z = expr.apply(lambda x: (x - x.mean()) / (x.std(ddof=0) + 1e-9), axis=1)\n",
    "\n",
    "    up = pd.Index(up_genes).intersection(Z.index)\n",
    "    dn = pd.Index(down_genes).intersection(Z.index)\n",
    "    cov = {\"up_used\": int(up.size), \"up_total\": len(up_genes),\n",
    "           \"down_used\": int(dn.size), \"down_total\": len(down_genes)}\n",
    "    if up.size < min_genes or dn.size < min_genes:\n",
    "        return pd.Series(np.nan, index=Z.columns, name=\"IGE_signed_score\"), cov\n",
    "\n",
    "    score = (Z.loc[up].mean(axis=0) - Z.loc[dn].mean(axis=0)).rename(\"IGE_signed_score\")\n",
    "    return score, cov\n",
    "\n",
    "def load_tcga_clin_pan_can(path):\n",
    "    if not path.exists():\n",
    "        raise FileNotFoundError(\"PanCan clinical file not found on Desktop.\")\n",
    "    clin = pd.read_csv(path)\n",
    "    # keep columns we need\n",
    "    need = [\"patientId\",\"OS_MONTHS\",\"OS_STATUS\"]\n",
    "    missing = [c for c in need if c not in clin.columns]\n",
    "    if missing:\n",
    "        raise ValueError(f\"Missing columns in clinical file: {missing}\")\n",
    "    clin[\"patientId\"] = clin[\"patientId\"].astype(str).str[:12]\n",
    "    # OS_STATUS: \"DECEASED\" vs \"LIVING\"\n",
    "    status = clin[\"OS_STATUS\"].astype(str).str.upper().str.contains(\"DECEASED\")\n",
    "    out = pd.DataFrame({\n",
    "        \"patientId\": clin[\"patientId\"],\n",
    "        \"OS_time_months\": pd.to_numeric(clin[\"OS_MONTHS\"], errors=\"coerce\"),\n",
    "        \"OS_event\": status.astype(float)  # 1.0 died, 0.0 alive\n",
    "    }).dropna(subset=[\"OS_time_months\",\"OS_event\"])\n",
    "    out = out.drop_duplicates(subset=[\"patientId\"]).set_index(\"patientId\")\n",
    "    print(f\"[CLIN] rows with OS: {out.shape[0]}\")\n",
    "    return out\n",
    "\n",
    "def zscore_series(s):\n",
    "    mu, sd = s.mean(), s.std(ddof=0)\n",
    "    if sd == 0 or np.isnan(sd):\n",
    "        return s*0\n",
    "    return (s - mu) / sd\n",
    "\n",
    "# ----------------- run -----------------\n",
    "expr_tcga = load_tcga_expr(expr_paths)\n",
    "scores, cov = score_signed_module(expr_tcga, IGE_UP, IGE_DOWN, min_genes=10)\n",
    "print(f\"[COVERAGE] UP {cov['up_used']}/{cov['up_total']} | DOWN {cov['down_used']}/{cov['down_total']}\")\n",
    "\n",
    "clin = load_tcga_clin_pan_can(clin_path)\n",
    "\n",
    "# align\n",
    "df = pd.concat([scores.rename(\"IGE\"), clin], axis=1, join=\"inner\").dropna(subset=[\"IGE\",\"OS_time_months\",\"OS_event\"])\n",
    "print(f\"[MERGE] N with score+OS: {df.shape[0]}\")\n",
    "if df.shape[0] < 10:\n",
    "    print(\"Not enough cases for KM (need >=10). Check alignment/coverage.\")\n",
    "else:\n",
    "    # median split\n",
    "    med = df[\"IGE\"].median()\n",
    "    df[\"group\"] = np.where(df[\"IGE\"] >= med, \"High IGE\", \"Low IGE\")\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "54131e3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[KM] N after NA-drop: 177 (High=89, Low=88)\n",
      "[SAVE] KM figure -> out_tcga_ige_survival/TCGA_IGE_KM.png\n",
      "[LOG-RANK] p = 0.9304  (chi2=0.008, dof=1)\n",
      "[SAVE] KM input table -> out_tcga_ige_survival/TCGA_IGE_scores_OS_group.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/mh/r2nrb73509z0t_wjbx9r5fg00000gn/T/ipykernel_92012/1049815803.py:51: UserWarning: FigureCanvasAgg is non-interactive, and thus cannot be shown\n",
      "  plt.show()\n"
     ]
    }
   ],
   "source": [
    "# --- KM plot without pandas' plotting backend ---\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from lifelines import KaplanMeierFitter\n",
    "from lifelines.statistics import logrank_test\n",
    "from pathlib import Path\n",
    "\n",
    "OUTDIR = Path(\"out_tcga_ige_survival\")\n",
    "OUTDIR.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "# df must already exist with columns: OS_time_months (numeric), OS_event (0/1), group (\"High IGE\"/\"Low IGE\")\n",
    "assert {\"OS_time_months\",\"OS_event\",\"group\"}.issubset(df.columns), df.columns.tolist()\n",
    "\n",
    "# sanity: ensure numeric + drop NA\n",
    "df = df.copy()\n",
    "df[\"OS_time_months\"] = pd.to_numeric(df[\"OS_time_months\"], errors=\"coerce\")\n",
    "df[\"OS_event\"] = pd.to_numeric(df[\"OS_event\"], errors=\"coerce\")\n",
    "df = df.dropna(subset=[\"OS_time_months\",\"OS_event\"])\n",
    "print(f\"[KM] N after NA-drop: {df.shape[0]} (High={sum(df['group']=='High IGE')}, Low={sum(df['group']=='Low IGE')})\")\n",
    "\n",
    "km = KaplanMeierFitter()\n",
    "plt.figure(figsize=(6.5,5))\n",
    "\n",
    "curves = {}\n",
    "for grp in [\"High IGE\",\"Low IGE\"]:\n",
    "    sub = df[df[\"group\"] == grp]\n",
    "    if sub.empty:\n",
    "        print(f\"[WARN] No samples in group: {grp}\")\n",
    "        continue\n",
    "    km.fit(durations=sub[\"OS_time_months\"], event_observed=sub[\"OS_event\"], label=grp)\n",
    "    # step survival curve\n",
    "    sf = km.survival_function_\n",
    "    t = sf.index.values\n",
    "    y = sf.iloc[:, 0].values\n",
    "    line = plt.step(t, y, where=\"post\", label=grp)[0]\n",
    "    # optional CI band\n",
    "    ci = km.confidence_interval_\n",
    "    lo = ci.iloc[:, 0].values\n",
    "    hi = ci.iloc[:, 1].values\n",
    "    plt.fill_between(t, lo, hi, step=\"post\", alpha=0.20)\n",
    "    curves[grp] = (t, y)\n",
    "\n",
    "plt.xlabel(\"Overall survival (months)\")\n",
    "plt.ylabel(\"Survival probability\")\n",
    "plt.title(\"TCGA-PAAD: IGE signed score (median split)\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "\n",
    "fig_path = OUTDIR / \"TCGA_IGE_KM.png\"\n",
    "plt.savefig(fig_path, dpi=160)\n",
    "plt.show()\n",
    "print(f\"[SAVE] KM figure -> {fig_path}\")\n",
    "\n",
    "# Log-rank test\n",
    "hi = df[df[\"group\"]==\"High IGE\"]\n",
    "lo = df[df[\"group\"]==\"Low IGE\"]\n",
    "if (len(hi) > 0) and (len(lo) > 0):\n",
    "    res = logrank_test(hi[\"OS_time_months\"], lo[\"OS_time_months\"],\n",
    "                       event_observed_A=hi[\"OS_event\"], event_observed_B=lo[\"OS_event\"])\n",
    "    print(f\"[LOG-RANK] p = {res.p_value:.4g}  (chi2={res.test_statistic:.3f}, dof=1)\")\n",
    "else:\n",
    "    print(\"[LOG-RANK] Skipped (one group has 0 samples).\")\n",
    "\n",
    "# save the merged table you just analyzed\n",
    "csv_path = OUTDIR / \"TCGA_IGE_scores_OS_group.csv\"\n",
    "df.to_csv(csv_path)\n",
    "print(f\"[SAVE] KM input table -> {csv_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "eb49c118",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from lifelines import KaplanMeierFitter\n",
    "from lifelines.statistics import logrank_test\n",
    "from pathlib import Path\n",
    "\n",
    "# --- GLOBAL STYLE (do this once) ---\n",
    "plt.rcParams.update({\n",
    "    \"font.size\": 11,           # base font size\n",
    "    \"axes.titlesize\": 13,      # panel title\n",
    "    \"axes.labelsize\": 12,      # x/y labels\n",
    "    \"xtick.labelsize\": 10,\n",
    "    \"ytick.labelsize\": 10,\n",
    "    \"legend.fontsize\": 10,\n",
    "})\n",
    "\n",
    "def plot_km_module(df, group_col, time_col, event_col,\n",
    "                   high_label, low_label,\n",
    "                   panel_title, outdir, filename,\n",
    "                   panel_letter=None):\n",
    "    \"\"\"\n",
    "    df: DataFrame with time, event, group columns\n",
    "    group_col: e.g. \"group\"\n",
    "    time_col:  e.g. \"OS_time_months\"\n",
    "    event_col: e.g. \"OS_event\"\n",
    "    high_label/low_label: strings used in group_col\n",
    "    panel_title: title for this KM panel\n",
    "    outdir: Path or str\n",
    "    filename: e.g. \"TCGA_IGE_KM.png\"\n",
    "    panel_letter: optional (\"A\", \"B\", \"C\", \"D\") to draw in upper-left\n",
    "    \"\"\"\n",
    "\n",
    "    outdir = Path(outdir)\n",
    "    outdir.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "    df = df.copy()\n",
    "    df[time_col] = pd.to_numeric(df[time_col], errors=\"coerce\")\n",
    "    df[event_col] = pd.to_numeric(df[event_col], errors=\"coerce\")\n",
    "    df = df.dropna(subset=[time_col, event_col])\n",
    "\n",
    "    km = KaplanMeierFitter()\n",
    "    plt.figure(figsize=(4.0, 3.6))  # same size for all panels\n",
    "\n",
    "    colors = {\n",
    "        high_label: \"#1f77b4\",   # blue\n",
    "        low_label:  \"#ff7f0e\",   # orange\n",
    "    }\n",
    "\n",
    "    for grp in [high_label, low_label]:\n",
    "        sub = df[df[group_col] == grp]\n",
    "        if sub.empty:\n",
    "            continue\n",
    "        km.fit(durations=sub[time_col],\n",
    "               event_observed=sub[event_col],\n",
    "               label=grp)\n",
    "        sf = km.survival_function_\n",
    "        t = sf.index.values\n",
    "        y = sf.iloc[:, 0].values\n",
    "\n",
    "        line = plt.step(\n",
    "            t, y, where=\"post\",\n",
    "            label=grp,\n",
    "            linewidth=1.8,\n",
    "            color=colors.get(grp, None)\n",
    "        )[0]\n",
    "\n",
    "        # CI band\n",
    "        ci = km.confidence_interval_\n",
    "        lo = ci.iloc[:, 0].values\n",
    "        hi = ci.iloc[:, 1].values\n",
    "        plt.fill_between(\n",
    "            t, lo, hi,\n",
    "            step=\"post\",\n",
    "            alpha=0.20,\n",
    "            color=line.get_color()\n",
    "        )\n",
    "\n",
    "    plt.xlabel(\"Overall survival (months)\")\n",
    "    plt.ylabel(\"Survival probability\")\n",
    "    plt.title(panel_title)\n",
    "    plt.legend(frameon=False, loc=\"best\")\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Optional panel letter in upper-left\n",
    "    if panel_letter is not None:\n",
    "        plt.text(\n",
    "            0.02, 0.98, panel_letter,\n",
    "            transform=plt.gca().transAxes,\n",
    "            ha=\"left\", va=\"top\",\n",
    "            fontsize=14, fontweight=\"bold\"\n",
    "        )\n",
    "\n",
    "    fig_path = outdir / filename\n",
    "    plt.savefig(fig_path, dpi=300)\n",
    "    plt.close()\n",
    "    print(f\"[SAVE] KM figure -> {fig_path}\")\n",
    "\n",
    "    # Log-rank test\n",
    "    hi = df[df[group_col] == high_label]\n",
    "    lo = df[df[group_col] == low_label]\n",
    "    if (len(hi) > 0) and (len(lo) > 0):\n",
    "        res = logrank_test(\n",
    "            hi[time_col], lo[time_col],\n",
    "            event_observed_A=hi[event_col],\n",
    "            event_observed_B=lo[event_col]\n",
    "        )\n",
    "        print(\n",
    "            f\"[LOG-RANK {panel_title}] \"\n",
    "            f\"p = {res.p_value:.4g} \"\n",
    "            f\"(chi2={res.test_statistic:.3f})\"\n",
    "        )\n",
    "\n",
    "    # Optional: save the table used\n",
    "    df.to_csv(outdir / (filename.replace(\".png\", \"_KM_input.csv\")),\n",
    "              index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "ecc1ceff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['TCGA-2J-AAB1-01A-11R-A41B-07',\n",
       " 'TCGA-2J-AAB4-01A-12R-A41B-07',\n",
       " 'TCGA-2J-AAB6-01A-11R-A41B-07',\n",
       " 'TCGA-2J-AAB8-01A-12R-A41B-07',\n",
       " 'TCGA-2J-AAB9-01A-11R-A41B-07',\n",
       " 'TCGA-2J-AABA-01A-21R-A41B-07',\n",
       " 'TCGA-2J-AABE-01A-12R-A41B-07',\n",
       " 'TCGA-2J-AABF-01A-31R-A41B-07',\n",
       " 'TCGA-2J-AABH-01A-21R-A41B-07',\n",
       " 'TCGA-2J-AABI-01A-12R-A41B-07',\n",
       " 'TCGA-2J-AABK-01A-31R-A41B-07',\n",
       " 'TCGA-2J-AABO-01A-21R-A41B-07',\n",
       " 'TCGA-2J-AABP-01A-11R-A41B-07',\n",
       " 'TCGA-2J-AABR-01A-11R-A41B-07',\n",
       " 'TCGA-2J-AABT-01A-11R-A41B-07',\n",
       " 'TCGA-2J-AABU-01A-11R-A41B-07',\n",
       " 'TCGA-2J-AABV-01A-12R-A41B-07',\n",
       " 'TCGA-2L-AAQA-01A-21R-A38C-07',\n",
       " 'TCGA-2L-AAQE-01A-11R-A39D-07',\n",
       " 'TCGA-2L-AAQI-01A-12R-A39D-07',\n",
       " 'TCGA-2L-AAQJ-01A-12R-A39D-07',\n",
       " 'TCGA-2L-AAQL-01A-11R-A38C-07',\n",
       " 'TCGA-2L-AAQM-01A-11R-A39D-07',\n",
       " 'TCGA-3A-A9I5-01A-11R-A38C-07',\n",
       " 'TCGA-3A-A9I7-01A-21R-A38C-07',\n",
       " 'TCGA-3A-A9I9-01A-11R-A38C-07',\n",
       " 'TCGA-3A-A9IB-01A-21R-A39D-07',\n",
       " 'TCGA-3A-A9IC-01A-11R-A38C-07',\n",
       " 'TCGA-3A-A9IH-01A-12R-A39D-07',\n",
       " 'TCGA-3A-A9IJ-01A-11R-A39D-07',\n",
       " 'TCGA-3A-A9IL-01A-11R-A38C-07',\n",
       " 'TCGA-3A-A9IN-01A-11R-A39D-07',\n",
       " 'TCGA-3A-A9IO-01A-11R-A38C-07',\n",
       " 'TCGA-3A-A9IR-01A-11R-A38C-07',\n",
       " 'TCGA-3A-A9IS-01A-21R-A39D-07',\n",
       " 'TCGA-3A-A9IU-01A-11R-A39D-07',\n",
       " 'TCGA-3A-A9IV-01A-11R-A41B-07',\n",
       " 'TCGA-3A-A9IX-01A-11R-A41B-07',\n",
       " 'TCGA-3A-A9IZ-01A-12R-A41B-07',\n",
       " 'TCGA-3A-A9J0-01A-11R-A41B-07',\n",
       " 'TCGA-3E-AAAY-01A-11R-A38C-07',\n",
       " 'TCGA-3E-AAAZ-01A-11R-A38C-07',\n",
       " 'TCGA-F2-6879-01A-11R-2156-07',\n",
       " 'TCGA-F2-6880-01A-11R-2156-07',\n",
       " 'TCGA-F2-7273-01A-11R-2156-07',\n",
       " 'TCGA-F2-7276-01A-11R-2156-07',\n",
       " 'TCGA-F2-A44G-01A-11R-A26U-07',\n",
       " 'TCGA-F2-A44H-01A-11R-A26U-07',\n",
       " 'TCGA-F2-A7TX-01A-33R-A38C-07',\n",
       " 'TCGA-F2-A8YN-01A-11R-A37L-07',\n",
       " 'TCGA-FB-A4P5-01A-11R-A26U-07',\n",
       " 'TCGA-FB-A4P6-01A-12R-A26U-07',\n",
       " 'TCGA-FB-A545-01A-11R-A26U-07',\n",
       " 'TCGA-FB-A5VM-01A-11R-A32O-07',\n",
       " 'TCGA-FB-A78T-01A-12R-A32O-07',\n",
       " 'TCGA-FB-A7DR-01A-21R-A33R-07',\n",
       " 'TCGA-FB-AAPP-01A-12R-A41B-07',\n",
       " 'TCGA-FB-AAPQ-01A-11R-A41B-07',\n",
       " 'TCGA-FB-AAPS-01A-12R-A39D-07',\n",
       " 'TCGA-FB-AAPU-01A-31R-A41B-07',\n",
       " 'TCGA-FB-AAPY-01A-11R-A41B-07',\n",
       " 'TCGA-FB-AAPZ-01A-11R-A41B-07',\n",
       " 'TCGA-FB-AAQ0-01A-31R-A41B-07',\n",
       " 'TCGA-FB-AAQ1-01A-12R-A41B-07',\n",
       " 'TCGA-FB-AAQ2-01A-31R-A41B-07',\n",
       " 'TCGA-FB-AAQ3-01A-11R-A41B-07',\n",
       " 'TCGA-FB-AAQ6-01A-11R-A41B-07',\n",
       " 'TCGA-H6-8124-11A-01R-2404-07',\n",
       " 'TCGA-H6-8124-01A-11R-2404-07',\n",
       " 'TCGA-H6-A45N-11A-12R-A26U-07',\n",
       " 'TCGA-H6-A45N-01A-11R-A26U-07',\n",
       " 'TCGA-H8-A6C1-01A-11R-A32O-07',\n",
       " 'TCGA-HV-A5A3-11A-11R-A26U-07',\n",
       " 'TCGA-HV-A5A3-01A-11R-A26U-07',\n",
       " 'TCGA-HV-A5A4-01A-11R-A26U-07',\n",
       " 'TCGA-HV-A5A5-01A-11R-A26U-07',\n",
       " 'TCGA-HV-A5A6-01A-11R-A26U-07',\n",
       " 'TCGA-HV-A7OL-01A-11R-A33R-07',\n",
       " 'TCGA-HV-A7OP-01A-11R-A33R-07',\n",
       " 'TCGA-HV-AA8V-01A-11R-A41B-07',\n",
       " 'TCGA-HV-AA8X-01A-11R-A39D-07',\n",
       " 'TCGA-HZ-7289-01A-11R-2156-07',\n",
       " 'TCGA-HZ-7918-01A-11R-2156-07',\n",
       " 'TCGA-HZ-7919-01A-11R-2156-07',\n",
       " 'TCGA-HZ-7920-01A-11R-2204-07',\n",
       " 'TCGA-HZ-7922-01A-11R-2156-07',\n",
       " 'TCGA-HZ-7923-01A-12R-2156-07',\n",
       " 'TCGA-HZ-7924-01A-11R-2156-07',\n",
       " 'TCGA-HZ-7925-01A-11R-2156-07',\n",
       " 'TCGA-HZ-7926-01A-11R-2156-07',\n",
       " 'TCGA-HZ-8001-01A-11R-2204-07',\n",
       " 'TCGA-HZ-8002-01A-11R-2204-07',\n",
       " 'TCGA-HZ-8003-01A-21R-2204-07',\n",
       " 'TCGA-HZ-8005-01A-11R-2204-07',\n",
       " 'TCGA-HZ-8315-01A-11R-2404-07',\n",
       " 'TCGA-HZ-8317-01A-11R-2404-07',\n",
       " 'TCGA-HZ-8519-01A-11R-2404-07',\n",
       " 'TCGA-HZ-8636-01A-21R-2404-07',\n",
       " 'TCGA-HZ-8637-01A-11R-2404-07',\n",
       " 'TCGA-HZ-8638-01A-11R-2404-07',\n",
       " 'TCGA-HZ-A49G-01A-11R-A26U-07',\n",
       " 'TCGA-HZ-A49H-01A-11R-A26U-07',\n",
       " 'TCGA-HZ-A49I-01A-12R-A26U-07',\n",
       " 'TCGA-HZ-A4BH-01A-11R-A26U-07',\n",
       " 'TCGA-HZ-A4BK-01A-11R-A26U-07',\n",
       " 'TCGA-HZ-A77O-01A-11R-A33R-07',\n",
       " 'TCGA-HZ-A77P-01A-11R-A33R-07',\n",
       " 'TCGA-HZ-A77Q-01A-11R-A36G-07',\n",
       " 'TCGA-HZ-A8P0-01A-11R-A36G-07',\n",
       " 'TCGA-HZ-A8P1-01A-11R-A37L-07',\n",
       " 'TCGA-HZ-A9TJ-06A-11R-A41B-07',\n",
       " 'TCGA-HZ-A9TJ-01A-11R-A41I-07',\n",
       " 'TCGA-IB-7644-01A-11R-2156-07',\n",
       " 'TCGA-IB-7645-01A-22R-2204-07',\n",
       " 'TCGA-IB-7646-01A-11R-2156-07',\n",
       " 'TCGA-IB-7647-01A-11R-2156-07',\n",
       " 'TCGA-IB-7649-01A-11R-2156-07',\n",
       " 'TCGA-IB-7651-01A-11R-2156-07',\n",
       " 'TCGA-IB-7652-01A-11R-2156-07',\n",
       " 'TCGA-IB-7654-01A-11R-2156-07',\n",
       " 'TCGA-IB-7885-01A-11R-2156-07',\n",
       " 'TCGA-IB-7886-01A-11R-2156-07',\n",
       " 'TCGA-IB-7887-01A-11R-2156-07',\n",
       " 'TCGA-IB-7888-01A-11R-2156-07',\n",
       " 'TCGA-IB-7889-01A-11R-2156-07',\n",
       " 'TCGA-IB-7890-01A-12R-2204-07',\n",
       " 'TCGA-IB-7891-01A-11R-2204-07',\n",
       " 'TCGA-IB-7893-01A-11R-2204-07',\n",
       " 'TCGA-IB-7897-01A-21R-2204-07',\n",
       " 'TCGA-IB-8126-01A-11R-2404-07',\n",
       " 'TCGA-IB-8127-01A-11R-2404-07',\n",
       " 'TCGA-IB-A5SO-01A-11R-A32O-07',\n",
       " 'TCGA-IB-A5SP-01A-11R-A32O-07',\n",
       " 'TCGA-IB-A5SQ-01A-11R-A32O-07',\n",
       " 'TCGA-IB-A5SS-01A-11R-A32O-07',\n",
       " 'TCGA-IB-A5ST-01A-11R-A32O-07',\n",
       " 'TCGA-IB-A6UF-01A-23R-A33R-07',\n",
       " 'TCGA-IB-A6UG-01A-32R-A33R-07',\n",
       " 'TCGA-IB-A7LX-01A-12R-A36G-07',\n",
       " 'TCGA-IB-A7M4-01A-11R-A36G-07',\n",
       " 'TCGA-IB-AAUM-01A-11R-A37L-07',\n",
       " 'TCGA-IB-AAUN-01A-12R-A38C-07',\n",
       " 'TCGA-IB-AAUO-01A-12R-A38C-07',\n",
       " 'TCGA-IB-AAUP-01A-11R-A37L-07',\n",
       " 'TCGA-IB-AAUQ-01A-22R-A41I-07',\n",
       " 'TCGA-IB-AAUR-01A-21R-A38C-07',\n",
       " 'TCGA-IB-AAUS-01A-12R-A38C-07',\n",
       " 'TCGA-IB-AAUT-01A-11R-A37L-07',\n",
       " 'TCGA-IB-AAUU-01A-11R-A37L-07',\n",
       " 'TCGA-IB-AAUV-01A-11R-A38C-07',\n",
       " 'TCGA-IB-AAUW-01A-12R-A38C-07',\n",
       " 'TCGA-L1-A7W4-01A-12R-A36G-07',\n",
       " 'TCGA-LB-A7SX-01A-11R-A33R-07',\n",
       " 'TCGA-LB-A8F3-01A-11R-A36G-07',\n",
       " 'TCGA-LB-A9Q5-01A-11R-A39D-07',\n",
       " 'TCGA-M8-A5N4-01A-11R-A26U-07',\n",
       " 'TCGA-OE-A75W-01A-12R-A32O-07',\n",
       " 'TCGA-PZ-A5RE-01A-11R-A32O-07',\n",
       " 'TCGA-Q3-A5QY-01A-12R-A32O-07',\n",
       " 'TCGA-Q3-AA2A-01A-11R-A37L-07',\n",
       " 'TCGA-RB-A7B8-01A-12R-A33R-07',\n",
       " 'TCGA-RB-AA9M-01A-11R-A39D-07',\n",
       " 'TCGA-RL-AAAS-01A-32R-A39D-07',\n",
       " 'TCGA-S4-A8RM-01A-11R-A37L-07',\n",
       " 'TCGA-S4-A8RO-01A-12R-A37L-07',\n",
       " 'TCGA-S4-A8RP-01A-11R-A36G-07',\n",
       " 'TCGA-US-A774-01A-21R-A32O-07',\n",
       " 'TCGA-US-A776-01A-13R-A33R-07',\n",
       " 'TCGA-US-A779-01A-11R-A32O-07',\n",
       " 'TCGA-US-A77E-01A-11R-A32O-07',\n",
       " 'TCGA-US-A77G-01A-11R-A32O-07',\n",
       " 'TCGA-US-A77J-01A-11R-A32O-07',\n",
       " 'TCGA-XD-AAUG-01A-61R-A41B-07',\n",
       " 'TCGA-XD-AAUH-01A-42R-A41B-07',\n",
       " 'TCGA-XD-AAUI-01A-42R-A41B-07',\n",
       " 'TCGA-XD-AAUL-01A-21R-A39D-07',\n",
       " 'TCGA-XN-A8T3-01A-11R-A36G-07',\n",
       " 'TCGA-XN-A8T5-01A-12R-A36G-07',\n",
       " 'TCGA-YB-A89D-11A-11R-A36G-07',\n",
       " 'TCGA-YB-A89D-01A-12R-A36G-07',\n",
       " 'TCGA-YH-A8SY-01A-11R-A37L-07',\n",
       " 'TCGA-YY-A8LH-01A-11R-A36G-07',\n",
       " 'TCGA-Z5-AAPL-01A-12R-A41B-07']"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tcga.columns.tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "399bd818",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'IGE_score'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pandas/core/indexes/base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3811\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3812\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32mpandas/_libs/index.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/index.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7088\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7096\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'IGE_score'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[106], line 15\u001b[0m\n\u001b[1;32m      8\u001b[0m     df_mod[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgroup\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mwhere(\n\u001b[1;32m      9\u001b[0m         df_mod[module_col] \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m median,\n\u001b[1;32m     10\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHigh \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodule_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     11\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLow \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodule_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     12\u001b[0m     )\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m df_mod\n\u001b[0;32m---> 15\u001b[0m df_ige \u001b[38;5;241m=\u001b[39m \u001b[43mmake_module_df\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf_tcga\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mIGE_score\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mIGE\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     16\u001b[0m df_sat \u001b[38;5;241m=\u001b[39m make_module_df(df_tcga, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSAT_score\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSAT\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     17\u001b[0m df_il2 \u001b[38;5;241m=\u001b[39m make_module_df(df_tcga, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIL2_score\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIL2\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[106], line 7\u001b[0m, in \u001b[0;36mmake_module_df\u001b[0;34m(df, module_col, module_name)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmake_module_df\u001b[39m(df, module_col, module_name):\n\u001b[1;32m      6\u001b[0m     df_mod \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[0;32m----> 7\u001b[0m     median \u001b[38;5;241m=\u001b[39m \u001b[43mdf_mod\u001b[49m\u001b[43m[\u001b[49m\u001b[43mmodule_col\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mmedian()\n\u001b[1;32m      8\u001b[0m     df_mod[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgroup\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mwhere(\n\u001b[1;32m      9\u001b[0m         df_mod[module_col] \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m median,\n\u001b[1;32m     10\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHigh \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodule_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     11\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLow \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodule_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     12\u001b[0m     )\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m df_mod\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pandas/core/frame.py:4113\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   4112\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 4113\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4114\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   4115\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pandas/core/indexes/base.py:3819\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3814\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[1;32m   3815\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[1;32m   3816\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[1;32m   3817\u001b[0m     ):\n\u001b[1;32m   3818\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[0;32m-> 3819\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3820\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3821\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3822\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3823\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3824\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'IGE_score'"
     ]
    }
   ],
   "source": [
    "# df_tcga must contain:\n",
    "# OS_time_months, OS_event, IGE_score, SAT_score, IL2_score, MPC_score\n",
    "\n",
    "# Helper to create High/Low split\n",
    "def make_module_df(df, module_col, module_name):\n",
    "    df_mod = df.copy()\n",
    "    median = df_mod[module_col].median()\n",
    "    df_mod[\"group\"] = np.where(\n",
    "        df_mod[module_col] >= median,\n",
    "        f\"High {module_name}\",\n",
    "        f\"Low {module_name}\"\n",
    "    )\n",
    "    return df_mod\n",
    "\n",
    "df_ige = make_module_df(df_tcga, \"IGE_score\", \"IGE\")\n",
    "df_sat = make_module_df(df_tcga, \"SAT_score\", \"SAT\")\n",
    "df_il2 = make_module_df(df_tcga, \"IL2_score\", \"IL2\")\n",
    "df_mpc = make_module_df(df_tcga, \"MPC_score\", \"MPC\")\n",
    "\n",
    "print(df_ige.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59236bde",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "0d126493",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/mh/r2nrb73509z0t_wjbx9r5fg00000gn/T/ipykernel_92012/2198067257.py:82: UserWarning: No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n",
      "  plt.legend(frameon=False, loc=\"best\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SAVE] KM figure -> KM_panels/TCGA_IGE_KM.png\n",
      "[SAVE] KM figure -> KM_panels/TCGA_SAT_KM.png\n"
     ]
    }
   ],
   "source": [
    "plot_km_module(\n",
    "    df=df_ige,\n",
    "    group_col=\"group\",\n",
    "    time_col=\"OS_time_months\",\n",
    "    event_col=\"OS_event\",\n",
    "    high_label=\"High IGE\",\n",
    "    low_label=\"Low IGE\",\n",
    "    panel_title=\"TCGA-PAAD: IGE module\",\n",
    "    outdir=\"KM_panels\",\n",
    "    filename=\"TCGA_IGE_KM.png\",\n",
    "    panel_letter=\"D\",\n",
    ")\n",
    "\n",
    "plot_km_module(\n",
    "    df=df_sat,\n",
    "    group_col=\"group\",\n",
    "    time_col=\"OS_time_months\",\n",
    "    event_col=\"OS_event\",\n",
    "    high_label=\"High SAT\",\n",
    "    low_label=\"Low SAT\",\n",
    "    panel_title=\"TCGA-PAAD: SAT module\",\n",
    "    outdir=\"KM_panels\",\n",
    "    filename=\"TCGA_SAT_KM.png\",\n",
    "    panel_letter=\"A\",\n",
    ")\n",
    "# ... similarly for IL2, MPC\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "f1efcfd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TCGA] Loading expression from: PAAD_RSEM_genes_normalized_CLEAN.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/mh/r2nrb73509z0t_wjbx9r5fg00000gn/T/ipykernel_92012/2690094429.py:50: FutureWarning: DataFrame.groupby with axis=1 is deprecated. Do `frame.T.groupby(...)` without axis instead.\n",
      "  df = df.groupby(df.columns, axis=1).mean(numeric_only=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TCGA] patient-level shape (genes x patients): (20502, 178)\n",
      "[COVERAGE] UP 102/118 | DOWN 13/20\n",
      "[CLIN] rows with OS: 184\n",
      "[MERGE] N with score+OS: 177\n",
      "[KM] IGE: p=0.93, median=-0.077 -> /Users/scottpowers/Desktop/tcga_paad_IGE_module_survival_out/IGE/IGE_KM.png\n"
     ]
    }
   ],
   "source": [
    "# --- TCGA PAAD survival • IGE signed score (single-module script) ---\n",
    "\n",
    "import pandas as pd, numpy as np\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "from lifelines import KaplanMeierFitter\n",
    "from lifelines.statistics import logrank_test\n",
    "\n",
    "# ----------------- INPUTS -----------------\n",
    "DESKTOP = Path.home() / \"Desktop\"\n",
    "expr_paths = [\n",
    "    DESKTOP / \"PAAD_RSEM_genes_normalized_CLEAN.csv\",\n",
    "    DESKTOP / \"PAAD.rnaseqv2__illuminahiseq_rnaseqv2__unc_edu__Level_3__RSEM_genes_normalized__data.data.csv\",\n",
    "]\n",
    "clin_path = DESKTOP / \"paad_tcga_pan_can_atlas_2018_clinical_data.csv\"\n",
    "OUTDIR = DESKTOP / \"tcga_paad_IGE_module_survival_out\" / \"IGE\"\n",
    "OUTDIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# IGE genes\n",
    "IGE_UP = [\n",
    "\"PFN2\",\"SET\",\"LGALS1\",\"PDLIM4\",\"EIF5A\",\"F8A1\",\"BANF1\",\"CTDNEP1\",\"TRAPPC1\",\"AMZ2\",\"PTGES3\",\"ST13\",\"FTH1\",\"PCBP1\",\n",
    "\"NAA10\",\"ARPC5L\",\"ETFB\",\"CCDC124\",\"SSR2\",\"PGLS\",\"SELENOH\",\"GSTP1\",\"NDUFB7\",\"AURKAIP1\",\"GCHFR\",\"MYL6\",\"AP2S1\",\n",
    "\"S100A13\",\"C9orf16\",\"KRT8\",\"PRKCSH\",\"CST3\",\"PET100\",\"DNAJA2\",\"VPS35\",\"VDAC1\",\"MGST3\",\"PRR13\",\"OCIAD2\",\"FUOM\",\"MIA\",\n",
    "\"RPN1\",\"FUCA2\",\"TMED4\",\"ERGIC3\",\"DDOST\",\"NAXE\",\"SNRPD1\",\"SKP1\",\"CNBP\",\"ATP5MC3\",\"SLC25A5\",\"LSM4\",\"NDUFAB1\",\"PCBD1\",\n",
    "\"HINT1\",\"ADI1\",\"NENF\",\"MRPL43\",\"VKORC1\",\"EMC4\",\"COA3\",\"NEDD8\",\"CHCHD2\",\"PRDX5\",\"WDR83OS\",\"NDUFA4\",\"GABARAP\",\"PHPT1\",\n",
    "\"UFC1\",\"MDH1\",\"ATP5F1E\",\"MRPL41\",\"UBL5\",\"COX5B\",\"ELOB\",\"ATP5ME\",\"UQCRB\",\"SEM1\",\"NDUFB1\",\"COX6C\",\"ATP6V1F\",\"HNRNPA1\",\n",
    "\"HIGD2A\",\"POLR2I\",\"METTL26\",\"NDUFB4\",\"OST4\",\"C19orf53\",\"RPL36AL\",\"PPIA\",\"COPS9\",\"COX8A\",\"COX5A\",\"RPL36\",\"RPS15\",\n",
    "\"RPS27\",\"RPS11\",\"FTL\",\"SNHG29\",\"NACA\",\"RPS17\",\"RPL23\",\"RPL39\",\"RPS21\",\"RPL9\",\"RPL15\",\"RPL34\",\"RPL27A\",\"RPL36A\",\n",
    "\"RPL38\",\"RPS26\",\"RPS14\",\"RPL35\",\"RPL37A\",\"RPL37\",\"RPL12\",\"RPS29\"\n",
    "]\n",
    "IGE_DOWN = [\"STN1\",\"NRG4\",\"IQSEC2\",\"IYD\",\"CHD9\",\"APBB1IP\",\"TMEM238\",\"REX1BD\",\"IFI27\",\"CYBA\",\"METRNL\",\"AKR7A2\",\n",
    "            \"SULT1A1\",\"ARHGEF35\",\"AC008397.1\",\"KLK11\",\"DELE1\",\"MISP\",\"FAM234A\",\"CMBL\"]\n",
    "\n",
    "# ----------------- helpers -----------------\n",
    "def load_tcga_expr(expr_paths):\n",
    "    path = next((p for p in expr_paths if p.exists()), None)\n",
    "    if path is None:\n",
    "        raise FileNotFoundError(\"No TCGA PAAD expression file found on Desktop.\")\n",
    "    print(f\"[TCGA] Loading expression from: {path.name}\")\n",
    "    df = pd.read_csv(path, low_memory=False)\n",
    "    gene_col = None\n",
    "    for c in [\"Hugo_Symbol\",\"gene\",\"Gene\",\"GeneSymbol\",\"gene_name\", df.columns[0]]:\n",
    "        if c in df.columns: gene_col = c; break\n",
    "    if gene_col is None: raise ValueError(\"Could not infer gene column.\")\n",
    "    df = df.rename(columns={gene_col: \"Gene\"})\n",
    "    df[\"Gene\"] = df[\"Gene\"].astype(str).str.split(\"|\").str[0]\n",
    "    df = df.set_index(\"Gene\")\n",
    "    df = df.apply(pd.to_numeric, errors=\"coerce\").dropna(how=\"all\", axis=0).dropna(how=\"all\", axis=1)\n",
    "    df.columns = pd.Index([str(c)[:12] for c in df.columns], name=\"patientId\")\n",
    "    df = df.groupby(df.columns, axis=1).mean(numeric_only=True)\n",
    "    print(f\"[TCGA] patient-level shape (genes x patients): {df.shape}\")\n",
    "    return df\n",
    "\n",
    "def score_signed(expr, up_genes, down_genes, min_genes=10, name=\"signed_score\"):\n",
    "    Z = expr.apply(lambda x: (x - x.mean()) / (x.std(ddof=0) + 1e-9), axis=1)\n",
    "    up = pd.Index(up_genes).intersection(Z.index); dn = pd.Index(down_genes).intersection(Z.index)\n",
    "    cov = {\"up_used\": int(up.size), \"up_total\": len(up_genes), \"down_used\": int(dn.size), \"down_total\": len(down_genes)}\n",
    "    if up.size < min_genes or dn.size < min_genes:\n",
    "        return pd.Series(np.nan, index=Z.columns, name=name), cov\n",
    "    return (Z.loc[up].mean(axis=0) - Z.loc[dn].mean(axis=0)).rename(name), cov\n",
    "\n",
    "def load_clin(path):\n",
    "    if not path.exists(): raise FileNotFoundError(\"PanCan clinical file not found on Desktop.\")\n",
    "    clin = pd.read_csv(path)\n",
    "    need = [\"patientId\",\"OS_MONTHS\",\"OS_STATUS\"]\n",
    "    miss = [c for c in need if c not in clin.columns]\n",
    "    if miss: raise ValueError(f\"Missing columns in clinical file: {miss}\")\n",
    "    clin[\"patientId\"] = clin[\"patientId\"].astype(str).str[:12]\n",
    "    status = clin[\"OS_STATUS\"].astype(str).str.upper().str.contains(\"DECEASED\")\n",
    "    out = pd.DataFrame({\n",
    "        \"patientId\": clin[\"patientId\"],\n",
    "        \"OS_time_months\": pd.to_numeric(clin[\"OS_MONTHS\"], errors=\"coerce\"),\n",
    "        \"OS_event\": status.astype(float)\n",
    "    }).dropna(subset=[\"OS_time_months\",\"OS_event\"]).drop_duplicates(subset=[\"patientId\"]).set_index(\"patientId\")\n",
    "    print(f\"[CLIN] rows with OS: {out.shape[0]}\")\n",
    "    return out\n",
    "\n",
    "def zscore_series(s):\n",
    "    mu, sd = s.mean(), s.std(ddof=0)\n",
    "    return s*0 if (sd == 0 or np.isnan(sd)) else (s - mu) / sd\n",
    "\n",
    "def km_plot_and_logrank(df, score_col, title, out_png, hi_label=\"High IGE\", lo_label=\"Low IGE\"):\n",
    "    med = df[score_col].median()\n",
    "    df = df.assign(group=np.where(df[score_col] >= med, hi_label, lo_label)).copy()\n",
    "    hi = df[\"group\"] == hi_label; lo = df[\"group\"] == lo_label\n",
    "    lr = logrank_test(df.loc[hi,\"OS_time_months\"], df.loc[lo,\"OS_time_months\"],\n",
    "                      event_observed_A=df.loc[hi,\"OS_event\"], event_observed_B=df.loc[lo,\"OS_event\"])\n",
    "    pval = float(lr.p_value)\n",
    "    km = KaplanMeierFitter()\n",
    "    fig, ax = plt.subplots(figsize=(6.5,5), dpi=160)\n",
    "    for label in (hi_label, lo_label):\n",
    "        sub = df[df[\"group\"] == label]\n",
    "        if sub.empty: continue\n",
    "        km.fit(sub[\"OS_time_months\"], sub[\"OS_event\"], label=label)\n",
    "        sf = km.survival_function_.iloc[:,0]; t = sf.index.values; y = sf.values\n",
    "        ax.step(t, y, where=\"post\", label=label)\n",
    "        ci = km.confidence_interval_; lo_ci = ci.iloc[:,0].values; hi_ci = ci.iloc[:,1].values\n",
    "        ax.fill_between(t, lo_ci, hi_ci, step=\"post\", alpha=0.20)\n",
    "    ax.set_xlabel(\"Time (months)\"); ax.set_ylabel(\"Overall survival probability\")\n",
    "    ax.set_title(f\"{title}\\nlog-rank p = {pval:.3g}\"); ax.legend(); fig.tight_layout()\n",
    "    fig.savefig(out_png, bbox_inches=\"tight\"); plt.close(fig)\n",
    "    return pval, float(med)\n",
    "\n",
    "# ----------------- run -----------------\n",
    "expr = load_tcga_expr(expr_paths)\n",
    "scores, cov = score_signed(expr, IGE_UP, IGE_DOWN, min_genes=10, name=\"IGE\")\n",
    "print(f\"[COVERAGE] UP {cov['up_used']}/{cov['up_total']} | DOWN {cov['down_used']}/{cov['down_total']}\")\n",
    "clin = load_clin(clin_path)\n",
    "\n",
    "df = pd.concat([scores, clin], axis=1, join=\"inner\").dropna(subset=[\"IGE\",\"OS_time_months\",\"OS_event\"])\n",
    "print(f\"[MERGE] N with score+OS: {df.shape[0]}\")\n",
    "(scores.rename(\"IGE\").to_csv(OUTDIR / \"IGE_signed_scores.csv\"))\n",
    "zscore_series(scores).rename(\"IGE_Z\").to_csv(OUTDIR / \"IGE_signed_scores_Z.csv\")\n",
    "\n",
    "if df.shape[0] >= 10 and np.isfinite(df[\"IGE\"]).any():\n",
    "    p, med = km_plot_and_logrank(df, \"IGE\", \"TCGA-PAAD: IGE signed score (median split)\", OUTDIR / \"IGE_KM.png\")\n",
    "    print(f\"[KM] IGE: p={p:.3g}, median={med:.3f} -> {OUTDIR/'IGE_KM.png'}\")\n",
    "    df_out = df.assign(group=np.where(df[\"IGE\"]>=med, \"High IGE\", \"Low IGE\"))\n",
    "    df_out.to_csv(OUTDIR / \"IGE_scores_OS_group.csv\")\n",
    "else:\n",
    "    print(\"[SKIP] Not enough valid cases for KM.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "ef107e86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TCGA] Loading expression from: PAAD_RSEM_genes_normalized_CLEAN.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/mh/r2nrb73509z0t_wjbx9r5fg00000gn/T/ipykernel_92012/3468198473.py:50: FutureWarning: DataFrame.groupby with axis=1 is deprecated. Do `frame.T.groupby(...)` without axis instead.\n",
      "  df = df.groupby(df.columns, axis=1).mean(numeric_only=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TCGA] patient-level shape (genes x patients): (20502, 178)\n",
      "[COVERAGE] UP 83/106 | DOWN 14/23\n",
      "[CLIN] rows with OS: 184\n",
      "[MERGE] N with score+OS: 177\n",
      "[KM] IL2: p=0.848, median=-0.034 -> /Users/scottpowers/Desktop/tcga_paad_IL2_module_survival_out/IL2/IL2_KM.png\n"
     ]
    }
   ],
   "source": [
    "# --- TCGA PAAD survival • IL2 signed score (single-module script) ---\n",
    "\n",
    "import pandas as pd, numpy as np\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "from lifelines import KaplanMeierFitter\n",
    "from lifelines.statistics import logrank_test\n",
    "\n",
    "DESKTOP = Path.home() / \"Desktop\"\n",
    "expr_paths = [\n",
    "    DESKTOP / \"PAAD_RSEM_genes_normalized_CLEAN.csv\",\n",
    "    DESKTOP / \"PAAD.rnaseqv2__illuminahiseq_rnaseqv2__unc_edu__Level_3__RSEM_genes_normalized__data.data.csv\",\n",
    "]\n",
    "clin_path = DESKTOP / \"paad_tcga_pan_can_atlas_2018_clinical_data.csv\"\n",
    "OUTDIR = DESKTOP / \"tcga_paad_IL2_module_survival_out\" / \"IL2\"\n",
    "OUTDIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "IL2_UP = [\n",
    "    \"ABHD15-AS1\",\"AC007780.1\",\"AC008105.3\",\"AC008964.1\",\"AC016831.1\",\"AC016831.5\",\"AC090772.1\",\"AC108863.2\",\n",
    "    \"ADARB1\",\"ALOX5AP\",\"ANKH\",\"ANKRD44\",\"APOBEC3G\",\"ARHGDIB\",\"ARL6IP5\",\"ARSG\",\"ATP10D\",\"BCL11B\",\"BORCS5\",\n",
    "    \"CAMK1D\",\"CD4\",\"CD84\",\"CD96\",\"CDC42EP3\",\"CELF2\",\"CERS4\",\"CLEC2D\",\"CNOT6L\",\"CRYBG1\",\"CTSW\",\"DSE\",\"FGD3\",\n",
    "    \"FMNL1\",\"FOXN3\",\"FOXO1\",\"FYB1\",\"GFI1\",\"GNAO1\",\"GPRIN3\",\"HOPX\",\"IGF1\",\"IKZF3\",\"IL18R1\",\"INKA2\",\"INSYN2B\",\n",
    "    \"IQSEC1\",\"ITPRIPL1\",\"JAK3\",\"KLRC2\",\"KLRC3\",\"KLRF1\",\"KLRG1\",\"LAPTM5\",\"LCP1\",\"LEPROTL1\",\"LINC00513\",\n",
    "    \"LINC01237\",\"MAN1A1\",\"MAPRE2\",\"MPHOSPH9\",\"MPP7\",\"MVB12B\",\"MYO5A\",\"NIN\",\"PARP11\",\"PARP15\",\"PCED1B-AS1\",\n",
    "    \"PDE3B\",\"PIP4K2A\",\"PLCL1\",\"PLEKHA2\",\"PPP3CC\",\"PRKCH\",\"PRKCQ\",\"PRKD3\",\"PRKX\",\"PTPN22\",\"RAC2\",\"RASGRF2\",\n",
    "    \"RFX3\",\"RIPOR2\",\"RNF166\",\"S1PR4\",\"SAMD3\",\"SENP7\",\"SH2B3\",\"SH2D2A\",\"SMARCA2\",\"SNHG26\",\"SPOCK2\",\"SRGN\",\n",
    "    \"ST8SIA1\",\"STAT5A\",\"STAT5B\",\"STIM1\",\"STK17A\",\"TMEM200A\",\"TMX4\",\"TRBC2\",\"TRDC\",\"TRIM22\",\"TTN\",\"VAV3\",\n",
    "    \"WNT5A-AS1\",\"ZNF101\",\"ZNF471\"\n",
    "]\n",
    "IL2_DOWN = [\n",
    "    \"RBP7\",\"OVCA2\",\"PLAC4\",\"AC026785.3\",\"LINC02212\",\"LINC00605\",\"AC246817.2\",\"FOXCUT\",\"VGLL2\",\"ZIC4\",\"FOLR3\",\n",
    "    \"ECEL1\",\"AC024337.1\",\"C5orf58\",\"AC060814.3\",\"B4GALNT1\",\"UCHL1\",\"VAX1\",\"AL451042.1\",\"COMMD8\",\"IFI30\",\n",
    "    \"AL096794.1\",\"RGS10\"\n",
    "]\n",
    "\n",
    "def load_tcga_expr(expr_paths):\n",
    "    path = next((p for p in expr_paths if p.exists()), None)\n",
    "    if path is None: raise FileNotFoundError(\"No TCGA PAAD expression file found on Desktop.\")\n",
    "    print(f\"[TCGA] Loading expression from: {path.name}\")\n",
    "    df = pd.read_csv(path, low_memory=False)\n",
    "    gene_col = None\n",
    "    for c in [\"Hugo_Symbol\",\"gene\",\"Gene\",\"GeneSymbol\",\"gene_name\", df.columns[0]]:\n",
    "        if c in df.columns: gene_col = c; break\n",
    "    if gene_col is None: raise ValueError(\"Could not infer gene column.\")\n",
    "    df = df.rename(columns={gene_col: \"Gene\"})\n",
    "    df[\"Gene\"] = df[\"Gene\"].astype(str).str.split(\"|\").str[0]\n",
    "    df = df.set_index(\"Gene\")\n",
    "    df = df.apply(pd.to_numeric, errors=\"coerce\").dropna(how=\"all\", axis=0).dropna(how=\"all\", axis=1)\n",
    "    df.columns = pd.Index([str(c)[:12] for c in df.columns], name=\"patientId\")\n",
    "    df = df.groupby(df.columns, axis=1).mean(numeric_only=True)\n",
    "    print(f\"[TCGA] patient-level shape (genes x patients): {df.shape}\")\n",
    "    return df\n",
    "\n",
    "def score_signed(expr, up_genes, down_genes, min_genes=10, name=\"signed_score\"):\n",
    "    Z = expr.apply(lambda x: (x - x.mean()) / (x.std(ddof=0) + 1e-9), axis=1)\n",
    "    up = pd.Index(up_genes).intersection(Z.index); dn = pd.Index(down_genes).intersection(Z.index)\n",
    "    cov = {\"up_used\": int(up.size), \"up_total\": len(up_genes), \"down_used\": int(dn.size), \"down_total\": len(down_genes)}\n",
    "    if up.size < min_genes or dn.size < min_genes:\n",
    "        return pd.Series(np.nan, index=Z.columns, name=name), cov\n",
    "    return (Z.loc[up].mean(axis=0) - Z.loc[dn].mean(axis=0)).rename(name), cov\n",
    "\n",
    "def load_clin(path):\n",
    "    if not path.exists(): raise FileNotFoundError(\"PanCan clinical file not found on Desktop.\")\n",
    "    clin = pd.read_csv(path)\n",
    "    need = [\"patientId\",\"OS_MONTHS\",\"OS_STATUS\"]\n",
    "    miss = [c for c in need if c not in clin.columns]\n",
    "    if miss: raise ValueError(f\"Missing columns in clinical file: {miss}\")\n",
    "    clin[\"patientId\"] = clin[\"patientId\"].astype(str).str[:12]\n",
    "    status = clin[\"OS_STATUS\"].astype(str).str.upper().str.contains(\"DECEASED\")\n",
    "    out = pd.DataFrame({\n",
    "        \"patientId\": clin[\"patientId\"],\n",
    "        \"OS_time_months\": pd.to_numeric(clin[\"OS_MONTHS\"], errors=\"coerce\"),\n",
    "        \"OS_event\": status.astype(float)\n",
    "    }).dropna(subset=[\"OS_time_months\",\"OS_event\"]).drop_duplicates(subset=[\"patientId\"]).set_index(\"patientId\")\n",
    "    print(f\"[CLIN] rows with OS: {out.shape[0]}\")\n",
    "    return out\n",
    "\n",
    "def zscore_series(s):\n",
    "    mu, sd = s.mean(), s.std(ddof=0)\n",
    "    return s*0 if (sd == 0 or np.isnan(sd)) else (s - mu) / sd\n",
    "\n",
    "def km_plot_and_logrank(df, score_col, title, out_png, hi_label=\"High IL2\", lo_label=\"Low IL2\"):\n",
    "    med = df[score_col].median()\n",
    "    df = df.assign(group=np.where(df[score_col] >= med, hi_label, lo_label)).copy()\n",
    "    hi = df[\"group\"] == hi_label; lo = df[\"group\"] == lo_label\n",
    "    lr = logrank_test(df.loc[hi,\"OS_time_months\"], df.loc[lo,\"OS_time_months\"],\n",
    "                      event_observed_A=df.loc[hi,\"OS_event\"], event_observed_B=df.loc[lo,\"OS_event\"])\n",
    "    pval = float(lr.p_value)\n",
    "    km = KaplanMeierFitter()\n",
    "    fig, ax = plt.subplots(figsize=(6.5,5), dpi=160)\n",
    "    for label in (hi_label, lo_label):\n",
    "        sub = df[df[\"group\"] == label]\n",
    "        if sub.empty: continue\n",
    "        km.fit(sub[\"OS_time_months\"], sub[\"OS_event\"], label=label)\n",
    "        sf = km.survival_function_.iloc[:,0]; t = sf.index.values; y = sf.values\n",
    "        ax.step(t, y, where=\"post\", label=label)\n",
    "        ci = km.confidence_interval_; lo_ci = ci.iloc[:,0].values; hi_ci = ci.iloc[:,1].values\n",
    "        ax.fill_between(t, lo_ci, hi_ci, step=\"post\", alpha=0.20)\n",
    "    ax.set_xlabel(\"Time (months)\"); ax.set_ylabel(\"Overall survival probability\")\n",
    "    ax.set_title(f\"{title}\\nlog-rank p = {pval:.3g}\"); ax.legend(); fig.tight_layout()\n",
    "    fig.savefig(out_png, bbox_inches=\"tight\"); plt.close(fig)\n",
    "    return pval, float(med)\n",
    "\n",
    "# ----------------- run -----------------\n",
    "expr = load_tcga_expr(expr_paths)\n",
    "scores, cov = score_signed(expr, IL2_UP, IL2_DOWN, min_genes=10, name=\"IL2\")\n",
    "print(f\"[COVERAGE] UP {cov['up_used']}/{cov['up_total']} | DOWN {cov['down_used']}/{cov['down_total']}\")\n",
    "clin = load_clin(clin_path)\n",
    "\n",
    "df = pd.concat([scores, clin], axis=1, join=\"inner\").dropna(subset=[\"IL2\",\"OS_time_months\",\"OS_event\"])\n",
    "print(f\"[MERGE] N with score+OS: {df.shape[0]}\")\n",
    "scores.rename(\"IL2\").to_csv(OUTDIR / \"IL2_signed_scores.csv\")\n",
    "zscore_series(scores).rename(\"IL2_Z\").to_csv(OUTDIR / \"IL2_signed_scores_Z.csv\")\n",
    "\n",
    "if df.shape[0] >= 10 and np.isfinite(df[\"IL2\"]).any():\n",
    "    p, med = km_plot_and_logrank(df, \"IL2\", \"TCGA-PAAD: IL2 signed score (median split)\", OUTDIR / \"IL2_KM.png\")\n",
    "    print(f\"[KM] IL2: p={p:.3g}, median={med:.3f} -> {OUTDIR/'IL2_KM.png'}\")\n",
    "    df_out = df.assign(group=np.where(df[\"IL2\"]>=med, \"High IL2\", \"Low IL2\"))\n",
    "    df_out.to_csv(OUTDIR / \"IL2_scores_OS_group.csv\")\n",
    "else:\n",
    "    print(\"[SKIP] Not enough valid cases for KM.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "694af76f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TCGA] Loading expression from: PAAD_RSEM_genes_normalized_CLEAN.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/mh/r2nrb73509z0t_wjbx9r5fg00000gn/T/ipykernel_92012/1272072538.py:66: FutureWarning: DataFrame.groupby with axis=1 is deprecated. Do `frame.T.groupby(...)` without axis instead.\n",
      "  df = df.groupby(df.columns, axis=1).mean(numeric_only=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TCGA] patient-level shape (genes x patients): (20502, 178)\n",
      "[COVERAGE] UP 273/304 | DOWN 12/14\n",
      "[CLIN] rows with OS: 184\n",
      "[MERGE] N with score+OS: 177\n",
      "[KM] MPC: p=0.922, median=0.068 -> /Users/scottpowers/Desktop/tcga_paad_MPC_module_survival_out/MOD3/MOD3_KM.png\n"
     ]
    }
   ],
   "source": [
    "# --- TCGA PAAD survival • MOD3 signed score (single-module script) ---\n",
    "\n",
    "import pandas as pd, numpy as np\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "from lifelines import KaplanMeierFitter\n",
    "from lifelines.statistics import logrank_test\n",
    "\n",
    "DESKTOP = Path.home() / \"Desktop\"\n",
    "expr_paths = [\n",
    "    DESKTOP / \"PAAD_RSEM_genes_normalized_CLEAN.csv\",\n",
    "    DESKTOP / \"PAAD.rnaseqv2__illuminahiseq_rnaseqv2__unc_edu__Level_3__RSEM_genes_normalized__data.data.csv\",\n",
    "]\n",
    "clin_path = DESKTOP / \"paad_tcga_pan_can_atlas_2018_clinical_data.csv\"\n",
    "OUTDIR = DESKTOP / \"tcga_paad_MPC_module_survival_out\" / \"MOD3\"\n",
    "OUTDIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "MPC_UP = [\n",
    "    \"KIAA1211L\",\"CASC4\",\"AHR\",\"YY1AP1\",\"COPA\",\"RELL1\",\"FBXW2\",\"CARMIL1\",\"NUBPL\",\"ZC3H18\",\"AGK\",\"HLCS\",\n",
    "    \"TMEM241\",\"URGCP\",\"CADPS2\",\"COBL\",\"ARHGAP42\",\"AC138305.1\",\"FAM135A\",\"SLC41A2\",\"TACC2\",\"MCU\",\"FMN1\",\n",
    "    \"LGR4\",\"BAIAP2L1\",\"SGPP2\",\"RGS12\",\"PTPN3\",\"IBTK\",\"SPRY4-AS1\",\"UGT8\",\"PNN\",\"SP140L\",\"PIK3CA\",\"CNOT2\",\n",
    "    \"ZFC3H1\",\"UBE2K\",\"STRN3\",\"STAG2\",\"KDM5A\",\"RC3H2\",\"TP53BP1\",\"SLC9A8\",\"ATF7IP\",\"MLLT10\",\"SCAPER\",\"CPSF6\",\n",
    "    \"KLC1\",\"HUWE1\",\"TAOK3\",\"ROCK1\",\"MAN2A1\",\"ZNF44\",\"ARGLU1\",\"EHMT1\",\"HTT\",\"SIN3A\",\"RSBN1L\",\"MLLT3\",\"RABGAP1\",\n",
    "    \"SCFD1\",\"NEMF\",\"DMXL1\",\"RCOR3\",\"NAA35\",\"WWP1\",\"VPS41\",\"PRRC2B\",\"STX16\",\"ANKRD11\",\"ARHGEF7\",\"SOS2\",\"SLAIN2\",\n",
    "    \"LUC7L2\",\"SRPK2\",\"TYW1\",\"HMBOX1\",\"LMBR1\",\"TCF12\",\"MBD5\",\"MON2\",\"COG5\",\"LONP2\",\"RAB3GAP2\",\"LARP4B\",\"NUMB\",\n",
    "    \"NF1\",\"NCOA2\",\"ZNF710\",\"CSNK1G1\",\"WDR37\",\"NUTM2B-AS1\",\"ITFG1\",\"UBE3C\",\"MFSD14C\",\"SPG11\",\"PTK2\",\"LPP\",\n",
    "    \"ZBTB20\",\"FCHO2\",\"PTPN12\",\"DCUN1D4\",\"KDM7A\",\"SLMAP\",\"KIF13B\",\"MIB1\",\"DIP2C\",\"LRCH1\",\"TNIK\",\"TNKS\",\"SMC5\",\n",
    "    \"ANKIB1\",\"RBM33\",\"TNPO3\",\"OSBPL3\",\"RAPGEF2\",\"MED13L\",\"FBXL20\",\"KIAA0232\",\"ITCH\",\"MARCH6\",\"ARID4B\",\"PLEKHA6\",\n",
    "    \"FNBP1L\",\"KIAA1217\",\"FARP2\",\"MAGI3\",\"DIAPH2\",\"VPS13A\",\"DGKH\",\"GNAQ\",\"ARHGEF12\",\"MYO1D\",\"CDC42BPA\",\"TTC7A\",\n",
    "    \"TRIM44\",\"NSD3\",\"NCOA3\",\"ADNP\",\"RUFY3\",\"RUNX1\",\"TRRAP\",\"PTBP2\",\"ZNF609\",\"CHD7\",\"PARP8\",\"ARIH1\",\"ZHX2\",\n",
    "    \"ETV6\",\"CUL1\",\"CDK13\",\"BRAF\",\"MBTD1\",\"AUH\",\"STX17\",\"POLR2J3\",\"KLHDC10\",\"TAF1\",\"TOGARAM1\",\"WRN\",\"ADK\",\n",
    "    \"TASOR2\",\"NUDCD3\",\"TBL1X\",\"MOSMO\",\"USP42\",\"CRCP\",\"GALNT11\",\"DDI2\",\"TTC14\",\"UPF2\",\"PDXDC1\",\"ETFDH\",\"SEL1L3\",\n",
    "    \"HEATR5A\",\"PSMD5\",\"TBC1D2B\",\"NUP214\",\"GAPVD1\",\"RNF19A\",\"SMURF2\",\"NRIP1\",\"WDFY2\",\"TBK1\",\"LCORL\",\"USP25\",\n",
    "    \"RABGEF1\",\"CASD1\",\"RBPJ\",\"AEBP2\",\"MALAT1\",\"MAML2\",\"RBMS1\",\"CRIM1\",\"SNX29\",\"PPFIBP1\",\"SVIL\",\"DDX24\",\"G2E3\",\n",
    "    \"RASA1\",\"FAM160A1\",\"RNF24\",\"ESYT2\",\"EPS8\",\"SESTD1\",\"ATP2B4\",\"PELI1\",\"RNF145\",\"B4GALT5\",\"PPP2R2A\",\"NOS1AP\",\n",
    "    \"EGFR\",\"CPNE8\",\"ARHGAP21\",\"SMAD3\",\"DAPK1\",\"IGF1R\",\"AFAP1\",\"KLF7\",\"DOCK5\",\"MINDY2\",\"ZXDC\",\"NEDD4\",\"METTL15\",\n",
    "    \"FNIP2\",\"NEAT1\",\"CELF1\",\"DANT2\",\"SYT17\",\"TMEM245\",\"ERICH1\",\"ADPGK\",\"LMBRD1\",\"MFSD11\",\"GOLGA2\",\"SCNN1A\",\n",
    "    \"XDH\",\"PLEKHA1\",\"PPP2CB\",\"GTF2E2\",\"KCNK1\",\"SPATS2L\",\"RTF1\",\"UACA\",\"VAV2\",\"MDFIC\",\"STAM\",\"CLIP4\",\"KYAT1\",\n",
    "    \"MECP2\",\"NUP160\",\"THOC1\",\"LINC-PINT\",\"MCPH1\",\"DISC1\",\"UBA6-AS1\",\"AAK1\",\"NRF1\",\"PHF20\",\"RNF216\",\"PCM1\",\"SAFB2\",\n",
    "    \"FAM133B\",\"NR6A1\",\"ATL2\",\"C1orf21\",\"MTUS1\",\"PARD3B\",\"EXT1\",\"ST5\",\"ABI2\",\"INTS6L\",\"TRIM56\",\"PTER\",\"PRR12\",\n",
    "    \"RSPH3\",\"TMC5\",\"MECOM\",\"ARHGEF10L\",\"HNF4G\",\"PPM1H\",\"AP005230.1\",\"AC119674.1\",\"ZSCAN18\",\"NOL4L\",\"PDPK1\",\n",
    "    \"RSU1\",\"TTC39C\",\"COL27A1\",\"SEC16B\",\"AC005162.3\",\"RASAL1\",\"IL17RA\",\"SPART-AS1\",\"CDC37\",\"MUCL3\",\"TMEM178B\",\n",
    "    \"LINC02614\",\"EREG\",\"ELK3\",\"TMTC1\",\"PALM2-AKAP2\",\"RAB31\",\"EMP3\"\n",
    "]\n",
    "\n",
    "\n",
    "MPC_DOWN = [\n",
    "    \"MRPS15\",\"TALDO1\",\"MDH2\",\"PSMB5\",\"PIK3CD-AS2\",\"DUSP9\",\"POPDC3\",\"AKR1C3\",\"MRPS18A\",\"EIF3H\",\"UQCRC2\",\n",
    "    \"IFT22\",\"RAB11B\",\"MBOAT7\"\n",
    "]\n",
    "\n",
    "def load_tcga_expr(paths):\n",
    "    path = next((p for p in paths if p.exists()), None)\n",
    "    if path is None: raise FileNotFoundError(\"No TCGA PAAD expression file found on Desktop.\")\n",
    "    print(f\"[TCGA] Loading expression from: {path.name}\")\n",
    "    df = pd.read_csv(path, low_memory=False)\n",
    "    gene_col = None\n",
    "    for c in [\"Hugo_Symbol\",\"gene\",\"Gene\",\"GeneSymbol\",\"gene_name\", df.columns[0]]:\n",
    "        if c in df.columns: gene_col = c; break\n",
    "    if gene_col is None: raise ValueError(\"Could not infer gene column.\")\n",
    "    df = df.rename(columns={gene_col:\"Gene\"})\n",
    "    df[\"Gene\"] = df[\"Gene\"].astype(str).str.split(\"|\").str[0]\n",
    "    df = df.set_index(\"Gene\")\n",
    "    df = df.apply(pd.to_numeric, errors=\"coerce\").dropna(how=\"all\", axis=0).dropna(how=\"all\", axis=1)\n",
    "    df.columns = pd.Index([str(c)[:12] for c in df.columns], name=\"patientId\")\n",
    "    df = df.groupby(df.columns, axis=1).mean(numeric_only=True)\n",
    "    print(f\"[TCGA] patient-level shape (genes x patients): {df.shape}\")\n",
    "    return df\n",
    "\n",
    "def score_signed(expr, up_genes, down_genes, min_genes=10, name=\"signed_score\"):\n",
    "    Z = expr.apply(lambda x: (x - x.mean()) / (x.std(ddof=0) + 1e-9), axis=1)\n",
    "    up = pd.Index(up_genes).intersection(Z.index); dn = pd.Index(down_genes).intersection(Z.index)\n",
    "    cov = {\"up_used\": int(up.size), \"up_total\": len(up_genes), \"down_used\": int(dn.size), \"down_total\": len(down_genes)}\n",
    "    if up.size < min_genes or dn.size < min_genes:\n",
    "        return pd.Series(np.nan, index=Z.columns, name=name), cov\n",
    "    return (Z.loc[up].mean(axis=0) - Z.loc[dn].mean(axis=0)).rename(name), cov\n",
    "\n",
    "def load_clin(path):\n",
    "    if not path.exists(): raise FileNotFoundError(\"PanCan clinical file not found on Desktop.\")\n",
    "    clin = pd.read_csv(path)\n",
    "    for c in [\"patientId\",\"OS_MONTHS\",\"OS_STATUS\"]:\n",
    "        if c not in clin.columns: raise ValueError(\"Missing columns in clinical file.\")\n",
    "    clin[\"patientId\"] = clin[\"patientId\"].astype(str).str[:12]\n",
    "    status = clin[\"OS_STATUS\"].astype(str).str.upper().str.contains(\"DECEASED\")\n",
    "    out = pd.DataFrame({\n",
    "        \"patientId\": clin[\"patientId\"],\n",
    "        \"OS_time_months\": pd.to_numeric(clin[\"OS_MONTHS\"], errors=\"coerce\"),\n",
    "        \"OS_event\": status.astype(float)\n",
    "    }).dropna(subset=[\"OS_time_months\",\"OS_event\"]).drop_duplicates(subset=[\"patientId\"]).set_index(\"patientId\")\n",
    "    print(f\"[CLIN] rows with OS: {out.shape[0]}\")\n",
    "    return out\n",
    "\n",
    "def zscore_series(s):\n",
    "    mu, sd = s.mean(), s.std(ddof=0)\n",
    "    return s*0 if (sd == 0 or np.isnan(sd)) else (s - mu) / sd\n",
    "\n",
    "def km_plot_and_logrank(df, score_col, title, out_png, hi_label=\"High MOD3\", lo_label=\"Low MOD3\"):\n",
    "    med = df[score_col].median()\n",
    "    df = df.assign(group=np.where(df[score_col] >= med, hi_label, lo_label)).copy()\n",
    "    hi = df[\"group\"] == hi_label; lo = df[\"group\"] == lo_label\n",
    "    lr = logrank_test(df.loc[hi,\"OS_time_months\"], df.loc[lo,\"OS_time_months\"],\n",
    "                      event_observed_A=df.loc[hi,\"OS_event\"], event_observed_B=df.loc[lo,\"OS_event\"])\n",
    "    pval = float(lr.p_value)\n",
    "    km = KaplanMeierFitter()\n",
    "    import matplotlib.pyplot as plt\n",
    "    fig, ax = plt.subplots(figsize=(6.5,5), dpi=160)\n",
    "    for label in (hi_label, lo_label):\n",
    "        sub = df[df[\"group\"] == label]\n",
    "        if sub.empty: continue\n",
    "        km.fit(sub[\"OS_time_months\"], sub[\"OS_event\"], label=label)\n",
    "        sf = km.survival_function_.iloc[:,0]; t = sf.index.values; y = sf.values\n",
    "        ax.step(t, y, where=\"post\", label=label)\n",
    "        ci = km.confidence_interval_; lo_ci = ci.iloc[:,0].values; hi_ci = ci.iloc[:,1].values\n",
    "        ax.fill_between(t, lo_ci, hi_ci, step=\"post\", alpha=0.20)\n",
    "    ax.set_xlabel(\"Time (months)\"); ax.set_ylabel(\"Overall survival probability\")\n",
    "    ax.set_title(f\"{title}\\nlog-rank p = {pval:.3g}\"); ax.legend(); fig.tight_layout()\n",
    "    fig.savefig(out_png, bbox_inches=\"tight\"); plt.close(fig)\n",
    "    return pval, float(med)\n",
    "\n",
    "# ----------------- run -----------------\n",
    "expr = load_tcga_expr(expr_paths)\n",
    "scores, cov = score_signed(expr, MPC_UP, MPC_DOWN, min_genes=10, name=\"MPC\")\n",
    "print(f\"[COVERAGE] UP {cov['up_used']}/{cov['up_total']} | DOWN {cov['down_used']}/{cov['down_total']}\")\n",
    "clin = load_clin(clin_path)\n",
    "\n",
    "df = pd.concat([scores, clin], axis=1, join=\"inner\").dropna(subset=[\"MPC\",\"OS_time_months\",\"OS_event\"])\n",
    "print(f\"[MERGE] N with score+OS: {df.shape[0]}\")\n",
    "scores.rename(\"MPC\").to_csv(OUTDIR / \"MPC_signed_scores.csv\")\n",
    "zscore_series(scores).rename(\"MPC_Z\").to_csv(OUTDIR / \"MPC_signed_scores_Z.csv\")\n",
    "\n",
    "if df.shape[0] >= 10 and np.isfinite(df[\"MPC\"]).any():\n",
    "    p, med = km_plot_and_logrank(df, \"MPC\", \"TCGA-PAAD: MPC signed score (median split)\", OUTDIR / \"MPC_KM.png\")\n",
    "    print(f\"[KM] MPC: p={p:.3g}, median={med:.3f} -> {OUTDIR/'MOD3_KM.png'}\")\n",
    "    df.assign(group=np.where(df[\"MPC\"]>=med, \"High MPC\",\"Low MPC\")).to_csv(OUTDIR / \"MPC_scores_OS_group.csv\")\n",
    "else:\n",
    "    print(\"[SKIP] Not enough valid cases for KM.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "cd7b0d90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MPC] Coverage: {'up_used': 273, 'up_total': 304, 'down_used': 12, 'down_total': 14}\n"
     ]
    }
   ],
   "source": [
    "# ---- Compute MPC signed score ----\n",
    "mpc_scores, mpc_cov = score_signed(\n",
    "    expr,\n",
    "    MPC_UP,\n",
    "    MPC_DOWN,\n",
    "    min_genes=10,\n",
    "    name=\"MPC\"\n",
    ")\n",
    "\n",
    "print(\"[MPC] Coverage:\", mpc_cov)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "be1afd43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved MPC KM plot → /Users/scottpowers/Desktop/tcga_paad_MPC_module_survival_out/MOD3/KM_MPC.png\n",
      "Optimal cut = 0.5160185362790477    p-value = 0.39405365788921465\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from lifelines import KaplanMeierFitter\n",
    "from lifelines.statistics import logrank_test\n",
    "\n",
    "plt.rcParams[\"font.family\"] = \"Arial\"\n",
    "\n",
    "# -------------------------\n",
    "# Build MPC dataframe\n",
    "# -------------------------\n",
    "df_mpc = pd.concat([\n",
    "    mpc_scores.rename(\"MPC\"),   # <-- your MPC signed score Series\n",
    "    clin\n",
    "], axis=1, join=\"inner\").dropna(\n",
    "    subset=[\"MPC\", \"OS_time_months\", \"OS_event\"]\n",
    ")\n",
    "\n",
    "# -------------------------\n",
    "# Optimal cut search\n",
    "# -------------------------\n",
    "scores_sorted = df_mpc[\"MPC\"].sort_values()\n",
    "n = len(scores_sorted)\n",
    "\n",
    "qmin = int(n * 0.20)\n",
    "qmax = int(n * 0.80)\n",
    "candidates = scores_sorted.iloc[qmin:qmax]\n",
    "\n",
    "best_cut, best_p = None, 1.0\n",
    "\n",
    "for cut in candidates:\n",
    "    grp = scores_sorted >= cut\n",
    "    hi = df_mpc.loc[grp]\n",
    "    lo = df_mpc.loc[~grp]\n",
    "\n",
    "    if len(hi) < 5 or len(lo) < 5:\n",
    "        continue\n",
    "\n",
    "    lr = logrank_test(\n",
    "        hi[\"OS_time_months\"], lo[\"OS_time_months\"],\n",
    "        event_observed_A=hi[\"OS_event\"],\n",
    "        event_observed_B=lo[\"OS_event\"]\n",
    "    )\n",
    "\n",
    "    if lr.p_value < best_p:\n",
    "        best_p = float(lr.p_value)\n",
    "        best_cut = float(cut)\n",
    "\n",
    "# fallback median\n",
    "if best_cut is None:\n",
    "    best_cut = float(scores_sorted.median())\n",
    "    best_p = float(\"nan\")\n",
    "\n",
    "# -------------------------\n",
    "# Plot MPC KM panel\n",
    "# -------------------------\n",
    "df_mpc = df_mpc.assign(\n",
    "    group=np.where(df_mpc[\"MPC\"] >= best_cut, \"MPC high\", \"MPC low\")\n",
    ")\n",
    "\n",
    "km = KaplanMeierFitter()\n",
    "fig, ax = plt.subplots(figsize=(4.2, 3.5), dpi=200)\n",
    "\n",
    "for grp in [\"MPC high\", \"MPC low\"]:\n",
    "    sub = df_mpc[df_mpc[\"group\"] == grp]\n",
    "    km.fit(sub[\"OS_time_months\"], sub[\"OS_event\"],\n",
    "           label=f\"{grp} (n={len(sub)})\")\n",
    "    km.plot_survival_function(ax=ax, ci_show=True)\n",
    "\n",
    "ax.set_xlabel(\"Time (months)\")\n",
    "ax.set_ylabel(\"Overall survival probability\")\n",
    "ax.set_title(f\"TCGA-PAAD: MPC module\\ncut={best_cut:.3f}, p={best_p:.3g}\")\n",
    "ax.legend(frameon=False)\n",
    "\n",
    "fig.tight_layout()\n",
    "OUT = OUTDIR / \"KM_MPC.png\"\n",
    "fig.savefig(OUT, bbox_inches=\"tight\")\n",
    "plt.close(fig)\n",
    "\n",
    "print(\"Saved MPC KM plot →\", OUT)\n",
    "print(\"Optimal cut =\", best_cut, \"   p-value =\", best_p)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "5d4f48c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'up_used': 83, 'up_total': 106, 'down_used': 14, 'down_total': 23}\n"
     ]
    }
   ],
   "source": [
    "# recompute IL2 quickly\n",
    "il2_scores, il2_cov = score_signed(expr, IL2_UP, IL2_DOWN, min_genes=10, name=\"IL2\")\n",
    "print(il2_cov)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "dad62bc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'up_used': 113, 'up_total': 185, 'down_used': 15, 'down_total': 25}\n"
     ]
    }
   ],
   "source": [
    "sat_scores, sat_cov = score_signed(expr, SAT_UP, SAT_DOWN, min_genes=10, name=\"SAT\")\n",
    "print(sat_cov)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "8f6b6bf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SAT size: (178,) NA: 0\n",
      "MPC size: (178,) NA: 0\n",
      "IL2 size: (178,) NA: 0\n",
      "\n",
      "[MERGED CHECK] shape: (177, 5)\n",
      "                   SAT       MPC       IL2  OS_time_months  OS_event\n",
      "patientId                                                           \n",
      "TCGA-2J-AAB1 -0.255525 -0.091211 -0.091641        2.169839       1.0\n",
      "TCGA-2J-AAB4 -0.426443  0.178417 -0.033635       23.966861       0.0\n",
      "TCGA-2J-AAB6  0.072369 -0.735729 -0.401843        9.632771       1.0\n",
      "TCGA-2J-AAB8  0.104286  0.046135 -0.271959        2.630108       0.0\n",
      "TCGA-2J-AAB9  0.155583 -0.048975  0.022216       20.613473       1.0\n",
      "\n",
      "NA per column:\n",
      "SAT               0\n",
      "MPC               0\n",
      "IL2               0\n",
      "OS_time_months    0\n",
      "OS_event          0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"SAT size:\", sat_scores.shape, \"NA:\", sat_scores.isna().sum())\n",
    "print(\"MPC size:\", mpc_scores.shape, \"NA:\", mpc_scores.isna().sum())\n",
    "print(\"IL2 size:\", il2_scores.shape, \"NA:\", il2_scores.isna().sum())\n",
    "\n",
    "df_check = pd.concat([sat_scores.rename(\"SAT\"),\n",
    "                      mpc_scores.rename(\"MPC\"),\n",
    "                      il2_scores.rename(\"IL2\"),\n",
    "                      clin],\n",
    "                     axis=1, join=\"inner\")\n",
    "\n",
    "print(\"\\n[MERGED CHECK] shape:\", df_check.shape)\n",
    "print(df_check.head())\n",
    "\n",
    "print(\"\\nNA per column:\")\n",
    "print(df_check.isna().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "fe727c04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[COMBO] N with score+OS: 177\n",
      "Saved combined KM plot → /Users/scottpowers/Desktop/tcga_paad_MPC_module_survival_out/MOD3/KM_COMBO.png\n",
      "Optimal cut = 0.8003307884498878    p-value = 0.03602022158904903\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from lifelines import KaplanMeierFitter\n",
    "from lifelines.statistics import logrank_test\n",
    "\n",
    "plt.rcParams[\"font.family\"] = \"Arial\"\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# 1) Build combined score from the three module score Series\n",
    "# -------------------------------------------------------------------\n",
    "# Assumes:\n",
    "#   sat_scores   (Series indexed by patientId)\n",
    "#   mpc_scores   (Series indexed by patientId)\n",
    "#   il2_scores   (Series indexed by patientId)\n",
    "#   clin         (DataFrame with OS_time_months and OS_event)\n",
    "#   OUTDIR       (Path)\n",
    "\n",
    "# Z-score each\n",
    "SAT_Z = (sat_scores - sat_scores.mean()) / sat_scores.std(ddof=0)\n",
    "MPC_Z = (mpc_scores - mpc_scores.mean()) / mpc_scores.std(ddof=0)\n",
    "IL2_Z = (il2_scores - il2_scores.mean()) / il2_scores.std(ddof=0)\n",
    "\n",
    "# Combined biologic burden score\n",
    "combo = (SAT_Z + MPC_Z - IL2_Z).rename(\"COMBO_SCORE\")\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# 2) Merge with clinical\n",
    "# -------------------------------------------------------------------\n",
    "df_combo = pd.concat([combo, clin], axis=1, join=\"inner\").dropna(\n",
    "    subset=[\"COMBO_SCORE\", \"OS_time_months\", \"OS_event\"]\n",
    ")\n",
    "\n",
    "print(\"[COMBO] N with score+OS:\", df_combo.shape[0])\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# 3) Optimal cut search (20–80% range)\n",
    "# -------------------------------------------------------------------\n",
    "scores_sorted = df_combo[\"COMBO_SCORE\"].sort_values()\n",
    "n = len(scores_sorted)\n",
    "\n",
    "qmin = int(n * 0.20)\n",
    "qmax = int(n * 0.80)\n",
    "candidates = scores_sorted.iloc[qmin:qmax]\n",
    "\n",
    "best_cut, best_p = None, 1.0\n",
    "\n",
    "for cut in candidates:\n",
    "    grp = scores_sorted >= cut\n",
    "    hi = df_combo.loc[grp]\n",
    "    lo = df_combo.loc[~grp]\n",
    "\n",
    "    if len(hi) < 5 or len(lo) < 5:\n",
    "        continue\n",
    "\n",
    "    lr = logrank_test(\n",
    "        hi[\"OS_time_months\"], lo[\"OS_time_months\"],\n",
    "        event_observed_A=hi[\"OS_event\"],\n",
    "        event_observed_B=lo[\"OS_event\"]\n",
    "    )\n",
    "\n",
    "    if lr.p_value < best_p:\n",
    "        best_p = float(lr.p_value)\n",
    "        best_cut = float(cut)\n",
    "\n",
    "if best_cut is None:\n",
    "    best_cut = float(scores_sorted.median())\n",
    "    best_p = float(\"nan\")\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# 4) Plot KM for COMBO\n",
    "# -------------------------------------------------------------------\n",
    "df_combo = df_combo.assign(\n",
    "    group=np.where(df_combo[\"COMBO_SCORE\"] >= best_cut,\n",
    "                   \"Combined high\",\n",
    "                   \"Combined low\")\n",
    ")\n",
    "\n",
    "km = KaplanMeierFitter()\n",
    "fig, ax = plt.subplots(figsize=(4.2, 3.5), dpi=200)\n",
    "\n",
    "for group in [\"Combined high\", \"Combined low\"]:\n",
    "    sub = df_combo[df_combo[\"group\"] == group]\n",
    "    km.fit(sub[\"OS_time_months\"], sub[\"OS_event\"], label=f\"{group} (n={len(sub)})\")\n",
    "    km.plot_survival_function(ax=ax, ci_show=True)\n",
    "\n",
    "ax.set_xlabel(\"Time (months)\")\n",
    "ax.set_ylabel(\"Overall survival probability\")\n",
    "ax.set_title(f\"TCGA-PAAD: Combined Module\\ncut={best_cut:.3f}, p={best_p:.3g}\")\n",
    "ax.legend(frameon=False)\n",
    "\n",
    "fig.tight_layout()\n",
    "\n",
    "OUT = OUTDIR / \"KM_COMBO.png\"\n",
    "fig.savefig(OUT, bbox_inches=\"tight\")\n",
    "plt.close(fig)\n",
    "\n",
    "print(\"Saved combined KM plot →\", OUT)\n",
    "print(\"Optimal cut =\", best_cut, \"   p-value =\", best_p)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "4987c87c",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'mpc_score' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[117], line 13\u001b[0m\n\u001b[1;32m      7\u001b[0m plt\u001b[38;5;241m.\u001b[39mrcParams[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfont.family\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mArial\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# -------------------------\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# Build MPC dataframe\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# -------------------------\u001b[39;00m\n\u001b[1;32m     12\u001b[0m df_mpc \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat([\n\u001b[0;32m---> 13\u001b[0m     \u001b[43mmpc_score\u001b[49m\u001b[38;5;241m.\u001b[39mrename(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMPC\u001b[39m\u001b[38;5;124m\"\u001b[39m),   \u001b[38;5;66;03m# <-- your MPC signed scores\u001b[39;00m\n\u001b[1;32m     14\u001b[0m     clin\n\u001b[1;32m     15\u001b[0m ], axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, join\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minner\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mdropna(\n\u001b[1;32m     16\u001b[0m     subset\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMPC\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOS_time_months\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOS_event\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m     17\u001b[0m )\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m# -------------------------\u001b[39;00m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;66;03m# Find optimal cut\u001b[39;00m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m# -------------------------\u001b[39;00m\n\u001b[1;32m     22\u001b[0m scores_sorted \u001b[38;5;241m=\u001b[39m df_mpc[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMPC\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39msort_values()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'mpc_score' is not defined"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from lifelines import KaplanMeierFitter\n",
    "from lifelines.statistics import logrank_test\n",
    "\n",
    "plt.rcParams[\"font.family\"] = \"Arial\"\n",
    "\n",
    "# -------------------------\n",
    "# Build MPC dataframe\n",
    "# -------------------------\n",
    "df_mpc = pd.concat([\n",
    "    mpc_score.rename(\"MPC\"),   # <-- your MPC signed scores\n",
    "    clin\n",
    "], axis=1, join=\"inner\").dropna(\n",
    "    subset=[\"MPC\", \"OS_time_months\", \"OS_event\"]\n",
    ")\n",
    "\n",
    "# -------------------------\n",
    "# Find optimal cut\n",
    "# -------------------------\n",
    "scores_sorted = df_mpc[\"MPC\"].sort_values()\n",
    "n = len(scores_sorted)\n",
    "\n",
    "qmin = int(n * 0.20)\n",
    "qmax = int(n * 0.80)\n",
    "candidates = scores_sorted.iloc[qmin:qmax]\n",
    "\n",
    "best_cut, best_p = None, 1.0\n",
    "\n",
    "for cut in candidates:\n",
    "    grp = scores_sorted >= cut\n",
    "    hi = df_mpc.loc[grp]\n",
    "    lo = df_mpc.loc[~grp]\n",
    "\n",
    "    if len(hi) < 5 or len(lo) < 5:\n",
    "        continue\n",
    "\n",
    "    lr = logrank_test(\n",
    "        hi[\"OS_time_months\"], lo[\"OS_time_months\"],\n",
    "        event_observed_A=hi[\"OS_event\"],\n",
    "        event_observed_B=lo[\"OS_event\"]\n",
    "    )\n",
    "\n",
    "    if lr.p_value < best_p:\n",
    "        best_p = float(lr.p_value)\n",
    "        best_cut = float(cut)\n",
    "\n",
    "# fallback median\n",
    "if best_cut is None:\n",
    "    best_cut = float(scores_sorted.median())\n",
    "    best_p = float(\"nan\")\n",
    "\n",
    "# -------------------------\n",
    "# Plot MPC KM panel\n",
    "# -------------------------\n",
    "df_mpc = df_mpc.assign(\n",
    "    group=np.where(df_mpc[\"MPC\"] >= best_cut, \"MPC high\", \"MPC low\")\n",
    ")\n",
    "\n",
    "km = KaplanMeierFitter()\n",
    "fig, ax = plt.subplots(figsize=(4.2, 3.5), dpi=200)\n",
    "\n",
    "for grp in [\"MPC high\", \"MPC low\"]:\n",
    "    sub = df_mpc[df_mpc[\"group\"] == grp]\n",
    "    km.fit(sub[\"OS_time_months\"], sub[\"OS_event\"],\n",
    "           label=f\"{grp} (n={len(sub)})\")\n",
    "    km.plot_survival_function(ax=ax, ci_show=True)\n",
    "\n",
    "ax.set_xlabel(\"Time (months)\")\n",
    "ax.set_ylabel(\"Overall survival probability\")\n",
    "ax.set_title(f\"TCGA-PAAD: MPC module\\ncut={best_cut:.3f}, p={best_p:.3g}\")\n",
    "ax.legend(frameon=False)\n",
    "\n",
    "fig.tight_layout()\n",
    "OUT = OUTDIR / \"KM_MPC.png\"\n",
    "fig.savefig(OUT, bbox_inches=\"tight\")\n",
    "plt.close(fig)\n",
    "\n",
    "print(\"Saved MPC KM plot →\", OUT)\n",
    "print(\"Optimal cut =\", best_cut, \"   p-value =\", best_p)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "8aef0ac4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TCGA] Loading expression from: PAAD_RSEM_genes_normalized_CLEAN.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/mh/r2nrb73509z0t_wjbx9r5fg00000gn/T/ipykernel_92012/3880301122.py:58: FutureWarning: DataFrame.groupby with axis=1 is deprecated. Do `frame.T.groupby(...)` without axis instead.\n",
      "  df = df.groupby(df.columns, axis=1).mean(numeric_only=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TCGA] patient-level shape (genes x patients): (20502, 178)\n",
      "[COVERAGE] UP 113/185 | DOWN 15/25\n",
      "[CLIN] rows with OS: 184\n",
      "[MERGE] N with score+OS: 177\n",
      "[KM] SAT: p=0.674, median=0.020 -> /Users/scottpowers/Desktop/tcga_paad_SAT_module_survival_out/SAT/SAT_KM.png\n"
     ]
    }
   ],
   "source": [
    "# --- TCGA PAAD survival • SAT signed score (single-module script) ---\n",
    "\n",
    "import pandas as pd, numpy as np\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "from lifelines import KaplanMeierFitter\n",
    "from lifelines.statistics import logrank_test\n",
    "\n",
    "DESKTOP = Path.home() / \"Desktop\"\n",
    "expr_paths = [\n",
    "    DESKTOP / \"PAAD_RSEM_genes_normalized_CLEAN.csv\",\n",
    "    DESKTOP / \"PAAD.rnaseqv2__illuminahiseq_rnaseqv2__unc_edu__Level_3__RSEM_genes_normalized__data.data.csv\",\n",
    "]\n",
    "clin_path = DESKTOP / \"paad_tcga_pan_can_atlas_2018_clinical_data.csv\"\n",
    "OUTDIR = DESKTOP / \"tcga_paad_SAT_module_survival_out\" / \"SAT\"\n",
    "OUTDIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "SAT_UP = [\n",
    "    \"ABHD8\",\"AC004870.4\",\"AC005920.1\",\"AC009041.1\",\"AC009309.1\",\"AC011498.1\",\"AC012447.1\",\"AC018521.5\",\n",
    "    \"AC018754.1\",\"AC027237.2\",\"AC068338.2\",\"AC072061.1\",\"AC079305.3\",\"AC079807.1\",\"AC087623.2\",\"AC090403.1\",\n",
    "    \"AC091271.1\",\"AC092287.1\",\"AC092910.3\",\"AC093323.1\",\"AC099778.1\",\"AC107959.2\",\"AC125611.3\",\"AC144652.1\",\n",
    "    \"AC239799.2\",\"AC253572.2\",\"ACBD7\",\"AFMID\",\"AHCY\",\"AL021155.5\",\"AL022069.1\",\"AL031963.3\",\"AL049869.2\",\n",
    "    \"AL121574.1\",\"AL133523.1\",\"AL139106.1\",\"AL139246.5\",\"AL355075.4\",\"AL360012.1\",\"AL365436.2\",\"AL592295.5\",\n",
    "    \"AL662844.4\",\"AP001160.1\",\"AP002381.2\",\"AP002813.1\",\"ARL4D\",\"ATP2B1-AS1\",\"ATRIP\",\"BAMBI\",\"BHLHE40-AS1\",\n",
    "    \"BOLA1\",\"BUD23\",\"C12orf65\",\"C19orf48\",\"C2CD4B\",\"C6orf120\",\"CABYR\",\"CCDC9\",\"CCNE2\",\"CDKN2AIP\",\"CHCHD7\",\n",
    "    \"CITED2\",\"CROCC\",\"CSKMT\",\"CTH\",\"DALRD3\",\"DRAIC\",\"DUSP28\",\"EAF2\",\"EIF4A3\",\"FOXA3\",\"FOXL1\",\"GADD45B\",\"GLA\",\n",
    "    \"GOT1\",\"GRPEL1\",\"GTF2A1\",\"GTF2B\",\"HEXIM1\",\"HIST1H2AG\",\"HIST1H2AH\",\"HIST1H2AL\",\"HIST1H2BJ\",\"HIST1H2BN\",\n",
    "    \"HIST1H3A\",\"HIST1H3J\",\"HIST1H4A\",\"HIST1H4C\",\"HIST1H4E\",\"HIST2H2AC\",\"HIST2H3PS2\",\"HIST3H2A\",\"HIST4H4\",\"HMBS\",\n",
    "    \"HSPA2\",\"ID2\",\"IDI1\",\"ING1\",\"KCTD5\",\"KIF9\",\"KLHL11\",\"LAP3\",\"LIFR-AS1\",\"LINC01970\",\"LINC02029\",\"LINC02363\",\n",
    "    \"LRG1\",\"LRTOMT\",\"MAFB\",\"MED29\",\"MEPCE\",\"MIR17HG\",\"MORF4L2-AS1\",\"MTHFD2\",\"MYCL\",\"MYOSLID\",\"NANOS1\",\"NPW\",\n",
    "    \"NRARP\",\"OAT\",\"OSER1-DT\",\"OSGIN1\",\"PHYH\",\"PICART1\",\"PIEZO1\",\"PIK3R3\",\"PLIN5\",\"PLK2\",\"PMAIP1\",\"PMEL\",\"PNKD\",\n",
    "    \"POU3F1\",\"PPP1R3C\",\"PRMT5-AS1\",\"PRR3\",\"PTCH2\",\"PTPN6\",\"RAB26\",\"RALY-AS1\",\"RASL11A\",\"RND1\",\"RNF223\",\"RUVBL2\",\n",
    "    \"SAE1\",\"SENP8\",\"SIAH2-AS1\",\"SIRT2\",\"SLC7A5\",\"SNHG12\",\"SNHG5\",\"SNHG8\",\"SREBF2-AS1\",\"SRSF7\",\"STARD5\",\"TBPL1\",\n",
    "    \"TCTA\",\"THAP9\",\"TLCD1\",\"TM7SF2\",\"TMEM107\",\"TMEM171\",\"TMEM69\",\"TNFRSF10D\",\"TNK1\",\"TRAM2-AS1\",\"TTC33\",\"UAP1\",\n",
    "    \"UBAC2-AS1\",\"UBE2D3-AS1\",\"UBE2S\",\"UGDH\",\"WDR74\",\"Z93241.1\",\"Z99127.4\",\"ZC3H10\",\"ZCWPW1\",\"ZFAS1\",\"ZFX-AS1\",\n",
    "    \"ZNF574\",\"ZNF584\",\"ZNF622\",\"ZNF687-AS1\",\"ZNF844\",\"ZNF92\",\"ZSWIM3\"\n",
    "]\n",
    "SAT_DOWN = [\n",
    "    \"PAX5\",\"AC117386.2\",\"PRSS55\",\"RPS16\",\"GDF7\",\"PAK4\",\"AC022144.1\",\"AC092745.5\",\"AL670729.3\",\n",
    "    \"DLEU2L\",\"ELP3\",\"KCNC2\",\"MAP4K1\",\"AL161729.4\",\"SV2C\",\"RGS11\",\"AC005498.1\",\"WFDC5\",\"PSENEN\",\n",
    "    \"LINC01956\",\"AC115485.1\",\"CYSLTR2\",\"ASMTL-AS1\",\"AP002001.3\",\"FAM153B\"\n",
    "]\n",
    "\n",
    "def load_tcga_expr(paths):\n",
    "    path = next((p for p in paths if p.exists()), None)\n",
    "    if path is None: raise FileNotFoundError(\"No TCGA PAAD expression file found on Desktop.\")\n",
    "    print(f\"[TCGA] Loading expression from: {path.name}\")\n",
    "    df = pd.read_csv(path, low_memory=False)\n",
    "    gene_col = None\n",
    "    for c in [\"Hugo_Symbol\",\"gene\",\"Gene\",\"GeneSymbol\",\"gene_name\", df.columns[0]]:\n",
    "        if c in df.columns: gene_col = c; break\n",
    "    if gene_col is None: raise ValueError(\"Could not infer gene column.\")\n",
    "    df = df.rename(columns={gene_col:\"Gene\"})\n",
    "    df[\"Gene\"] = df[\"Gene\"].astype(str).str.split(\"|\").str[0]\n",
    "    df = df.set_index(\"Gene\")\n",
    "    df = df.apply(pd.to_numeric, errors=\"coerce\").dropna(how=\"all\", axis=0).dropna(how=\"all\", axis=1)\n",
    "    df.columns = pd.Index([str(c)[:12] for c in df.columns], name=\"patientId\")\n",
    "    df = df.groupby(df.columns, axis=1).mean(numeric_only=True)\n",
    "    print(f\"[TCGA] patient-level shape (genes x patients): {df.shape}\")\n",
    "    return df\n",
    "\n",
    "def score_signed(expr, up_genes, down_genes, min_genes=10, name=\"signed_score\"):\n",
    "    Z = expr.apply(lambda x: (x - x.mean()) / (x.std(ddof=0) + 1e-9), axis=1)\n",
    "    up = pd.Index(up_genes).intersection(Z.index); dn = pd.Index(down_genes).intersection(Z.index)\n",
    "    cov = {\"up_used\": int(up.size), \"up_total\": len(up_genes), \"down_used\": int(dn.size), \"down_total\": len(down_genes)}\n",
    "    if up.size < min_genes or dn.size < min_genes:\n",
    "        return pd.Series(np.nan, index=Z.columns, name=name), cov\n",
    "    return (Z.loc[up].mean(axis=0) - Z.loc[dn].mean(axis=0)).rename(name), cov\n",
    "\n",
    "def load_clin(path):\n",
    "    if not path.exists(): raise FileNotFoundError(\"PanCan clinical file not found on Desktop.\")\n",
    "    clin = pd.read_csv(path)\n",
    "    for c in [\"patientId\",\"OS_MONTHS\",\"OS_STATUS\"]:\n",
    "        if c not in clin.columns: raise ValueError(\"Missing columns in clinical file.\")\n",
    "    clin[\"patientId\"] = clin[\"patientId\"].astype(str).str[:12]\n",
    "    status = clin[\"OS_STATUS\"].astype(str).str.upper().str.contains(\"DECEASED\")\n",
    "    out = pd.DataFrame({\n",
    "        \"patientId\": clin[\"patientId\"],\n",
    "        \"OS_time_months\": pd.to_numeric(clin[\"OS_MONTHS\"], errors=\"coerce\"),\n",
    "        \"OS_event\": status.astype(float)\n",
    "    }).dropna(subset=[\"OS_time_months\",\"OS_event\"]).drop_duplicates(subset=[\"patientId\"]).set_index(\"patientId\")\n",
    "    print(f\"[CLIN] rows with OS: {out.shape[0]}\")\n",
    "    return out\n",
    "\n",
    "def zscore_series(s):\n",
    "    mu, sd = s.mean(), s.std(ddof=0)\n",
    "    return s*0 if (sd == 0 or np.isnan(sd)) else (s - mu) / sd\n",
    "\n",
    "def km_plot_and_logrank(df, score_col, title, out_png, hi_label=\"High SAT\", lo_label=\"Low SAT\"):\n",
    "    med = df[score_col].median()\n",
    "    df = df.assign(group=np.where(df[score_col] >= med, hi_label, lo_label)).copy()\n",
    "    hi = df[\"group\"] == hi_label; lo = df[\"group\"] == lo_label\n",
    "    lr = logrank_test(df.loc[hi,\"OS_time_months\"], df.loc[lo,\"OS_time_months\"],\n",
    "                      event_observed_A=df.loc[hi,\"OS_event\"], event_observed_B=df.loc[lo,\"OS_event\"])\n",
    "    pval = float(lr.p_value)\n",
    "    km = KaplanMeierFitter()\n",
    "    import matplotlib.pyplot as plt\n",
    "    fig, ax = plt.subplots(figsize=(6.5,5), dpi=160)\n",
    "    for label in (hi_label, lo_label):\n",
    "        sub = df[df[\"group\"] == label]\n",
    "        if sub.empty: continue\n",
    "        km.fit(sub[\"OS_time_months\"], sub[\"OS_event\"], label=label)\n",
    "        sf = km.survival_function_.iloc[:,0]; t = sf.index.values; y = sf.values\n",
    "        ax.step(t, y, where=\"post\", label=label)\n",
    "        ci = km.confidence_interval_; lo_ci = ci.iloc[:,0].values; hi_ci = ci.iloc[:,1].values\n",
    "        ax.fill_between(t, lo_ci, hi_ci, step=\"post\", alpha=0.20)\n",
    "    ax.set_xlabel(\"Time (months)\"); ax.set_ylabel(\"Overall survival probability\")\n",
    "    ax.set_title(f\"{title}\\nlog-rank p = {pval:.3g}\"); ax.legend(); fig.tight_layout()\n",
    "    fig.savefig(out_png, bbox_inches=\"tight\"); plt.close(fig)\n",
    "    return pval, float(med)\n",
    "\n",
    "# ----------------- run -----------------\n",
    "expr = load_tcga_expr(expr_paths)\n",
    "scores, cov = score_signed(expr, SAT_UP, SAT_DOWN, min_genes=10, name=\"SAT\")\n",
    "print(f\"[COVERAGE] UP {cov['up_used']}/{cov['up_total']} | DOWN {cov['down_used']}/{cov['down_total']}\")\n",
    "clin = load_clin(clin_path)\n",
    "\n",
    "df = pd.concat([scores, clin], axis=1, join=\"inner\").dropna(subset=[\"SAT\",\"OS_time_months\",\"OS_event\"])\n",
    "print(f\"[MERGE] N with score+OS: {df.shape[0]}\")\n",
    "scores.rename(\"SAT\").to_csv(OUTDIR / \"SAT_signed_scores.csv\")\n",
    "zscore_series(scores).rename(\"SAT_Z\").to_csv(OUTDIR / \"SAT_signed_scores_Z.csv\")\n",
    "\n",
    "if df.shape[0] >= 10 and np.isfinite(df[\"SAT\"]).any():\n",
    "    p, med = km_plot_and_logrank(df, \"SAT\", \"TCGA-PAAD: SAT signed score (median split)\", OUTDIR / \"SAT_KM.png\")\n",
    "    print(f\"[KM] SAT: p={p:.3g}, median={med:.3f} -> {OUTDIR/'SAT_KM.png'}\")\n",
    "    df.assign(group=np.where(df[\"SAT\"]>=med, \"High SAT\",\"Low SAT\")).to_csv(OUTDIR / \"SAT_scores_OS_group.csv\")\n",
    "else:\n",
    "    print(\"[SKIP] Not enough valid cases for KM.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "31b01fc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TCGA] Loading expression from: PAAD_RSEM_genes_normalized_CLEAN.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/mh/r2nrb73509z0t_wjbx9r5fg00000gn/T/ipykernel_92012/1066461206.py:49: FutureWarning: DataFrame.groupby with axis=1 is deprecated. Do `frame.T.groupby(...)` without axis instead.\n",
      "  df = df.groupby(df.columns, axis=1).mean(numeric_only=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TCGA] patient-level shape (genes x patients): (20502, 178)\n",
      "[COVERAGE] UP 102/118 | DOWN 13/20\n",
      "[CLIN] rows with OS: 184\n",
      "[MERGE] N with score+OS: 177\n",
      "[KM optimal] IGE: cut=0.194, p=0.387 -> /Users/scottpowers/Desktop/tcga_paad_IGE_KM_module_survival_out/IGE_opt/IGE_KM_opt.png\n"
     ]
    }
   ],
   "source": [
    "# --- TCGA PAAD survival • IGE signed score (optimal KM cut) ---\n",
    "\n",
    "import pandas as pd, numpy as np\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "from lifelines import KaplanMeierFitter\n",
    "from lifelines.statistics import logrank_test\n",
    "\n",
    "# ----------------- INPUTS -----------------\n",
    "DESKTOP = Path.home() / \"Desktop\"\n",
    "expr_paths = [\n",
    "    DESKTOP / \"PAAD_RSEM_genes_normalized_CLEAN.csv\",\n",
    "    DESKTOP / \"PAAD.rnaseqv2__illuminahiseq_rnaseqv2__unc_edu__Level_3__RSEM_genes_normalized__data.data.csv\",\n",
    "]\n",
    "clin_path = DESKTOP / \"paad_tcga_pan_can_atlas_2018_clinical_data.csv\"\n",
    "OUTDIR = DESKTOP / \"tcga_paad_IGE_KM_module_survival_out\" / \"IGE_opt\"\n",
    "OUTDIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# IGE genes\n",
    "IGE_UP = [\n",
    "\"PFN2\",\"SET\",\"LGALS1\",\"PDLIM4\",\"EIF5A\",\"F8A1\",\"BANF1\",\"CTDNEP1\",\"TRAPPC1\",\"AMZ2\",\"PTGES3\",\"ST13\",\"FTH1\",\"PCBP1\",\n",
    "\"NAA10\",\"ARPC5L\",\"ETFB\",\"CCDC124\",\"SSR2\",\"PGLS\",\"SELENOH\",\"GSTP1\",\"NDUFB7\",\"AURKAIP1\",\"GCHFR\",\"MYL6\",\"AP2S1\",\n",
    "\"S100A13\",\"C9orf16\",\"KRT8\",\"PRKCSH\",\"CST3\",\"PET100\",\"DNAJA2\",\"VPS35\",\"VDAC1\",\"MGST3\",\"PRR13\",\"OCIAD2\",\"FUOM\",\"MIA\",\n",
    "\"RPN1\",\"FUCA2\",\"TMED4\",\"ERGIC3\",\"DDOST\",\"NAXE\",\"SNRPD1\",\"SKP1\",\"CNBP\",\"ATP5MC3\",\"SLC25A5\",\"LSM4\",\"NDUFAB1\",\"PCBD1\",\n",
    "\"HINT1\",\"ADI1\",\"NENF\",\"MRPL43\",\"VKORC1\",\"EMC4\",\"COA3\",\"NEDD8\",\"CHCHD2\",\"PRDX5\",\"WDR83OS\",\"NDUFA4\",\"GABARAP\",\"PHPT1\",\n",
    "\"UFC1\",\"MDH1\",\"ATP5F1E\",\"MRPL41\",\"UBL5\",\"COX5B\",\"ELOB\",\"ATP5ME\",\"UQCRB\",\"SEM1\",\"NDUFB1\",\"COX6C\",\"ATP6V1F\",\"HNRNPA1\",\n",
    "\"HIGD2A\",\"POLR2I\",\"METTL26\",\"NDUFB4\",\"OST4\",\"C19orf53\",\"RPL36AL\",\"PPIA\",\"COPS9\",\"COX8A\",\"COX5A\",\"RPL36\",\"RPS15\",\n",
    "\"RPS27\",\"RPS11\",\"FTL\",\"SNHG29\",\"NACA\",\"RPS17\",\"RPL23\",\"RPL39\",\"RPS21\",\"RPL9\",\"RPL15\",\"RPL34\",\"RPL27A\",\"RPL36A\",\n",
    "\"RPL38\",\"RPS26\",\"RPS14\",\"RPL35\",\"RPL37A\",\"RPL37\",\"RPL12\",\"RPS29\"\n",
    "]\n",
    "IGE_DOWN = [\"STN1\",\"NRG4\",\"IQSEC2\",\"IYD\",\"CHD9\",\"APBB1IP\",\"TMEM238\",\"REX1BD\",\"IFI27\",\"CYBA\",\"METRNL\",\"AKR7A2\",\n",
    "            \"SULT1A1\",\"ARHGEF35\",\"AC008397.1\",\"KLK11\",\"DELE1\",\"MISP\",\"FAM234A\",\"CMBL\"]\n",
    "\n",
    "# ----------------- helpers -----------------\n",
    "def load_tcga_expr(expr_paths):\n",
    "    path = next((p for p in expr_paths if p.exists()), None)\n",
    "    if path is None: raise FileNotFoundError(\"No TCGA PAAD expression file found on Desktop.\")\n",
    "    print(f\"[TCGA] Loading expression from: {path.name}\")\n",
    "    df = pd.read_csv(path, low_memory=False)\n",
    "    gene_col = None\n",
    "    for c in [\"Hugo_Symbol\",\"gene\",\"Gene\",\"GeneSymbol\",\"gene_name\", df.columns[0]]:\n",
    "        if c in df.columns: gene_col = c; break\n",
    "    if gene_col is None: raise ValueError(\"Could not infer gene column.\")\n",
    "    df = df.rename(columns={gene_col:\"Gene\"})\n",
    "    df[\"Gene\"] = df[\"Gene\"].astype(str).str.split(\"|\").str[0]\n",
    "    df = df.set_index(\"Gene\")\n",
    "    df = df.apply(pd.to_numeric, errors=\"coerce\").dropna(how=\"all\", axis=0).dropna(how=\"all\", axis=1)\n",
    "    df.columns = pd.Index([str(c)[:12] for c in df.columns], name=\"patientId\")\n",
    "    df = df.groupby(df.columns, axis=1).mean(numeric_only=True)\n",
    "    print(f\"[TCGA] patient-level shape (genes x patients): {df.shape}\")\n",
    "    return df\n",
    "\n",
    "def score_signed(expr, up_genes, down_genes, min_genes=10, name=\"signed_score\"):\n",
    "    Z = expr.apply(lambda x: (x - x.mean()) / (x.std(ddof=0) + 1e-9), axis=1)\n",
    "    up = pd.Index(up_genes).intersection(Z.index); dn = pd.Index(down_genes).intersection(Z.index)\n",
    "    cov = {\"up_used\": int(up.size), \"up_total\": len(up_genes), \"down_used\": int(dn.size), \"down_total\": len(down_genes)}\n",
    "    if up.size < min_genes or dn.size < min_genes:\n",
    "        return pd.Series(np.nan, index=Z.columns, name=name), cov\n",
    "    return (Z.loc[up].mean(axis=0) - Z.loc[dn].mean(axis=0)).rename(name), cov\n",
    "\n",
    "def load_clin(path):\n",
    "    if not path.exists(): raise FileNotFoundError(\"PanCan clinical file not found on Desktop.\")\n",
    "    clin = pd.read_csv(path)\n",
    "    need = [\"patientId\",\"OS_MONTHS\",\"OS_STATUS\"]\n",
    "    miss = [c for c in need if c not in clin.columns]\n",
    "    if miss: raise ValueError(f\"Missing columns in clinical file: {miss}\")\n",
    "    clin[\"patientId\"] = clin[\"patientId\"].astype(str).str[:12]\n",
    "    status = clin[\"OS_STATUS\"].astype(str).str.upper().str.contains(\"DECEASED\")\n",
    "    out = pd.DataFrame({\n",
    "        \"patientId\": clin[\"patientId\"],\n",
    "        \"OS_time_months\": pd.to_numeric(clin[\"OS_MONTHS\"], errors=\"coerce\"),\n",
    "        \"OS_event\": status.astype(float)\n",
    "    }).dropna(subset=[\"OS_time_months\",\"OS_event\"]).drop_duplicates(subset=[\"patientId\"]).set_index(\"patientId\")\n",
    "    print(f\"[CLIN] rows with OS: {out.shape[0]}\")\n",
    "    return out\n",
    "\n",
    "def zscore_series(s):\n",
    "    mu, sd = s.mean(), s.std(ddof=0)\n",
    "    return s*0 if (sd == 0 or np.isnan(sd)) else (s - mu) / sd\n",
    "\n",
    "def km_plot_and_logrank_optimal(df, score_col, title, out_png,\n",
    "                                min_quantile=0.2, max_quantile=0.8,\n",
    "                                hi_label=\"High IGE\", lo_label=\"Low IGE\"):\n",
    "    scores = df[score_col].dropna().sort_values()\n",
    "    n = len(scores)\n",
    "    best_cut, best_p, best_lr = None, 1.0, None\n",
    "    qmin = int(n * min_quantile); qmax = int(n * max_quantile)\n",
    "    candidates = scores.iloc[qmin:qmax]\n",
    "    for cut in candidates:\n",
    "        group = scores >= cut\n",
    "        hi = df.loc[group, \"OS_time_months\"]; lo = df.loc[~group, \"OS_time_months\"]\n",
    "        hi_e = df.loc[group, \"OS_event\"];     lo_e = df.loc[~group, \"OS_event\"]\n",
    "        if len(hi) < 5 or len(lo) < 5: continue\n",
    "        lr = logrank_test(hi, lo, event_observed_A=hi_e, event_observed_B=lo_e)\n",
    "        if lr.p_value < best_p: best_p, best_cut, best_lr = lr.p_value, float(cut), lr\n",
    "    if best_cut is None:\n",
    "        print(\"[WARN] No valid cutpoint in range — using median.\")\n",
    "        best_cut = float(scores.median())\n",
    "        best_p = float(\"nan\")\n",
    "\n",
    "    df = df.assign(group=np.where(df[score_col] >= best_cut, hi_label, lo_label))\n",
    "    km = KaplanMeierFitter()\n",
    "    fig, ax = plt.subplots(figsize=(6.5,5), dpi=160)\n",
    "    for label in (hi_label, lo_label):\n",
    "        sub = df[df[\"group\"] == label]\n",
    "        if sub.empty: continue\n",
    "        km.fit(sub[\"OS_time_months\"], sub[\"OS_event\"], label=f\"{label} (n={len(sub)})\")\n",
    "        sf = km.survival_function_.iloc[:,0]; t = sf.index.values; y = sf.values\n",
    "        ax.step(t, y, where=\"post\", label=km._label)\n",
    "        ci = km.confidence_interval_; ax.fill_between(t, ci.iloc[:,0].values, ci.iloc[:,1].values, step=\"post\", alpha=0.20)\n",
    "    ax.set_xlabel(\"Time (months)\"); ax.set_ylabel(\"Overall survival probability\")\n",
    "    ax.set_title(f\"{title}\\noptimal cut={best_cut:.3f}, p={best_p:.3g}\")\n",
    "    ax.legend(); fig.tight_layout(); fig.savefig(out_png, bbox_inches=\"tight\"); plt.close(fig)\n",
    "    return best_cut, best_p\n",
    "\n",
    "# ----------------- run -----------------\n",
    "expr = load_tcga_expr(expr_paths)\n",
    "scores, cov = score_signed(expr, IGE_UP, IGE_DOWN, min_genes=10, name=\"IGE\")\n",
    "print(f\"[COVERAGE] UP {cov['up_used']}/{cov['up_total']} | DOWN {cov['down_used']}/{cov['down_total']}\")\n",
    "clin = load_clin(clin_path)\n",
    "\n",
    "df = pd.concat([scores, clin], axis=1, join=\"inner\").dropna(subset=[\"IGE\",\"OS_time_months\",\"OS_event\"])\n",
    "print(f\"[MERGE] N with score+OS: {df.shape[0]}\")\n",
    "scores.rename(\"IGE\").to_csv(OUTDIR / \"IGE_signed_scores.csv\")\n",
    "zscore_series(scores).rename(\"IGE_Z\").to_csv(OUTDIR / \"IGE_signed_scores_Z.csv\")\n",
    "\n",
    "if df.shape[0] >= 10 and np.isfinite(df[\"IGE\"]).any():\n",
    "    cut, p = km_plot_and_logrank_optimal(df, \"IGE\", \"TCGA-PAAD: IGE signed score (optimal cut)\", OUTDIR / \"IGE_KM_opt.png\")\n",
    "    print(f\"[KM optimal] IGE: cut={cut:.3f}, p={p:.3g} -> {OUTDIR/'IGE_KM_opt.png'}\")\n",
    "    df.assign(group=np.where(df[\"IGE\"]>=cut, \"High IGE\", \"Low IGE\")).to_csv(OUTDIR / \"IGE_scores_OS_group_opt.csv\")\n",
    "else:\n",
    "    print(\"[SKIP] Not enough valid cases for KM.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "bee5861f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved IGE KM plot → /Users/scottpowers/Desktop/tcga_paad_IGE_KM_module_survival_out/IGE_opt/KM_IGE.png\n",
      "Optimal cut = 0.19400999499702265    p-value = 0.38711776921505847\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from lifelines import KaplanMeierFitter\n",
    "from lifelines.statistics import logrank_test\n",
    "\n",
    "plt.rcParams[\"font.family\"] = \"Arial\"\n",
    "\n",
    "# -------------------------\n",
    "# Build IGE dataframe\n",
    "# -------------------------\n",
    "df_ige = pd.concat([\n",
    "    scores.rename(\"IGE\"),    # your IGE signed scores\n",
    "    clin\n",
    "], axis=1, join=\"inner\").dropna(\n",
    "    subset=[\"IGE\", \"OS_time_months\", \"OS_event\"]\n",
    ")\n",
    "\n",
    "# -------------------------\n",
    "# Optimal cut search\n",
    "# -------------------------\n",
    "scores_sorted = df_ige[\"IGE\"].sort_values()\n",
    "n = len(scores_sorted)\n",
    "\n",
    "qmin = int(n * 0.20)\n",
    "qmax = int(n * 0.80)\n",
    "candidates = scores_sorted.iloc[qmin:qmax]\n",
    "\n",
    "best_cut, best_p = None, 1.0\n",
    "\n",
    "for cut in candidates:\n",
    "    grp = scores_sorted >= cut\n",
    "    hi = df_ige.loc[grp]\n",
    "    lo = df_ige.loc[~grp]\n",
    "\n",
    "    if len(hi) < 5 or len(lo) < 5:\n",
    "        continue\n",
    "\n",
    "    lr = logrank_test(\n",
    "        hi[\"OS_time_months\"], lo[\"OS_time_months\"],\n",
    "        event_observed_A=hi[\"OS_event\"],\n",
    "        event_observed_B=lo[\"OS_event\"]\n",
    "    )\n",
    "\n",
    "    if lr.p_value < best_p:\n",
    "        best_p = float(lr.p_value)\n",
    "        best_cut = float(cut)\n",
    "\n",
    "# fallback median\n",
    "if best_cut is None:\n",
    "    best_cut = float(scores_sorted.median())\n",
    "    best_p = float(\"nan\")\n",
    "\n",
    "# -------------------------\n",
    "# Plot KM for IGE\n",
    "# -------------------------\n",
    "df_ige = df_ige.assign(\n",
    "    group=np.where(df_ige[\"IGE\"] >= best_cut, \"IGE high\", \"IGE low\")\n",
    ")\n",
    "\n",
    "km = KaplanMeierFitter()\n",
    "fig, ax = plt.subplots(figsize=(4.2, 3.5), dpi=200)\n",
    "\n",
    "for grp in [\"IGE high\", \"IGE low\"]:\n",
    "    sub = df_ige[df_ige[\"group\"] == grp]\n",
    "    km.fit(sub[\"OS_time_months\"], sub[\"OS_event\"], label=f\"{grp} (n={len(sub)})\")\n",
    "    km.plot_survival_function(ax=ax, ci_show=True)\n",
    "\n",
    "ax.set_xlabel(\"Time (months)\")\n",
    "ax.set_ylabel(\"Overall survival probability\")\n",
    "ax.set_title(f\"TCGA-PAAD: IGE module\\ncut={best_cut:.3f}, p={best_p:.3g}\")\n",
    "ax.legend(frameon=False)\n",
    "\n",
    "fig.tight_layout()\n",
    "OUT = OUTDIR / \"KM_IGE.png\"\n",
    "fig.savefig(OUT, bbox_inches=\"tight\")\n",
    "plt.close(fig)\n",
    "\n",
    "print(\"Saved IGE KM plot →\", OUT)\n",
    "print(\"Optimal cut =\", best_cut, \"   p-value =\", best_p)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "293821f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TCGA] Loading expression from: PAAD_RSEM_genes_normalized_CLEAN.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/mh/r2nrb73509z0t_wjbx9r5fg00000gn/T/ipykernel_92012/3031472702.py:59: FutureWarning: DataFrame.groupby with axis=1 is deprecated. Do `frame.T.groupby(...)` without axis instead.\n",
      "  df = df.groupby(df.columns, axis=1).mean(numeric_only=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TCGA] patient-level shape (genes x patients): (20502, 178)\n",
      "[COVERAGE] UP 113/185 | DOWN 15/25\n",
      "[CLIN] rows with OS: 184\n",
      "[MERGE] N with score+OS: 177\n",
      "[KM optimal] SAT: cut=0.144, p=0.0384 -> /Users/scottpowers/Desktop/tcga_paad_SAT_KM_module_survival_out/SAT_opt/SAT_KM_opt.png\n"
     ]
    }
   ],
   "source": [
    "# --- TCGA PAAD survival • SAT signed score (optimal KM cut) ---\n",
    "\n",
    "import pandas as pd, numpy as np\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "from lifelines import KaplanMeierFitter\n",
    "from lifelines.statistics import logrank_test\n",
    "\n",
    "DESKTOP = Path.home() / \"Desktop\"\n",
    "expr_paths = [\n",
    "    DESKTOP / \"PAAD_RSEM_genes_normalized_CLEAN.csv\",\n",
    "    DESKTOP / \"PAAD.rnaseqv2__illuminahiseq_rnaseqv2__unc_edu__Level_3__RSEM_genes_normalized__data.data.csv\",\n",
    "]\n",
    "clin_path = DESKTOP / \"paad_tcga_pan_can_atlas_2018_clinical_data.csv\"\n",
    "OUTDIR = DESKTOP / \"tcga_paad_SAT_KM_module_survival_out\" / \"SAT_opt\"\n",
    "OUTDIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# SAT gene sets (from your lists)\n",
    "SAT_UP = [\n",
    "    \"ABHD8\",\"AC004870.4\",\"AC005920.1\",\"AC009041.1\",\"AC009309.1\",\"AC011498.1\",\"AC012447.1\",\"AC018521.5\",\n",
    "    \"AC018754.1\",\"AC027237.2\",\"AC068338.2\",\"AC072061.1\",\"AC079305.3\",\"AC079807.1\",\"AC087623.2\",\"AC090403.1\",\n",
    "    \"AC091271.1\",\"AC092287.1\",\"AC092910.3\",\"AC093323.1\",\"AC099778.1\",\"AC107959.2\",\"AC125611.3\",\"AC144652.1\",\n",
    "    \"AC239799.2\",\"AC253572.2\",\"ACBD7\",\"AFMID\",\"AHCY\",\"AL021155.5\",\"AL022069.1\",\"AL031963.3\",\"AL049869.2\",\n",
    "    \"AL121574.1\",\"AL133523.1\",\"AL139106.1\",\"AL139246.5\",\"AL355075.4\",\"AL360012.1\",\"AL365436.2\",\"AL592295.5\",\n",
    "    \"AL662844.4\",\"AP001160.1\",\"AP002381.2\",\"AP002813.1\",\"ARL4D\",\"ATP2B1-AS1\",\"ATRIP\",\"BAMBI\",\"BHLHE40-AS1\",\n",
    "    \"BOLA1\",\"BUD23\",\"C12orf65\",\"C19orf48\",\"C2CD4B\",\"C6orf120\",\"CABYR\",\"CCDC9\",\"CCNE2\",\"CDKN2AIP\",\"CHCHD7\",\n",
    "    \"CITED2\",\"CROCC\",\"CSKMT\",\"CTH\",\"DALRD3\",\"DRAIC\",\"DUSP28\",\"EAF2\",\"EIF4A3\",\"FOXA3\",\"FOXL1\",\"GADD45B\",\"GLA\",\n",
    "    \"GOT1\",\"GRPEL1\",\"GTF2A1\",\"GTF2B\",\"HEXIM1\",\"HIST1H2AG\",\"HIST1H2AH\",\"HIST1H2AL\",\"HIST1H2BJ\",\"HIST1H2BN\",\n",
    "    \"HIST1H3A\",\"HIST1H3J\",\"HIST1H4A\",\"HIST1H4C\",\"HIST1H4E\",\"HIST2H2AC\",\"HIST2H3PS2\",\"HIST3H2A\",\"HIST4H4\",\"HMBS\",\n",
    "    \"HSPA2\",\"ID2\",\"IDI1\",\"ING1\",\"KCTD5\",\"KIF9\",\"KLHL11\",\"LAP3\",\"LIFR-AS1\",\"LINC01970\",\"LINC02029\",\"LINC02363\",\n",
    "    \"LRG1\",\"LRTOMT\",\"MAFB\",\"MED29\",\"MEPCE\",\"MIR17HG\",\"MORF4L2-AS1\",\"MTHFD2\",\"MYCL\",\"MYOSLID\",\"NANOS1\",\"NPW\",\n",
    "    \"NRARP\",\"OAT\",\"OSER1-DT\",\"OSGIN1\",\"PHYH\",\"PICART1\",\"PIEZO1\",\"PIK3R3\",\"PLIN5\",\"PLK2\",\"PMAIP1\",\"PMEL\",\"PNKD\",\n",
    "    \"POU3F1\",\"PPP1R3C\",\"PRMT5-AS1\",\"PRR3\",\"PTCH2\",\"PTPN6\",\"RAB26\",\"RALY-AS1\",\"RASL11A\",\"RND1\",\"RNF223\",\"RUVBL2\",\n",
    "    \"SAE1\",\"SENP8\",\"SIAH2-AS1\",\"SIRT2\",\"SLC7A5\",\"SNHG12\",\"SNHG5\",\"SNHG8\",\"SREBF2-AS1\",\"SRSF7\",\"STARD5\",\"TBPL1\",\n",
    "    \"TCTA\",\"THAP9\",\"TLCD1\",\"TM7SF2\",\"TMEM107\",\"TMEM171\",\"TMEM69\",\"TNFRSF10D\",\"TNK1\",\"TRAM2-AS1\",\"TTC33\",\"UAP1\",\n",
    "    \"UBAC2-AS1\",\"UBE2D3-AS1\",\"UBE2S\",\"UGDH\",\"WDR74\",\"Z93241.1\",\"Z99127.4\",\"ZC3H10\",\"ZCWPW1\",\"ZFAS1\",\"ZFX-AS1\",\n",
    "    \"ZNF574\",\"ZNF584\",\"ZNF622\",\"ZNF687-AS1\",\"ZNF844\",\"ZNF92\",\"ZSWIM3\"\n",
    "]\n",
    "SAT_DOWN = [\n",
    "    \"PAX5\",\"AC117386.2\",\"PRSS55\",\"RPS16\",\"GDF7\",\"PAK4\",\"AC022144.1\",\"AC092745.5\",\"AL670729.3\",\n",
    "    \"DLEU2L\",\"ELP3\",\"KCNC2\",\"MAP4K1\",\"AL161729.4\",\"SV2C\",\"RGS11\",\"AC005498.1\",\"WFDC5\",\"PSENEN\",\n",
    "    \"LINC01956\",\"AC115485.1\",\"CYSLTR2\",\"ASMTL-AS1\",\"AP002001.3\",\"FAM153B\"\n",
    "]\n",
    "\n",
    "def load_tcga_expr(paths):\n",
    "    path = next((p for p in paths if p.exists()), None)\n",
    "    if path is None: raise FileNotFoundError(\"No TCGA PAAD expression file found on Desktop.\")\n",
    "    print(f\"[TCGA] Loading expression from: {path.name}\")\n",
    "    df = pd.read_csv(path, low_memory=False)\n",
    "    gene_col = None\n",
    "    for c in [\"Hugo_Symbol\",\"gene\",\"Gene\",\"GeneSymbol\",\"gene_name\", df.columns[0]]:\n",
    "        if c in df.columns: gene_col = c; break\n",
    "    if gene_col is None: raise ValueError(\"Could not infer gene column.\")\n",
    "    df = df.rename(columns={gene_col:\"Gene\"})\n",
    "    df[\"Gene\"] = df[\"Gene\"].astype(str).str.split(\"|\").str[0]\n",
    "    df = df.set_index(\"Gene\")\n",
    "    df = df.apply(pd.to_numeric, errors=\"coerce\").dropna(how=\"all\", axis=0).dropna(how=\"all\", axis=1)\n",
    "    df.columns = pd.Index([str(c)[:12] for c in df.columns], name=\"patientId\")\n",
    "    df = df.groupby(df.columns, axis=1).mean(numeric_only=True)\n",
    "    print(f\"[TCGA] patient-level shape (genes x patients): {df.shape}\")\n",
    "    return df\n",
    "\n",
    "def score_signed(expr, up_genes, down_genes, min_genes=10, name=\"signed_score\"):\n",
    "    Z = expr.apply(lambda x: (x - x.mean()) / (x.std(ddof=0) + 1e-9), axis=1)\n",
    "    up = pd.Index(up_genes).intersection(Z.index); dn = pd.Index(down_genes).intersection(Z.index)\n",
    "    cov = {\"up_used\": int(up.size), \"up_total\": len(up_genes), \"down_used\": int(dn.size), \"down_total\": len(down_genes)}\n",
    "    if up.size < min_genes or dn.size < min_genes:\n",
    "        return pd.Series(np.nan, index=Z.columns, name=name), cov\n",
    "    return (Z.loc[up].mean(axis=0) - Z.loc[dn].mean(axis=0)).rename(name), cov\n",
    "\n",
    "def load_clin(path):\n",
    "    if not path.exists(): raise FileNotFoundError(\"PanCan clinical file not found on Desktop.\")\n",
    "    clin = pd.read_csv(path)\n",
    "    need = [\"patientId\",\"OS_MONTHS\",\"OS_STATUS\"]\n",
    "    miss = [c for c in need if c not in clin.columns]\n",
    "    if miss: raise ValueError(f\"Missing columns in clinical file: {miss}\")\n",
    "    clin[\"patientId\"] = clin[\"patientId\"].astype(str).str[:12]\n",
    "    status = clin[\"OS_STATUS\"].astype(str).str.upper().str.contains(\"DECEASED\")\n",
    "    out = pd.DataFrame({\n",
    "        \"patientId\": clin[\"patientId\"],\n",
    "        \"OS_time_months\": pd.to_numeric(clin[\"OS_MONTHS\"], errors=\"coerce\"),\n",
    "        \"OS_event\": status.astype(float)\n",
    "    }).dropna(subset=[\"OS_time_months\",\"OS_event\"]).drop_duplicates(subset=[\"patientId\"]).set_index(\"patientId\")\n",
    "    print(f\"[CLIN] rows with OS: {out.shape[0]}\")\n",
    "    return out\n",
    "\n",
    "def zscore_series(s):\n",
    "    mu, sd = s.mean(), s.std(ddof=0)\n",
    "    return s*0 if (sd == 0 or np.isnan(sd)) else (s - mu) / sd\n",
    "\n",
    "def km_plot_and_logrank_optimal(df, score_col, title, out_png,\n",
    "                                min_quantile=0.2, max_quantile=0.8,\n",
    "                                hi_label=\"High SAT\", lo_label=\"Low SAT\"):\n",
    "    scores = df[score_col].dropna().sort_values()\n",
    "    n = len(scores)\n",
    "    best_cut, best_p = None, 1.0\n",
    "    qmin = int(n * min_quantile); qmax = int(n * max_quantile)\n",
    "    candidates = scores.iloc[qmin:qmax]\n",
    "    for cut in candidates:\n",
    "        group = scores >= cut\n",
    "        hi = df.loc[group, \"OS_time_months\"]; lo = df.loc[~group, \"OS_time_months\"]\n",
    "        hi_e = df.loc[group, \"OS_event\"];     lo_e = df.loc[~group, \"OS_event\"]\n",
    "        if len(hi) < 5 or len(lo) < 5: continue\n",
    "        lr = logrank_test(hi, lo, event_observed_A=hi_e, event_observed_B=lo_e)\n",
    "        if lr.p_value < best_p: best_p, best_cut = float(lr.p_value), float(cut)\n",
    "    if best_cut is None:\n",
    "        print(\"[WARN] No valid cutpoint in range — using median.\")\n",
    "        best_cut = float(scores.median()); best_p = float(\"nan\")\n",
    "\n",
    "    df = df.assign(group=np.where(df[score_col] >= best_cut, hi_label, lo_label))\n",
    "    km = KaplanMeierFitter()\n",
    "    fig, ax = plt.subplots(figsize=(6.5,5), dpi=160)\n",
    "    for label in (hi_label, lo_label):\n",
    "        sub = df[df[\"group\"] == label]\n",
    "        if sub.empty: continue\n",
    "        km.fit(sub[\"OS_time_months\"], sub[\"OS_event\"], label=f\"{label} (n={len(sub)})\")\n",
    "        sf = km.survival_function_.iloc[:,0]; t = sf.index.values; y = sf.values\n",
    "        ax.step(t, y, where=\"post\", label=km._label)\n",
    "        ci = km.confidence_interval_; ax.fill_between(t, ci.iloc[:,0].values, ci.iloc[:,1].values, step=\"post\", alpha=0.20)\n",
    "    ax.set_xlabel(\"Time (months)\"); ax.set_ylabel(\"Overall survival probability\")\n",
    "    ax.set_title(f\"{title}\\noptimal cut={best_cut:.3f}, p={best_p:.3g}\")\n",
    "    ax.legend(); fig.tight_layout(); fig.savefig(out_png, bbox_inches=\"tight\"); plt.close(fig)\n",
    "    return best_cut, best_p\n",
    "\n",
    "# ----------------- run -----------------\n",
    "expr = load_tcga_expr(expr_paths)\n",
    "scores, cov = score_signed(expr, SAT_UP, SAT_DOWN, min_genes=10, name=\"SAT\")\n",
    "print(f\"[COVERAGE] UP {cov['up_used']}/{cov['up_total']} | DOWN {cov['down_used']}/{cov['down_total']}\")\n",
    "clin = load_clin(clin_path)\n",
    "\n",
    "df = pd.concat([scores, clin], axis=1, join=\"inner\").dropna(subset=[\"SAT\",\"OS_time_months\",\"OS_event\"])\n",
    "print(f\"[MERGE] N with score+OS: {df.shape[0]}\")\n",
    "scores.rename(\"SAT\").to_csv(OUTDIR / \"SAT_signed_scores.csv\")\n",
    "zscore_series(scores).rename(\"SAT_Z\").to_csv(OUTDIR / \"SAT_signed_scores_Z.csv\")\n",
    "\n",
    "if df.shape[0] >= 10 and np.isfinite(df[\"SAT\"]).any():\n",
    "    cut, p = km_plot_and_logrank_optimal(df, \"SAT\", \"TCGA-PAAD: SAT signed score (optimal cut)\", OUTDIR / \"SAT_KM_opt.png\")\n",
    "    print(f\"[KM optimal] SAT: cut={cut:.3f}, p={p:.3g} -> {OUTDIR/'SAT_KM_opt.png'}\")\n",
    "    df.assign(group=np.where(df[\"SAT\"]>=cut, \"High SAT\", \"Low SAT\")).to_csv(OUTDIR / \"SAT_scores_OS_group_opt.csv\")\n",
    "else:\n",
    "    print(\"[SKIP] Not enough valid cases for KM.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "48625f63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========= 1) EXPRESSION MATRIX (expr) =========\n",
      "Shape: (20502, 178)\n",
      "Example genes: ['A1BG', 'A1CF', 'A2BP1', 'A2LD1', 'A2ML1']\n",
      "Example patient IDs: ['TCGA-2J-AAB1', 'TCGA-2J-AAB4', 'TCGA-2J-AAB6', 'TCGA-2J-AAB8', 'TCGA-2J-AAB9']\n",
      "\n",
      "========= 2) SAT SCORES (scores) =========\n",
      "Length: (178,)\n",
      "NA count: 0\n",
      "patientId\n",
      "TCGA-2J-AAB1   -0.255525\n",
      "TCGA-2J-AAB4   -0.426443\n",
      "TCGA-2J-AAB6    0.072369\n",
      "TCGA-2J-AAB8    0.104286\n",
      "TCGA-2J-AAB9    0.155583\n",
      "Name: SAT, dtype: float64\n",
      "\n",
      "========= 3) CLINICAL DATA (clin) =========\n",
      "Shape: (184, 2)\n",
      "              OS_time_months  OS_event\n",
      "patientId                             \n",
      "TCGA-3A-A9IN       68.514318       0.0\n",
      "TCGA-2J-AAB4       23.966861       0.0\n",
      "TCGA-HV-A5A3        4.208173       1.0\n",
      "TCGA-FZ-5922       36.196864       1.0\n",
      "TCGA-HZ-7925       20.186080       1.0\n",
      "OS_event counts: OS_event\n",
      "1.0    99\n",
      "0.0    85\n",
      "Name: count, dtype: int64\n",
      "\n",
      "========= 4) MERGED DF (df) — what KM truly uses =========\n",
      "Shape: (177, 3)\n",
      "                   SAT  OS_time_months  OS_event\n",
      "patientId                                       \n",
      "TCGA-2J-AAB1 -0.255525        2.169839       1.0\n",
      "TCGA-2J-AAB4 -0.426443       23.966861       0.0\n",
      "TCGA-2J-AAB6  0.072369        9.632771       1.0\n",
      "TCGA-2J-AAB8  0.104286        2.630108       0.0\n",
      "TCGA-2J-AAB9  0.155583       20.613473       1.0\n",
      "\n",
      "Columns: ['SAT', 'OS_time_months', 'OS_event']\n",
      "\n",
      "SAT summary:\n",
      "count    177.000000\n",
      "mean       0.000007\n",
      "std        0.307312\n",
      "min       -1.639474\n",
      "25%       -0.123129\n",
      "50%        0.019771\n",
      "75%        0.160912\n",
      "max        0.909909\n",
      "Name: SAT, dtype: float64\n",
      "\n",
      "OS_time_months summary:\n",
      "count    177.000000\n",
      "mean      18.691228\n",
      "std       15.744679\n",
      "min        0.000000\n",
      "25%        9.106750\n",
      "50%       15.221751\n",
      "75%       22.224414\n",
      "max       90.114081\n",
      "Name: OS_time_months, dtype: float64\n",
      "\n",
      "OS_event summary:\n",
      "OS_event\n",
      "1.0    92\n",
      "0.0    85\n",
      "Name: count, dtype: int64\n",
      "\n",
      "========= END DIAGNOSTIC =========\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# --- DIAGNOSTIC: what did the old SAT pipeline rely on? ---\n",
    "\n",
    "print(\"\\n========= 1) EXPRESSION MATRIX (expr) =========\")\n",
    "try:\n",
    "    print(\"Shape:\", expr.shape)\n",
    "    print(\"Example genes:\", expr.index[:5].tolist())\n",
    "    print(\"Example patient IDs:\", expr.columns[:5].tolist())\n",
    "except Exception as e:\n",
    "    print(\"ERROR: expr is not defined or failed to load:\", e)\n",
    "\n",
    "print(\"\\n========= 2) SAT SCORES (scores) =========\")\n",
    "try:\n",
    "    print(\"Length:\", scores.shape)\n",
    "    print(\"NA count:\", scores.isna().sum())\n",
    "    print(scores.head())\n",
    "except Exception as e:\n",
    "    print(\"ERROR: scores not defined:\", e)\n",
    "\n",
    "print(\"\\n========= 3) CLINICAL DATA (clin) =========\")\n",
    "try:\n",
    "    print(\"Shape:\", clin.shape)\n",
    "    print(clin.head())\n",
    "    print(\"OS_event counts:\", clin[\"OS_event\"].value_counts(dropna=False))\n",
    "except Exception as e:\n",
    "    print(\"ERROR: clin not defined:\", e)\n",
    "\n",
    "print(\"\\n========= 4) MERGED DF (df) — what KM truly uses =========\")\n",
    "try:\n",
    "    print(\"Shape:\", df.shape)\n",
    "    print(df.head())\n",
    "\n",
    "    print(\"\\nColumns:\", df.columns.tolist())\n",
    "\n",
    "    # Summary statistics\n",
    "    try:\n",
    "        print(\"\\nSAT summary:\")\n",
    "        print(df[\"SAT\"].describe())\n",
    "        print(\"\\nOS_time_months summary:\")\n",
    "        print(df[\"OS_time_months\"].describe())\n",
    "        print(\"\\nOS_event summary:\")\n",
    "        print(df[\"OS_event\"].value_counts(dropna=False))\n",
    "    except Exception as stat_err:\n",
    "        print(\"Could not summarize SAT/OS:\", stat_err)\n",
    "\n",
    "except Exception as e:\n",
    "    print(\"ERROR: df not defined:\", e)\n",
    "\n",
    "print(\"\\n========= END DIAGNOSTIC =========\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "a0ac653d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[KM RESULT]\n",
      "Optimal cut: 0.14439319910447584\n",
      "p-value: 0.038365137174561165\n",
      "Output figure: /Users/scottpowers/Desktop/tcga_paad_SAT_KM_module_survival_out/SAT_opt/SAT_KM_opt.png\n"
     ]
    }
   ],
   "source": [
    "cut, p = km_plot_and_logrank_optimal(\n",
    "    df,\n",
    "    score_col=\"SAT\",\n",
    "    title=\"TCGA-PAAD: SAT signed score (optimal cut)\",\n",
    "    out_png=OUTDIR / \"SAT_KM_opt.png\"\n",
    ")\n",
    "\n",
    "print(\"\\n[KM RESULT]\")\n",
    "print(\"Optimal cut:\", cut)\n",
    "print(\"p-value:\", p)\n",
    "print(\"Output figure:\", OUTDIR / \"SAT_KM_opt.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "ae1435d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved SAT KM plot → /Users/scottpowers/Desktop/tcga_paad_SAT_KM_module_survival_out/SAT_opt/KM_SAT.png\n",
      "Optimal cut = 0.14439319910447584    p-value = 0.038365137174561165\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from lifelines import KaplanMeierFitter\n",
    "from lifelines.statistics import logrank_test\n",
    "\n",
    "# Use Arial\n",
    "plt.rcParams[\"font.family\"] = \"Arial\"\n",
    "\n",
    "# -------------------------\n",
    "# Build SAT dataframe\n",
    "# -------------------------\n",
    "df_sat = pd.concat([\n",
    "    scores.rename(\"SAT\"),    # your SAT signed scores\n",
    "    clin                     # clinical DF with OS_time_months + OS_event\n",
    "], axis=1, join=\"inner\").dropna(\n",
    "    subset=[\"SAT\", \"OS_time_months\", \"OS_event\"]\n",
    ")\n",
    "\n",
    "# -------------------------\n",
    "# Find optimal cut\n",
    "# -------------------------\n",
    "scores_sorted = df_sat[\"SAT\"].sort_values()\n",
    "n = len(scores_sorted)\n",
    "\n",
    "qmin = int(n * 0.20)\n",
    "qmax = int(n * 0.80)\n",
    "candidates = scores_sorted.iloc[qmin:qmax]\n",
    "\n",
    "best_cut, best_p = None, 1.0\n",
    "\n",
    "for cut in candidates:\n",
    "    grp = scores_sorted >= cut\n",
    "    hi, lo = df_sat.loc[grp], df_sat.loc[~grp]\n",
    "\n",
    "    if len(hi) < 5 or len(lo) < 5:\n",
    "        continue\n",
    "\n",
    "    lr = logrank_test(\n",
    "        hi[\"OS_time_months\"], lo[\"OS_time_months\"],\n",
    "        event_observed_A=hi[\"OS_event\"],\n",
    "        event_observed_B=lo[\"OS_event\"]\n",
    "    )\n",
    "    if lr.p_value < best_p:\n",
    "        best_p = float(lr.p_value)\n",
    "        best_cut = float(cut)\n",
    "\n",
    "# fallback median\n",
    "if best_cut is None:\n",
    "    best_cut = float(scores_sorted.median())\n",
    "    best_p = float(\"nan\")\n",
    "\n",
    "# -------------------------\n",
    "# KM plot\n",
    "# -------------------------\n",
    "df_sat = df_sat.assign(\n",
    "    group=np.where(df_sat[\"SAT\"] >= best_cut, \"SAT high\", \"SAT low\")\n",
    ")\n",
    "\n",
    "km = KaplanMeierFitter()\n",
    "fig, ax = plt.subplots(figsize=(4.2, 3.5), dpi=200)\n",
    "\n",
    "for group in [\"SAT high\", \"SAT low\"]:\n",
    "    sub = df_sat[df_sat[\"group\"] == group]\n",
    "    km.fit(sub[\"OS_time_months\"], sub[\"OS_event\"], label=f\"{group} (n={len(sub)})\")\n",
    "    km.plot_survival_function(ax=ax, ci_show=True)\n",
    "\n",
    "ax.set_xlabel(\"Time (months)\")\n",
    "ax.set_ylabel(\"Overall survival probability\")\n",
    "ax.set_title(f\"TCGA-PAAD: SAT module\\ncut={best_cut:.3f}, p={best_p:.3g}\")\n",
    "ax.legend(frameon=False)\n",
    "\n",
    "fig.tight_layout()\n",
    "\n",
    "OUT = OUTDIR / \"KM_SAT.png\"\n",
    "fig.savefig(OUT, bbox_inches=\"tight\")\n",
    "plt.close(fig)\n",
    "\n",
    "print(\"Saved SAT KM plot →\", OUT)\n",
    "print(\"Optimal cut =\", best_cut, \"   p-value =\", best_p)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "363446d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TCGA] Loading expression from: PAAD_RSEM_genes_normalized_CLEAN.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/mh/r2nrb73509z0t_wjbx9r5fg00000gn/T/ipykernel_92012/3692135367.py:51: FutureWarning: DataFrame.groupby with axis=1 is deprecated. Do `frame.T.groupby(...)` without axis instead.\n",
      "  df = df.groupby(df.columns, axis=1).mean(numeric_only=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TCGA] patient-level shape (genes x patients): (20502, 178)\n",
      "[COVERAGE] UP 83/106 | DOWN 14/23\n",
      "[CLIN] rows with OS: 184\n",
      "[MERGE] N with score+OS: 177\n",
      "[KM optimal] IL2: cut=-0.331, p=0.422 -> /Users/scottpowers/Desktop/tcga_paad_IL2_KM_module_survival_out/IL2_opt/IL2_KM_opt.png\n"
     ]
    }
   ],
   "source": [
    "# --- TCGA PAAD survival • IL2 signed score (optimal KM cut) ---\n",
    "\n",
    "import pandas as pd, numpy as np\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "from lifelines import KaplanMeierFitter\n",
    "from lifelines.statistics import logrank_test\n",
    "\n",
    "DESKTOP = Path.home() / \"Desktop\"\n",
    "expr_paths = [\n",
    "    DESKTOP / \"PAAD_RSEM_genes_normalized_CLEAN.csv\",\n",
    "    DESKTOP / \"PAAD.rnaseqv2__illuminahiseq_rnaseqv2__unc_edu__Level_3__RSEM_genes_normalized__data.data.csv\",\n",
    "]\n",
    "clin_path = DESKTOP / \"paad_tcga_pan_can_atlas_2018_clinical_data.csv\"\n",
    "OUTDIR = DESKTOP / \"tcga_paad_IL2_KM_module_survival_out\" / \"IL2_opt\"\n",
    "OUTDIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "IL2_UP = [\n",
    "    \"ABHD15-AS1\",\"AC007780.1\",\"AC008105.3\",\"AC008964.1\",\"AC016831.1\",\"AC016831.5\",\"AC090772.1\",\"AC108863.2\",\n",
    "    \"ADARB1\",\"ALOX5AP\",\"ANKH\",\"ANKRD44\",\"APOBEC3G\",\"ARHGDIB\",\"ARL6IP5\",\"ARSG\",\"ATP10D\",\"BCL11B\",\"BORCS5\",\n",
    "    \"CAMK1D\",\"CD4\",\"CD84\",\"CD96\",\"CDC42EP3\",\"CELF2\",\"CERS4\",\"CLEC2D\",\"CNOT6L\",\"CRYBG1\",\"CTSW\",\"DSE\",\"FGD3\",\n",
    "    \"FMNL1\",\"FOXN3\",\"FOXO1\",\"FYB1\",\"GFI1\",\"GNAO1\",\"GPRIN3\",\"HOPX\",\"IGF1\",\"IKZF3\",\"IL18R1\",\"INKA2\",\"INSYN2B\",\n",
    "    \"IQSEC1\",\"ITPRIPL1\",\"JAK3\",\"KLRC2\",\"KLRC3\",\"KLRF1\",\"KLRG1\",\"LAPTM5\",\"LCP1\",\"LEPROTL1\",\"LINC00513\",\n",
    "    \"LINC01237\",\"MAN1A1\",\"MAPRE2\",\"MPHOSPH9\",\"MPP7\",\"MVB12B\",\"MYO5A\",\"NIN\",\"PARP11\",\"PARP15\",\"PCED1B-AS1\",\n",
    "    \"PDE3B\",\"PIP4K2A\",\"PLCL1\",\"PLEKHA2\",\"PPP3CC\",\"PRKCH\",\"PRKCQ\",\"PRKD3\",\"PRKX\",\"PTPN22\",\"RAC2\",\"RASGRF2\",\n",
    "    \"RFX3\",\"RIPOR2\",\"RNF166\",\"S1PR4\",\"SAMD3\",\"SENP7\",\"SH2B3\",\"SH2D2A\",\"SMARCA2\",\"SNHG26\",\"SPOCK2\",\"SRGN\",\n",
    "    \"ST8SIA1\",\"STAT5A\",\"STAT5B\",\"STIM1\",\"STK17A\",\"TMEM200A\",\"TMX4\",\"TRBC2\",\"TRDC\",\"TRIM22\",\"TTN\",\"VAV3\",\n",
    "    \"WNT5A-AS1\",\"ZNF101\",\"ZNF471\"\n",
    "]\n",
    "IL2_DOWN = [\n",
    "    \"RBP7\",\"OVCA2\",\"PLAC4\",\"AC026785.3\",\"LINC02212\",\"LINC00605\",\"AC246817.2\",\"FOXCUT\",\"VGLL2\",\"ZIC4\",\"FOLR3\",\n",
    "    \"ECEL1\",\"AC024337.1\",\"C5orf58\",\"AC060814.3\",\"B4GALNT1\",\"UCHL1\",\"VAX1\",\"AL451042.1\",\"COMMD8\",\"IFI30\",\n",
    "    \"AL096794.1\",\"RGS10\"\n",
    "]\n",
    "\n",
    "# helpers reused from IGE script (identical)\n",
    "def load_tcga_expr(paths):\n",
    "    path = next((p for p in paths if p.exists()), None)\n",
    "    if path is None: raise FileNotFoundError(\"No TCGA PAAD expression file found on Desktop.\")\n",
    "    print(f\"[TCGA] Loading expression from: {path.name}\")\n",
    "    df = pd.read_csv(path, low_memory=False)\n",
    "    gene_col = None\n",
    "    for c in [\"Hugo_Symbol\",\"gene\",\"Gene\",\"GeneSymbol\",\"gene_name\", df.columns[0]]:\n",
    "        if c in df.columns: gene_col = c; break\n",
    "    if gene_col is None: raise ValueError(\"Could not infer gene column.\")\n",
    "    df = df.rename(columns={gene_col:\"Gene\"})\n",
    "    df[\"Gene\"] = df[\"Gene\"].astype(str).str.split(\"|\").str[0]\n",
    "    df = df.set_index(\"Gene\")\n",
    "    df = df.apply(pd.to_numeric, errors=\"coerce\").dropna(how=\"all\", axis=0).dropna(how=\"all\", axis=1)\n",
    "    df.columns = pd.Index([str(c)[:12] for c in df.columns], name=\"patientId\")\n",
    "    df = df.groupby(df.columns, axis=1).mean(numeric_only=True)\n",
    "    print(f\"[TCGA] patient-level shape (genes x patients): {df.shape}\")\n",
    "    return df\n",
    "\n",
    "def score_signed(expr, up_genes, down_genes, min_genes=10, name=\"signed_score\"):\n",
    "    Z = expr.apply(lambda x: (x - x.mean()) / (x.std(ddof=0) + 1e-9), axis=1)\n",
    "    up = pd.Index(up_genes).intersection(Z.index); dn = pd.Index(down_genes).intersection(Z.index)\n",
    "    cov = {\"up_used\": int(up.size), \"up_total\": len(up_genes), \"down_used\": int(dn.size), \"down_total\": len(down_genes)}\n",
    "    if up.size < min_genes or dn.size < min_genes:\n",
    "        return pd.Series(np.nan, index=Z.columns, name=name), cov\n",
    "    return (Z.loc[up].mean(axis=0) - Z.loc[dn].mean(axis=0)).rename(name), cov\n",
    "\n",
    "def load_clin(path):\n",
    "    if not path.exists(): raise FileNotFoundError(\"PanCan clinical file not found on Desktop.\")\n",
    "    clin = pd.read_csv(path)\n",
    "    need = [\"patientId\",\"OS_MONTHS\",\"OS_STATUS\"]\n",
    "    miss = [c for c in need if c not in clin.columns]\n",
    "    if miss: raise ValueError(f\"Missing columns in clinical file: {miss}\")\n",
    "    clin[\"patientId\"] = clin[\"patientId\"].astype(str).str[:12]\n",
    "    status = clin[\"OS_STATUS\"].astype(str).str.upper().str.contains(\"DECEASED\")\n",
    "    out = pd.DataFrame({\n",
    "        \"patientId\": clin[\"patientId\"],\n",
    "        \"OS_time_months\": pd.to_numeric(clin[\"OS_MONTHS\"], errors=\"coerce\"),\n",
    "        \"OS_event\": status.astype(float)\n",
    "    }).dropna(subset=[\"OS_time_months\",\"OS_event\"]).drop_duplicates(subset=[\"patientId\"]).set_index(\"patientId\")\n",
    "    print(f\"[CLIN] rows with OS: {out.shape[0]}\")\n",
    "    return out\n",
    "\n",
    "def zscore_series(s):\n",
    "    mu, sd = s.mean(), s.std(ddof=0)\n",
    "    return s*0 if (sd == 0 or np.isnan(sd)) else (s - mu) / sd\n",
    "\n",
    "def km_plot_and_logrank_optimal(df, score_col, title, out_png,\n",
    "                                min_quantile=0.2, max_quantile=0.8,\n",
    "                                hi_label=\"High IL2\", lo_label=\"Low IL2\"):\n",
    "    scores = df[score_col].dropna().sort_values()\n",
    "    n = len(scores)\n",
    "    best_cut, best_p = None, 1.0\n",
    "    qmin = int(n * min_quantile); qmax = int(n * max_quantile)\n",
    "    candidates = scores.iloc[qmin:qmax]\n",
    "    for cut in candidates:\n",
    "        group = scores >= cut\n",
    "        hi = df.loc[group, \"OS_time_months\"]; lo = df.loc[~group, \"OS_time_months\"]\n",
    "        hi_e = df.loc[group, \"OS_event\"];     lo_e = df.loc[~group, \"OS_event\"]\n",
    "        if len(hi) < 5 or len(lo) < 5: continue\n",
    "        lr = logrank_test(hi, lo, event_observed_A=hi_e, event_observed_B=lo_e)\n",
    "        if lr.p_value < best_p: best_p, best_cut = float(lr.p_value), float(cut)\n",
    "    if best_cut is None:\n",
    "        print(\"[WARN] No valid cutpoint in range — using median.\")\n",
    "        best_cut = float(scores.median()); best_p = float(\"nan\")\n",
    "\n",
    "    df = df.assign(group=np.where(df[score_col] >= best_cut, hi_label, lo_label))\n",
    "    km = KaplanMeierFitter()\n",
    "    fig, ax = plt.subplots(figsize=(6.5,5), dpi=160)\n",
    "    for label in (hi_label, lo_label):\n",
    "        sub = df[df[\"group\"] == label]\n",
    "        if sub.empty: continue\n",
    "        km.fit(sub[\"OS_time_months\"], sub[\"OS_event\"], label=f\"{label} (n={len(sub)})\")\n",
    "        sf = km.survival_function_.iloc[:,0]; t = sf.index.values; y = sf.values\n",
    "        ax.step(t, y, where=\"post\", label=km._label)\n",
    "        ci = km.confidence_interval_; ax.fill_between(t, ci.iloc[:,0].values, ci.iloc[:,1].values, step=\"post\", alpha=0.20)\n",
    "    ax.set_xlabel(\"Time (months)\"); ax.set_ylabel(\"Overall survival probability\")\n",
    "    ax.set_title(f\"{title}\\noptimal cut={best_cut:.3f}, p={best_p:.3g}\")\n",
    "    ax.legend(); fig.tight_layout(); fig.savefig(out_png, bbox_inches=\"tight\"); plt.close(fig)\n",
    "    return best_cut, best_p\n",
    "\n",
    "# ----------------- run -----------------\n",
    "expr = load_tcga_expr(expr_paths)\n",
    "scores, cov = score_signed(expr, IL2_UP, IL2_DOWN, min_genes=10, name=\"IL2\")\n",
    "print(f\"[COVERAGE] UP {cov['up_used']}/{cov['up_total']} | DOWN {cov['down_used']}/{cov['down_total']}\")\n",
    "clin = load_clin(clin_path)\n",
    "\n",
    "df = pd.concat([scores, clin], axis=1, join=\"inner\").dropna(subset=[\"IL2\",\"OS_time_months\",\"OS_event\"])\n",
    "print(f\"[MERGE] N with score+OS: {df.shape[0]}\")\n",
    "scores.rename(\"IL2\").to_csv(OUTDIR / \"IL2_signed_scores.csv\")\n",
    "zscore_series(scores).rename(\"IL2_Z\").to_csv(OUTDIR / \"IL2_signed_scores_Z.csv\")\n",
    "\n",
    "if df.shape[0] >= 10 and np.isfinite(df[\"IL2\"]).any():\n",
    "    cut, p = km_plot_and_logrank_optimal(df, \"IL2\", \"TCGA-PAAD: IL2 signed score (optimal cut)\", OUTDIR / \"IL2_KM_opt.png\")\n",
    "    print(f\"[KM optimal] IL2: cut={cut:.3f}, p={p:.3g} -> {OUTDIR/'IL2_KM_opt.png'}\")\n",
    "    df.assign(group=np.where(df[\"IL2\"]>=cut, \"High IL2\", \"Low IL2\")).to_csv(OUTDIR / \"IL2_scores_OS_group_opt.csv\")\n",
    "else:\n",
    "    print(\"[SKIP] Not enough valid cases for KM.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "dca09215",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved IL2 KM plot → /Users/scottpowers/Desktop/tcga_paad_IL2_KM_module_survival_out/IL2_opt/KM_IL2.png\n",
      "Optimal cut = -0.33103009561635677    p-value = 0.4219072463284781\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from lifelines import KaplanMeierFitter\n",
    "from lifelines.statistics import logrank_test\n",
    "\n",
    "plt.rcParams[\"font.family\"] = \"Arial\"\n",
    "\n",
    "# -------------------------\n",
    "# Build IL2 dataframe\n",
    "# -------------------------\n",
    "df_il2 = pd.concat([\n",
    "    scores.rename(\"IL2\"),    # your IL2 signed scores\n",
    "    clin                     # clinical DF\n",
    "], axis=1, join=\"inner\").dropna(\n",
    "    subset=[\"IL2\", \"OS_time_months\", \"OS_event\"]\n",
    ")\n",
    "\n",
    "# -------------------------\n",
    "# Optimal cut search\n",
    "# -------------------------\n",
    "scores_sorted = df_il2[\"IL2\"].sort_values()\n",
    "n = len(scores_sorted)\n",
    "\n",
    "qmin = int(n * 0.20)\n",
    "qmax = int(n * 0.80)\n",
    "candidates = scores_sorted.iloc[qmin:qmax]\n",
    "\n",
    "best_cut, best_p = None, 1.0\n",
    "\n",
    "for cut in candidates:\n",
    "    grp = scores_sorted >= cut\n",
    "    hi = df_il2.loc[grp]\n",
    "    lo = df_il2.loc[~grp]\n",
    "\n",
    "    if len(hi) < 5 or len(lo) < 5:\n",
    "        continue\n",
    "\n",
    "    lr = logrank_test(\n",
    "        hi[\"OS_time_months\"], lo[\"OS_time_months\"],\n",
    "        event_observed_A=hi[\"OS_event\"],\n",
    "        event_observed_B=lo[\"OS_event\"]\n",
    "    )\n",
    "\n",
    "    if lr.p_value < best_p:\n",
    "        best_p = float(lr.p_value)\n",
    "        best_cut = float(cut)\n",
    "\n",
    "# fallback median\n",
    "if best_cut is None:\n",
    "    best_cut = float(scores_sorted.median())\n",
    "    best_p = float(\"nan\")\n",
    "\n",
    "# -------------------------\n",
    "# Plot KM for IL2\n",
    "# -------------------------\n",
    "df_il2 = df_il2.assign(\n",
    "    group=np.where(df_il2[\"IL2\"] >= best_cut, \"IL2 high\", \"IL2 low\")\n",
    ")\n",
    "\n",
    "km = KaplanMeierFitter()\n",
    "fig, ax = plt.subplots(figsize=(4.2, 3.5), dpi=200)\n",
    "\n",
    "for grp in [\"IL2 high\", \"IL2 low\"]:\n",
    "    sub = df_il2[df_il2[\"group\"] == grp]\n",
    "    km.fit(sub[\"OS_time_months\"], sub[\"OS_event\"], label=f\"{grp} (n={len(sub)})\")\n",
    "    km.plot_survival_function(ax=ax, ci_show=True)\n",
    "\n",
    "ax.set_xlabel(\"Time (months)\")\n",
    "ax.set_ylabel(\"Overall survival probability\")\n",
    "ax.set_title(f\"TCGA-PAAD: IL2 module\\ncut={best_cut:.3f}, p={best_p:.3g}\")\n",
    "ax.legend(frameon=False)\n",
    "\n",
    "fig.tight_layout()\n",
    "OUT = OUTDIR / \"KM_IL2.png\"\n",
    "fig.savefig(OUT, bbox_inches=\"tight\")\n",
    "plt.close(fig)\n",
    "\n",
    "print(\"Saved IL2 KM plot →\", OUT)\n",
    "print(\"Optimal cut =\", best_cut, \"   p-value =\", best_p)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bf0f0f38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SDRF] columns (count=51):\n",
      "    0 | Source Name\n",
      "    1 | Characteristics[organism]\n",
      "    2 | Characteristics[developmental stage]\n",
      "    3 | Characteristics[sex]\n",
      "    4 | Characteristics[organism part]\n",
      "    5 | Characteristics[disease]\n",
      "    6 | Characteristics[sampling site]\n",
      "    7 | Characteristics[tumor grading]\n",
      "    8 | Characteristics[TNM tumour grading]\n",
      "    9 | Characteristics[resection margin]\n",
      "   10 | Characteristics[clinical center]\n",
      "   11 | Characteristics[ffpeblock age]\n",
      "   12 | Unit[time unit]\n",
      "   13 | Term Source REF\n",
      "   14 | Term Accession Number\n",
      "   15 | Characteristics[os.delay]\n",
      "   16 | Unit[time unit].1\n",
      "   17 | Term Source REF.1\n",
      "   18 | Term Accession Number.1\n",
      "   19 | Characteristics[os.event]\n",
      "   20 | Characteristics[dfs.delay]\n",
      "   21 | Unit[time unit].2\n",
      "   22 | Term Source REF.2\n",
      "   23 | Term Accession Number.2\n",
      "   24 | Characteristics[dfs.event]\n",
      "   25 | Characteristics[hightumcellclassif]\n",
      "   26 | Characteristics[wholetumclassif]\n",
      "   27 | Characteristics[average vaf]\n",
      "   28 | Characteristics[krasmut]\n",
      "   29 | Characteristics[tp53mut]\n",
      "   30 | Characteristics[cdkn2amut]\n",
      "   31 | Material Type\n",
      "   32 | Description\n",
      "   33 | Protocol REF\n",
      "   34 | Protocol REF.1\n",
      "   35 | Extract Name\n",
      "   36 | Protocol REF.2\n",
      "   37 | Labeled Extract Name\n",
      "   38 | Label\n",
      "   39 | Protocol REF.3\n",
      "   40 | Assay Name\n",
      "   41 | Technology Type\n",
      "   42 | Array Design REF\n",
      "   43 | Term Source REF.3\n",
      "   44 | Protocol REF.4\n",
      "   45 | Array Data File\n",
      "   46 | Comment [ArrayExpress FTP file]\n",
      "   47 | Protocol REF.5\n",
      "   48 | Derived Array Data File\n",
      "   49 | Comment [Derived ArrayExpress FTP file]\n",
      "   50 | Factor Value[wholetumclassif]\n",
      "[WIDE] built with 21 columns (normalized).\n",
      "\n",
      "✅ Puleo survival rows: 0  -> /Users/scottpowers/Desktop/Puleo_survival_from_SDRF.csv\n",
      "\n",
      "[EXPLORER] No survival parsed. Let's inspect.\n",
      "ID column used: Assay Name\n",
      "\n",
      "Top 60 header names:\n",
      "    0 | Source Name\n",
      "    1 | Characteristics[organism]\n",
      "    2 | Characteristics[developmental stage]\n",
      "    3 | Characteristics[sex]\n",
      "    4 | Characteristics[organism part]\n",
      "    5 | Characteristics[disease]\n",
      "    6 | Characteristics[sampling site]\n",
      "    7 | Characteristics[tumor grading]\n",
      "    8 | Characteristics[TNM tumour grading]\n",
      "    9 | Characteristics[resection margin]\n",
      "   10 | Characteristics[clinical center]\n",
      "   11 | Characteristics[ffpeblock age]\n",
      "   12 | Unit[time unit]\n",
      "   13 | Term Source REF\n",
      "   14 | Term Accession Number\n",
      "   15 | Characteristics[os.delay]\n",
      "   16 | Unit[time unit].1\n",
      "   17 | Term Source REF.1\n",
      "   18 | Term Accession Number.1\n",
      "   19 | Characteristics[os.event]\n",
      "   20 | Characteristics[dfs.delay]\n",
      "   21 | Unit[time unit].2\n",
      "   22 | Term Source REF.2\n",
      "   23 | Term Accession Number.2\n",
      "   24 | Characteristics[dfs.event]\n",
      "   25 | Characteristics[hightumcellclassif]\n",
      "   26 | Characteristics[wholetumclassif]\n",
      "   27 | Characteristics[average vaf]\n",
      "   28 | Characteristics[krasmut]\n",
      "   29 | Characteristics[tp53mut]\n",
      "   30 | Characteristics[cdkn2amut]\n",
      "   31 | Material Type\n",
      "   32 | Description\n",
      "   33 | Protocol REF\n",
      "   34 | Protocol REF.1\n",
      "   35 | Extract Name\n",
      "   36 | Protocol REF.2\n",
      "   37 | Labeled Extract Name\n",
      "   38 | Label\n",
      "   39 | Protocol REF.3\n",
      "   40 | Assay Name\n",
      "   41 | Technology Type\n",
      "   42 | Array Design REF\n",
      "   43 | Term Source REF.3\n",
      "   44 | Protocol REF.4\n",
      "   45 | Array Data File\n",
      "   46 | Comment [ArrayExpress FTP file]\n",
      "   47 | Protocol REF.5\n",
      "   48 | Derived Array Data File\n",
      "   49 | Comment [Derived ArrayExpress FTP file]\n",
      "   50 | Factor Value[wholetumclassif]\n",
      "   51 | _id\n",
      "\n",
      "Candidate clinical-ish columns (24 found):\n",
      "  Characteristics[organism]\n",
      "  Characteristics[developmental stage]\n",
      "  Characteristics[sex]\n",
      "  Characteristics[organism part]\n",
      "  Characteristics[disease]\n",
      "  Characteristics[sampling site]\n",
      "  Characteristics[tumor grading]\n",
      "  Characteristics[TNM tumour grading]\n",
      "  Characteristics[resection margin]\n",
      "  Characteristics[clinical center]\n",
      "  Characteristics[ffpeblock age]\n",
      "  Characteristics[os.delay]\n",
      "  Characteristics[os.event]\n",
      "  Characteristics[dfs.delay]\n",
      "  Characteristics[dfs.event]\n",
      "  Characteristics[hightumcellclassif]\n",
      "  Characteristics[wholetumclassif]\n",
      "  Characteristics[average vaf]\n",
      "  Characteristics[krasmut]\n",
      "  Characteristics[tp53mut]\n",
      "  Characteristics[cdkn2amut]\n",
      "  Comment [ArrayExpress FTP file]\n",
      "  Comment [Derived ArrayExpress FTP file]\n",
      "  Factor Value[wholetumclassif]\n",
      "\n",
      "[PEEK clinical-ish columns] first 5 rows:\n",
      "          _id Characteristics[organism] Characteristics[developmental stage] Characteristics[sex] Characteristics[organism part]         Characteristics[disease] Characteristics[sampling site] Characteristics[tumor grading] Characteristics[TNM tumour grading] Characteristics[resection margin] Characteristics[clinical center] Characteristics[ffpeblock age] Characteristics[os.delay] Characteristics[os.event] Characteristics[dfs.delay] Characteristics[dfs.event] Characteristics[hightumcellclassif] Characteristics[wholetumclassif] Characteristics[average vaf] Characteristics[krasmut] Characteristics[tp53mut] Characteristics[cdkn2amut]                                                                     Comment [ArrayExpress FTP file]                                                                   Comment [Derived ArrayExpress FTP file] Factor Value[wholetumclassif]\n",
      " H08C5473_E09              Homo sapiens                                adult                 male                       pancreas pancreatic ductal adenocarcinoma                       neoplasm              tumour grading G1                                T3N1               resection margin R0                Pitie Salpetriere                              9                     24.28                         1                       5.92                          1                       not available                     Desmoplastic                         2.05      no mutation in KRas      no mutation in TP53      no mutation in CDKN2a ftp://ftp.ebi.ac.uk/pub/databases/microarray/data/experiment/MTAB/E-MTAB-6134/E-MTAB-6134.raw.1.zip ftp://ftp.ebi.ac.uk/pub/databases/microarray/data/experiment/MTAB/E-MTAB-6134/E-MTAB-6134.processed.1.zip                  Desmoplastic\n",
      "H07C10608_C04              Homo sapiens                                adult                 male                       pancreas pancreatic ductal adenocarcinoma                       neoplasm              tumour grading G2                                T3N1               resection margin R0                Pitie Salpetriere                              9                     20.13                         1                       6.91                          1                       not available                     Desmoplastic                         2.07      no mutation in KRas      no mutation in TP53      no mutation in CDKN2a ftp://ftp.ebi.ac.uk/pub/databases/microarray/data/experiment/MTAB/E-MTAB-6134/E-MTAB-6134.raw.1.zip ftp://ftp.ebi.ac.uk/pub/databases/microarray/data/experiment/MTAB/E-MTAB-6134/E-MTAB-6134.processed.1.zip                  Desmoplastic\n",
      "    A2299_064              Homo sapiens                                adult                 male                       pancreas pancreatic ductal adenocarcinoma                       neoplasm              tumour grading G3                                T3N1               resection margin R0                          Belgium                             14                     12.11                         1                       3.39                          1                       not available                  ImmuneClassical                         2.12      no mutation in KRas      no mutation in TP53      no mutation in CDKN2a ftp://ftp.ebi.ac.uk/pub/databases/microarray/data/experiment/MTAB/E-MTAB-6134/E-MTAB-6134.raw.1.zip ftp://ftp.ebi.ac.uk/pub/databases/microarray/data/experiment/MTAB/E-MTAB-6134/E-MTAB-6134.processed.1.zip               ImmuneClassical\n",
      "  G046800_F02              Homo sapiens                                adult                 male                       pancreas pancreatic ductal adenocarcinoma                       neoplasm              tumour grading G2                                T3N1               resection margin R0                    Saint Antoine                             12                      25.2                         1                      16.64                          1                       not available                     Desmoplastic                         2.23      no mutation in KRas         mutation in TP53      no mutation in CDKN2a ftp://ftp.ebi.ac.uk/pub/databases/microarray/data/experiment/MTAB/E-MTAB-6134/E-MTAB-6134.raw.1.zip ftp://ftp.ebi.ac.uk/pub/databases/microarray/data/experiment/MTAB/E-MTAB-6134/E-MTAB-6134.processed.1.zip                  Desmoplastic\n",
      "    A2299_053              Homo sapiens                                adult                 male                       pancreas pancreatic ductal adenocarcinoma                       neoplasm              tumour grading G2                                T3N1               resection margin R0                          Belgium                             14                      9.21                         1                       8.62                          1                       not available                     Desmoplastic                         2.26      no mutation in KRas         mutation in TP53      no mutation in CDKN2a ftp://ftp.ebi.ac.uk/pub/databases/microarray/data/experiment/MTAB/E-MTAB-6134/E-MTAB-6134.raw.1.zip ftp://ftp.ebi.ac.uk/pub/databases/microarray/data/experiment/MTAB/E-MTAB-6134/E-MTAB-6134.processed.1.zip                  Desmoplastic\n"
     ]
    }
   ],
   "source": [
    "# --- E-MTAB-6134 (Puleo 2018) • Build survival even if SDRF lacks \"Characteristics[...]\"\n",
    "# Saves: ~/Desktop/Puleo_survival_from_SDRF.csv\n",
    "import re, requests, pandas as pd, numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "DESKTOP = Path(\"~/Desktop\").expanduser()\n",
    "DESKTOP.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "SDRF_URL = \"https://www.ebi.ac.uk/arrayexpress/files/E-MTAB-6134/E-MTAB-6134.sdrf.txt\"\n",
    "SDRF = DESKTOP / \"E-MTAB-6134.sdrf.txt\"\n",
    "\n",
    "# Download once (delete to re-download)\n",
    "if not SDRF.exists():\n",
    "    r = requests.get(SDRF_URL, timeout=120)\n",
    "    r.raise_for_status()\n",
    "    SDRF.write_bytes(r.content)\n",
    "\n",
    "sdrf = pd.read_csv(SDRF, sep=\"\\t\", dtype=str).fillna(\"\")\n",
    "\n",
    "print(\"[SDRF] columns (count={}):\".format(len(sdrf.columns)))\n",
    "for i, c in enumerate(sdrf.columns):\n",
    "    print(f\"  {i:>3} | {c}\")\n",
    "\n",
    "# ---------- Choose an ID column to index samples ----------\n",
    "id_col = None\n",
    "for c in [\"Assay Name\", \"Sample Name\", \"Source Name\", \"Scan Name\", \"Array Data File\", \"Derived Array Data File\"]:\n",
    "    if c in sdrf.columns:\n",
    "        id_col = c\n",
    "        break\n",
    "if id_col is None:\n",
    "    raise ValueError(\"No suitable ID column found in SDRF.\")\n",
    "\n",
    "sdrf[\"_id\"] = sdrf[id_col].astype(str).str.strip()\n",
    "\n",
    "# ---------- Collect any clinical-ish columns ----------\n",
    "# We will include:\n",
    "#   • Characteristics[...] (if present)\n",
    "#   • Factor Value[...] (often used in AE)\n",
    "#   • Any column whose name hints at survival/time/vital status, regardless of bracket patterns\n",
    "def norm_label(colname: str) -> str:\n",
    "    # pull text in brackets if present; else use the whole name\n",
    "    m = re.search(r\"\\[(.+?)\\]\", colname)\n",
    "    lab = (m.group(1) if m else colname).strip().lower()\n",
    "    lab = re.sub(r\"[^a-z0-9]+\", \"_\", lab)\n",
    "    lab = re.sub(r\"(^_+|_+$)\", \"\", lab)\n",
    "    return lab\n",
    "\n",
    "clin_like_regex = re.compile(\n",
    "    r\"(characteristics\\s*\\[.+?\\]|factor value\\s*\\[.+?\\]|\"\n",
    "    r\"surviv|overall|os|vital|status|alive|dead|deceased|follow|death|days|months?)\",\n",
    "    re.I\n",
    ")\n",
    "\n",
    "wide_map = {\"_id\": sdrf[\"_id\"]}\n",
    "picked_cols = []\n",
    "\n",
    "for c in sdrf.columns:\n",
    "    if c == \"_id\":\n",
    "        continue\n",
    "    if clin_like_regex.search(c):\n",
    "        picked_cols.append(c)\n",
    "        wide_map[norm_label(c)] = sdrf[c].astype(str)\n",
    "\n",
    "if len(picked_cols) == 0:\n",
    "    print(\"[INFO] No Characteristics/Factor Value/clinical-looking columns found. \"\n",
    "          \"Will still try free-text on *all* columns.\")\n",
    "\n",
    "# As a last resort, build a free-text matrix of ALL columns (kept separate)\n",
    "all_text = sdrf.drop(columns=[\"_id\"]).astype(str)\n",
    "\n",
    "wide = pd.DataFrame(wide_map).set_index(\"_id\")\n",
    "print(f\"[WIDE] built with {wide.shape[1]} columns (normalized).\")\n",
    "\n",
    "# ---------- Extract survival: time_months and event ----------\n",
    "time_month_labels = [k for k in wide.columns if re.search(r\"(overall|os|survival|time).*month|^months$\", k)]\n",
    "time_day_labels   = [k for k in wide.columns if re.search(r\"(overall|os|survival|time).*day|days_to_(death|follow)\", k)]\n",
    "status_labels     = [k for k in wide.columns if re.search(r\"(vital.*status|status|event|alive|dead|deceased)\", k)]\n",
    "\n",
    "def to_num(s):\n",
    "    m = re.search(r\"([0-9]+(?:\\.[0-9]+)?)\", str(s))\n",
    "    return float(m.group(1)) if m else np.nan\n",
    "\n",
    "def to_event(v):\n",
    "    s = str(v).strip().lower()\n",
    "    if any(x in s for x in [\"dead\",\"deceased\",\"died\",\"death\"]): return 1.0\n",
    "    if any(x in s for x in [\"alive\",\"living\"]):                 return 0.0\n",
    "    if s.startswith(\"1\"): return 1.0\n",
    "    if s.startswith(\"0\"): return 0.0\n",
    "    return np.nan\n",
    "\n",
    "surv = pd.DataFrame(index=wide.index, columns=[\"time_months\",\"event\"], dtype=float)\n",
    "\n",
    "# Months directly\n",
    "for k in time_month_labels:\n",
    "    vals = wide[k].map(to_num)\n",
    "    surv[\"time_months\"] = surv[\"time_months\"].fillna(vals)\n",
    "\n",
    "# Days -> months\n",
    "for k in time_day_labels:\n",
    "    vals = wide[k].map(to_num) / 30.44\n",
    "    surv[\"time_months\"] = surv[\"time_months\"].fillna(vals)\n",
    "\n",
    "# Event/status\n",
    "for k in status_labels:\n",
    "    surv[\"event\"] = surv[\"event\"].fillna(wide[k].map(to_event))\n",
    "\n",
    "# ---------- Free-text fallback over ALL *picked* columns ----------\n",
    "def parse_free_row(row) -> dict:\n",
    "    try:\n",
    "        t = \" ; \".join([str(x) for x in row if isinstance(x, str)]).lower()\n",
    "    except Exception:\n",
    "        t = \"\"\n",
    "    out = {}\n",
    "\n",
    "    m = re.search(r\"(overall|os|survival|time)\\W*(months|mos)\\W*([0-9.]+)\", t, re.I)\n",
    "    if m: out[\"time_months\"] = float(m.group(3))\n",
    "\n",
    "    m = re.search(r\"(overall|os|survival|time)\\W*(days)\\W*([0-9.]+)\", t, re.I)\n",
    "    if m and \"time_months\" not in out:\n",
    "        out[\"time_months\"] = float(m.group(3)) / 30.44\n",
    "\n",
    "    m = re.search(r\"days\\W*to\\W*death\\W*([0-9.]+)\", t, re.I)\n",
    "    if m:\n",
    "        out[\"event\"] = 1.0\n",
    "        out[\"time_months\"] = float(m.group(1)) / 30.44\n",
    "\n",
    "    m = re.search(r\"(days\\W*to\\W*last\\W*follow(?:-|\\s)?up)\\W*([0-9.]+)\", t, re.I)\n",
    "    if m and \"time_months\" not in out:\n",
    "        out[\"event\"] = 0.0\n",
    "        out[\"time_months\"] = float(m.group(2)) / 30.44\n",
    "\n",
    "    m = re.search(r\"(vital|status|event|deceased|dead|alive)\\W*[:=]?\\W*([a-z0-9 _()-]+)\", t, re.I)\n",
    "    if m:\n",
    "        ev = to_event(m.group(2))\n",
    "        if not np.isnan(ev): out[\"event\"] = ev\n",
    "\n",
    "    return out\n",
    "\n",
    "if wide.shape[1] > 0:\n",
    "    free = wide.apply(parse_free_row, axis=1)\n",
    "    tm = free.map(lambda d: d.get(\"time_months\", np.nan) if isinstance(d, dict) else np.nan)\n",
    "    ev = free.map(lambda d: d.get(\"event\", np.nan)       if isinstance(d, dict) else np.nan)\n",
    "    surv[\"time_months\"] = surv[\"time_months\"].fillna(tm)\n",
    "    surv[\"event\"]       = surv[\"event\"].fillna(ev)\n",
    "else:\n",
    "    # Absolute last resort: free-text scan across ALL SDRF columns\n",
    "    free = all_text.apply(parse_free_row, axis=1)\n",
    "    tm = free.map(lambda d: d.get(\"time_months\", np.nan) if isinstance(d, dict) else np.nan)\n",
    "    ev = free.map(lambda d: d.get(\"event\", np.nan)       if isinstance(d, dict) else np.nan)\n",
    "    surv = pd.DataFrame({\n",
    "        \"time_months\": tm.values,\n",
    "        \"event\": ev.values\n",
    "    }, index=sdrf[\"_id\"])\n",
    "\n",
    "# ---------- Final tidy + save ----------\n",
    "surv = surv.dropna(subset=[\"time_months\"])\n",
    "surv[\"event\"] = surv[\"event\"].fillna(0.0).clip(0,1)\n",
    "surv.index.name = \"sample_id\"\n",
    "\n",
    "out_csv = DESKTOP / \"Puleo_survival_from_SDRF.csv\"\n",
    "surv.to_csv(out_csv)\n",
    "print(f\"\\n✅ Puleo survival rows: {surv.shape[0]}  -> {out_csv}\")\n",
    "\n",
    "# ---------- If still zero, show a compact explorer so we can hard-wire column names ----------\n",
    "if surv.shape[0] == 0:\n",
    "    print(\"\\n[EXPLORER] No survival parsed. Let's inspect.\")\n",
    "    print(\"ID column used:\", id_col)\n",
    "    print(\"\\nTop 60 header names:\")\n",
    "    for i, c in enumerate(sdrf.columns[:60]):\n",
    "        print(f\"  {i:>3} | {c}\")\n",
    "\n",
    "    # Find all columns that might plausibly carry clinical info\n",
    "    hint_cols = [c for c in sdrf.columns if re.search(\n",
    "        r\"(characteristics|factor value|comment|surviv|overall|os|vital|status|alive|dead|deceased|follow|death|days|months?)\",\n",
    "        c, re.I)]\n",
    "    print(\"\\nCandidate clinical-ish columns ({} found):\".format(len(hint_cols)))\n",
    "    for c in hint_cols[:50]:\n",
    "        print(\" \", c)\n",
    "\n",
    "    # Peek a few rows for those columns\n",
    "    if hint_cols:\n",
    "        print(\"\\n[PEEK clinical-ish columns] first 5 rows:\")\n",
    "        print(sdrf[[\"_id\"] + hint_cols].head(5).to_string(index=False))\n",
    "    else:\n",
    "        print(\"\\n[PEEK first 8 rows of SDRF]:\")\n",
    "        print(sdrf.head(8).to_string(index=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2e3f154f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Puleo survival rows: 288  -> /Users/scottpowers/Desktop/Puleo_survival_from_SDRF.csv\n",
      "[checks] unit column used: Unit[time unit].1\n",
      "event\n",
      "0.0    288\n",
      "Name: count, dtype: int64\n",
      "count    288.000000\n",
      "mean      29.812847\n",
      "std       26.907389\n",
      "min        1.120000\n",
      "25%       11.855000\n",
      "50%       20.855000\n",
      "75%       37.107500\n",
      "max      146.400000\n",
      "Name: time_months, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# --- E-MTAB-6134 (Puleo 2018) • OS survival from SDRF explicit columns ---\n",
    "# Uses: Characteristics[os.delay], Unit[time unit].1 (if present), Characteristics[os.event]\n",
    "# Saves: ~/Desktop/Puleo_survival_from_SDRF.csv\n",
    "import re, pandas as pd, numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "DESKTOP = Path(\"~/Desktop\").expanduser()\n",
    "SDRF = DESKTOP / \"E-MTAB-6134.sdrf.txt\"\n",
    "\n",
    "sdrf = pd.read_csv(SDRF, sep=\"\\t\", dtype=str).fillna(\"\")\n",
    "\n",
    "# Pick a stable ID (ArrayExpress: 'Assay Name' is best)\n",
    "id_col = \"Assay Name\" if \"Assay Name\" in sdrf.columns else None\n",
    "for c in [\"Sample Name\", \"Source Name\", \"Array Data File\", \"Derived Array Data File\"]:\n",
    "    if id_col is None and c in sdrf.columns:\n",
    "        id_col = c\n",
    "if id_col is None:\n",
    "    raise ValueError(\"No suitable ID column in SDRF.\")\n",
    "sdrf[\"_id\"] = sdrf[id_col].astype(str).str.strip()\n",
    "\n",
    "# Required fields\n",
    "time_col  = \"Characteristics[os.delay]\"\n",
    "event_col = \"Characteristics[os.event]\"\n",
    "if time_col not in sdrf.columns or event_col not in sdrf.columns:\n",
    "    raise ValueError(\"Expected OS columns not found. Need 'Characteristics[os.delay]' and 'Characteristics[os.event]'.\")\n",
    "\n",
    "# Try to pick the unit column immediately after os.delay (as in your header listing)\n",
    "unit_col = None\n",
    "cols = list(sdrf.columns)\n",
    "if time_col in cols:\n",
    "    ix = cols.index(time_col)\n",
    "    if ix+1 < len(cols) and cols[ix+1].startswith(\"Unit[time unit]\"):\n",
    "        unit_col = cols[ix+1]\n",
    "# Fallback: any Unit[...] column\n",
    "if unit_col is None:\n",
    "    for c in sdrf.columns:\n",
    "        if c.startswith(\"Unit[time unit]\"):\n",
    "            unit_col = c\n",
    "            break\n",
    "\n",
    "def to_float_num(s: str) -> float:\n",
    "    m = re.search(r\"([0-9]+(?:\\.[0-9]+)?)\", str(s))\n",
    "    return float(m.group(1)) if m else np.nan\n",
    "\n",
    "def to_event(v) -> float:\n",
    "    s = str(v).strip().lower()\n",
    "    if s in {\"1\",\"yes\",\"true\",\"event\",\"dead\",\"deceased\",\"died\",\"death\"}: return 1.0\n",
    "    if s in {\"0\",\"no\",\"false\",\"alive\",\"living\",\"censored\"}:               return 0.0\n",
    "    # tolerate \"1 (dead)\" / \"0 (alive)\"\n",
    "    if s.startswith(\"1\"): return 1.0\n",
    "    if s.startswith(\"0\"): return 0.0\n",
    "    return np.nan\n",
    "\n",
    "# Parse time and convert units if needed\n",
    "time_vals = sdrf[time_col].map(to_float_num)\n",
    "if unit_col and unit_col in sdrf.columns:\n",
    "    units = sdrf[unit_col].astype(str).str.lower().str.strip()\n",
    "    # If explicitly \"days\", convert to months; if \"months\"/empty/missing, leave as-is\n",
    "    is_days = units.str.contains(\"day\", na=False)\n",
    "    time_vals = np.where(is_days, time_vals/30.44, time_vals)\n",
    "\n",
    "event_vals = sdrf[event_col].map(to_event)\n",
    "\n",
    "surv = pd.DataFrame({\n",
    "    \"time_months\": time_vals,\n",
    "    \"event\": event_vals\n",
    "}, index=sdrf[\"_id\"])\n",
    "\n",
    "# Clean up\n",
    "surv = surv.dropna(subset=[\"time_months\"])\n",
    "surv[\"event\"] = surv[\"event\"].fillna(0.0).clip(0,1)\n",
    "surv.index.name = \"sample_id\"\n",
    "\n",
    "out_csv = DESKTOP / \"Puleo_survival_from_SDRF.csv\"\n",
    "surv.to_csv(out_csv)\n",
    "print(f\"✅ Puleo survival rows: {surv.shape[0]}  -> {out_csv}\")\n",
    "print(\"[checks] unit column used:\", unit_col)\n",
    "print(surv[\"event\"].value_counts(dropna=False))\n",
    "print(surv[\"time_months\"].describe())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "523570d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DL] Found 1 ZIP(s):\n",
      "    https://ftp.ebi.ac.uk/pub/databases/microarray/data/experiment/MTAB/E-MTAB-6134/E-MTAB-6134.processed.1.zip\n",
      "[DL] exists -> E-MTAB-6134.processed.1.zip\n",
      "\n",
      "[CANDIDATES] potential matrices (largest first):\n",
      "  ProcessedExpression.tsv                   258.47 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/mh/r2nrb73509z0t_wjbx9r5fg00000gn/T/ipykernel_92012/1006120790.py:160: FutureWarning: DataFrame.groupby with axis=1 is deprecated. Do `frame.T.groupby(...)` without axis instead.\n",
      "  df = df.groupby(df.columns, axis=1).mean(numeric_only=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ Saved expression: /Users/scottpowers/Desktop/E-MTAB-6134_expression.csv (genes=49386, samples=308)\n",
      "  picked file: ProcessedExpression.tsv\n",
      "[OVERLAP] expression vs survival (Assay Name): 0 / 308\n",
      "  Note: if columns still look like file stems, mapping used Array/Derived file stems → Assay Name.\n"
     ]
    }
   ],
   "source": [
    "# --- E-MTAB-6134 (Puleo 2018) • Download & build processed expression (FTP→HTTPS fix) ---\n",
    "# Outputs:\n",
    "#   ~/Desktop/E-MTAB-6134_expression.csv  (genes x samples; columns = Assay Name where possible)\n",
    "#   Overlap report with ~/Desktop/Puleo_survival_from_SDRF.csv (if present)\n",
    "\n",
    "import os, re, zipfile, requests, pandas as pd, numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "DESKTOP = Path(\"~/Desktop\").expanduser()\n",
    "OUTDIR  = DESKTOP / \"E-MTAB-6134_processed\"\n",
    "OUTDIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "SDRF = DESKTOP / \"E-MTAB-6134.sdrf.txt\"   # make sure you ran the SDRF step first\n",
    "SURV = DESKTOP / \"Puleo_survival_from_SDRF.csv\"\n",
    "\n",
    "if not SDRF.exists():\n",
    "    raise FileNotFoundError(\"Missing E-MTAB-6134.sdrf.txt on Desktop. Run the SDRF step first.\")\n",
    "\n",
    "# --- Load SDRF\n",
    "sdrf = pd.read_csv(SDRF, sep=\"\\t\", dtype=str).fillna(\"\")\n",
    "\n",
    "# Choose ID column (Assay Name best)\n",
    "id_col = \"Assay Name\" if \"Assay Name\" in sdrf.columns else None\n",
    "for c in [\"Sample Name\", \"Source Name\", \"Array Data File\", \"Derived Array Data File\"]:\n",
    "    if id_col is None and c in sdrf.columns:\n",
    "        id_col = c\n",
    "if id_col is None:\n",
    "    raise ValueError(\"No suitable ID column found in SDRF.\")\n",
    "sdrf[\"_id\"] = sdrf[id_col].astype(str).str.strip()\n",
    "\n",
    "# Build filename stem -> Assay Name map from Array/Derived files\n",
    "def stem(s):\n",
    "    s = str(s)\n",
    "    s = s.split(\"/\")[-1]  # strip path\n",
    "    s = re.sub(r\"\\.(txt|tsv|csv|gct|cel)(\\.gz)?$|\\.zip$\", \"\", s, flags=re.I)\n",
    "    return s.strip()\n",
    "\n",
    "file_cols = [c for c in [\"Array Data File\",\"Derived Array Data File\"] if c in sdrf.columns]\n",
    "fname_to_assay = {}\n",
    "for c in file_cols:\n",
    "    for _, row in sdrf[[c, \"_id\"]].iterrows():\n",
    "        fn = stem(row[c])\n",
    "        if fn:\n",
    "            fname_to_assay[fn] = row[\"_id\"]\n",
    "\n",
    "# Collect processed ZIP URLs, normalize FTP→HTTPS\n",
    "url_col = None\n",
    "for c in [\"Comment [Derived ArrayExpress FTP file]\", \"Comment [ArrayExpress FTP file]\"]:\n",
    "    if c in sdrf.columns:\n",
    "        url_col = c\n",
    "        break\n",
    "if url_col is None:\n",
    "    raise ValueError(\"No FTP file URL columns found in SDRF.\")\n",
    "\n",
    "def normalize_url(u: str) -> str:\n",
    "    u = u.strip()\n",
    "    # Primary: swap ftp://ftp.ebi.ac.uk → https://ftp.ebi.ac.uk\n",
    "    if u.lower().startswith(\"ftp://ftp.ebi.ac.uk\"):\n",
    "        return \"https://\" + u[len(\"ftp://\"):]\n",
    "    # Sometimes URLs start with http://; upgrade to https\n",
    "    if u.lower().startswith(\"http://\"):\n",
    "        return \"https://\" + u[7:]\n",
    "    return u  # already https\n",
    "\n",
    "zip_urls = sorted(set(sdrf[url_col].dropna().astype(str)))\n",
    "zip_urls = [normalize_url(u) for u in zip_urls if u.lower().endswith(\".zip\")]\n",
    "\n",
    "if not zip_urls:\n",
    "    raise ValueError(\"No processed ZIP URLs found in SDRF.\")\n",
    "\n",
    "print(f\"[DL] Found {len(zip_urls)} ZIP(s):\")\n",
    "for u in zip_urls:\n",
    "    print(\"   \", u)\n",
    "\n",
    "# Download & extract\n",
    "local_zips = []\n",
    "for u in zip_urls:\n",
    "    name = u.split(\"/\")[-1]\n",
    "    lp = OUTDIR / name\n",
    "    if not lp.exists():\n",
    "        print(\"[DL] downloading ->\", name)\n",
    "        with requests.get(u, stream=True, timeout=300) as r:\n",
    "            r.raise_for_status()\n",
    "            with open(lp, \"wb\") as f:\n",
    "                for chunk in r.iter_content(1<<20):\n",
    "                    if chunk: f.write(chunk)\n",
    "    else:\n",
    "        print(\"[DL] exists ->\", name)\n",
    "    local_zips.append(lp)\n",
    "\n",
    "# Extract all text-ish files\n",
    "extract_dir = OUTDIR / \"unzipped\"\n",
    "extract_dir.mkdir(exist_ok=True)\n",
    "candidates = []\n",
    "for zp in local_zips:\n",
    "    try:\n",
    "        with zipfile.ZipFile(zp) as zf:\n",
    "            for info in zf.infolist():\n",
    "                if info.is_dir():\n",
    "                    continue\n",
    "                fn = info.filename\n",
    "                if re.search(r\"\\.(txt|tsv|csv|gct)(\\.gz)?$\", fn, re.I):\n",
    "                    dst = extract_dir / Path(fn).name\n",
    "                    if not dst.exists():\n",
    "                        with zf.open(info) as src, open(dst, \"wb\") as out:\n",
    "                            out.write(src.read())\n",
    "                    candidates.append(dst)\n",
    "    except zipfile.BadZipFile:\n",
    "        print(\"[WARN] Bad zip:\", zp)\n",
    "\n",
    "if not candidates:\n",
    "    raise FileNotFoundError(\"No txt/tsv/csv/gct files found in processed ZIPs.\")\n",
    "\n",
    "# Pick likely matrix: largest table-like file\n",
    "candidates = sorted(candidates, key=lambda p: p.stat().st_size, reverse=True)\n",
    "print(\"\\n[CANDIDATES] potential matrices (largest first):\")\n",
    "for p in candidates[:10]:\n",
    "    print(f\"  {p.name:40s}  {p.stat().st_size/1e6:6.2f} MB\")\n",
    "\n",
    "# Try reading candidates until one looks like genes x samples\n",
    "def try_read(path: Path):\n",
    "    # Guess sep by extension\n",
    "    if path.suffix.lower() == \".csv\":\n",
    "        df = pd.read_csv(path, dtype=str)\n",
    "    else:\n",
    "        df = pd.read_csv(path, sep=\"\\t\", dtype=str)\n",
    "    return df\n",
    "\n",
    "expr_df = None\n",
    "picked = None\n",
    "for path in candidates:\n",
    "    try:\n",
    "        df = try_read(path)\n",
    "        if df.shape[1] < 10 or df.shape[0] < 1000:\n",
    "            continue\n",
    "        first_col = df.columns[0]\n",
    "        # first column should look gene-like\n",
    "        gene_like = df[first_col].astype(str).str.match(r\"^[A-Za-z0-9._-]+$\", na=False).mean() > 0.8\n",
    "        if not gene_like:\n",
    "            continue\n",
    "        df = df.set_index(first_col)\n",
    "        # numeric conversion\n",
    "        for c in df.columns:\n",
    "            df[c] = pd.to_numeric(df[c], errors=\"coerce\")\n",
    "        df = df.dropna(axis=1, how=\"all\")\n",
    "\n",
    "        # Map column names (often file stems) → Assay Name via SDRF\n",
    "        cols = df.columns.astype(str).str.strip()\n",
    "        stems = cols.str.replace(r\"\\.(txt|tsv|csv|gct)$\", \"\", regex=True, flags=re.I)\n",
    "        mapped = []\n",
    "        mapped_ok = 0\n",
    "        for s in stems:\n",
    "            if s in fname_to_assay:\n",
    "                mapped.append(fname_to_assay[s])\n",
    "                mapped_ok += 1\n",
    "            else:\n",
    "                mapped.append(s)  # might already be Assay Name\n",
    "        df.columns = pd.Index(mapped, name=\"AssayName_or_stem\")\n",
    "        # collapse duplicates (e.g., multi-file per assay) by mean\n",
    "        df = df.groupby(df.columns, axis=1).mean(numeric_only=True)\n",
    "\n",
    "        expr_df = df\n",
    "        picked = path\n",
    "        break\n",
    "    except Exception as e:\n",
    "        # Uncomment to debug specific file failures:\n",
    "        # print(f\"[skip] {path.name}: {e}\")\n",
    "        continue\n",
    "\n",
    "if expr_df is None:\n",
    "    raise RuntimeError(\"Failed to auto-detect a usable expression matrix from processed ZIPs.\")\n",
    "\n",
    "# Clean gene index\n",
    "idx = expr_df.index.astype(str)\n",
    "mask_bad = idx.str.fullmatch(r\"\\s*|\\?+|NA\", case=False) | idx.str.startswith(\"?\")\n",
    "expr_df = expr_df[~mask_bad]\n",
    "expr_df = expr_df[~expr_df.index.duplicated(keep=\"first\")]\n",
    "\n",
    "# Save expression\n",
    "expr_out = DESKTOP / \"E-MTAB-6134_expression.csv\"\n",
    "expr_df.to_csv(expr_out)\n",
    "print(f\"\\n✅ Saved expression: {expr_out} (genes={expr_df.shape[0]}, samples={expr_df.shape[1]})\")\n",
    "print(\"  picked file:\", picked.name)\n",
    "\n",
    "# If survival exists, report overlap\n",
    "if SURV.exists():\n",
    "    surv = pd.read_csv(SURV, index_col=0)\n",
    "    surv.index = surv.index.astype(str).str.strip()\n",
    "    common = expr_df.columns.intersection(surv.index)\n",
    "    print(f\"[OVERLAP] expression vs survival (Assay Name): {len(common)} / {expr_df.shape[1]}\")\n",
    "    if len(common) < 10:\n",
    "        print(\"  Note: if columns still look like file stems, mapping used Array/Derived file stems → Assay Name.\")\n",
    "else:\n",
    "    print(f\"[NOTE] Survival CSV not found at {SURV}. Build it first if you want overlap reported.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0945439e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LOAD] expr shape: (49386, 308)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/mh/r2nrb73509z0t_wjbx9r5fg00000gn/T/ipykernel_92012/1754427058.py:98: FutureWarning: DataFrame.groupby with axis=1 is deprecated. Do `frame.T.groupby(...)` without axis instead.\n",
      "  expr = expr.groupby(expr.columns, axis=1).mean(numeric_only=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved remapped expression: /Users/scottpowers/Desktop/E-MTAB-6134_expression_ASSAY.csv (genes=49386, samples=308)\n",
      "[MAP] columns matching Assay Name now: 0 / 308\n",
      "\n",
      "[UNMAPPED sample columns] showing up to 12:\n",
      "  - PANC1\n",
      "  - PANC10\n",
      "  - PANC100\n",
      "  - PANC101\n",
      "  - PANC103\n",
      "  - PANC104\n",
      "  - PANC105\n",
      "  - PANC106\n",
      "  - PANC107\n",
      "  - PANC108\n",
      "  - PANC109\n",
      "  - PANC11\n",
      "\n",
      "[OVERLAP] expression vs survival: 0 / 308\n",
      "Tip: the above UNMAPPED column examples will help refine mapping if needed.\n"
     ]
    }
   ],
   "source": [
    "# --- Map E-MTAB-6134 expression columns to Assay Name using SDRF (robust) ---\n",
    "import re, pandas as pd, numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "DESKTOP = Path(\"~/Desktop\").expanduser()\n",
    "SDRF = DESKTOP / \"E-MTAB-6134.sdrf.txt\"\n",
    "EXPR = DESKTOP / \"E-MTAB-6134_expression.csv\"   # from previous step\n",
    "SURV = DESKTOP / \"Puleo_survival_from_SDRF.csv\" # from previous step\n",
    "\n",
    "# Load\n",
    "sdrf = pd.read_csv(SDRF, sep=\"\\t\", dtype=str).fillna(\"\")\n",
    "expr = pd.read_csv(EXPR, index_col=0)\n",
    "print(f\"[LOAD] expr shape: {expr.shape}\")\n",
    "\n",
    "# Choose ID = Assay Name\n",
    "id_col = \"Assay Name\" if \"Assay Name\" in sdrf.columns else None\n",
    "for c in [\"Sample Name\", \"Source Name\", \"Array Data File\", \"Derived Array Data File\"]:\n",
    "    if id_col is None and c in sdrf.columns:\n",
    "        id_col = c\n",
    "if id_col is None:\n",
    "    raise ValueError(\"No suitable ID column found.\")\n",
    "sdrf[\"_id\"] = sdrf[id_col].astype(str).str.strip()\n",
    "\n",
    "# Helper normalizers\n",
    "def basename(p):\n",
    "    s = str(p)\n",
    "    s = s.split(\"/\")[-1]\n",
    "    return s\n",
    "\n",
    "def strip_ext(s):\n",
    "    return re.sub(r\"\\.(txt|tsv|csv|gct|cel)(\\.gz)?$\", \"\", str(s), flags=re.I)\n",
    "\n",
    "def norm(s):\n",
    "    s = str(s).strip().lower()\n",
    "    # unify common separators and remove non-alnum\n",
    "    s = re.sub(r\"[._\\- ]+\", \"\", s)\n",
    "    return s\n",
    "\n",
    "# Build a big dictionary of candidate → Assay Name\n",
    "cand_to_assay = {}\n",
    "\n",
    "def add_cand(key, assay):\n",
    "    if key:\n",
    "        cand_to_assay.setdefault(key, assay)\n",
    "\n",
    "file_cols = [c for c in [\"Array Data File\",\"Derived Array Data File\"] if c in sdrf.columns]\n",
    "\n",
    "for _, row in sdrf.iterrows():\n",
    "    assay = str(row[\"_id\"]).strip()\n",
    "    # direct Assay Name itself\n",
    "    add_cand(norm(assay), assay)\n",
    "\n",
    "    # file-based candidates\n",
    "    for c in file_cols:\n",
    "        val = row.get(c, \"\")\n",
    "        if not val: \n",
    "            continue\n",
    "        b = basename(val)\n",
    "        st = strip_ext(b)\n",
    "\n",
    "        # raw variants\n",
    "        for v in [b, st]:\n",
    "            add_cand(norm(v), assay)\n",
    "            add_cand(norm(v.replace(\" \", \"\")), assay)\n",
    "\n",
    "        # also try removing common processed suffixes\n",
    "        for v in [st]:\n",
    "            v2 = re.sub(r\"(_normalized|_processed|_proc|_signal|_matrix)$\", \"\", v, flags=re.I)\n",
    "            if v2 != v:\n",
    "                add_cand(norm(v2), assay)\n",
    "\n",
    "# Try mapping each expression column\n",
    "expr_cols = pd.Index(expr.columns.astype(str).str.strip())\n",
    "mapped = []\n",
    "unmapped = []\n",
    "\n",
    "for c in expr_cols:\n",
    "    c_norms = {\n",
    "        norm(c),\n",
    "        norm(strip_ext(c)),\n",
    "        norm(basename(c)),\n",
    "        norm(strip_ext(basename(c))),\n",
    "    }\n",
    "    hit = None\n",
    "    for k in c_norms:\n",
    "        if k in cand_to_assay:\n",
    "            hit = cand_to_assay[k]\n",
    "            break\n",
    "    if hit is None:\n",
    "        unmapped.append(c)\n",
    "        mapped.append(c)  # keep original for now\n",
    "    else:\n",
    "        mapped.append(hit)\n",
    "\n",
    "expr.columns = pd.Index(mapped, name=\"AssayName_or_stem\")\n",
    "\n",
    "# Collapse duplicates after mapping\n",
    "expr = expr.groupby(expr.columns, axis=1).mean(numeric_only=True)\n",
    "\n",
    "# Save remapped expression\n",
    "remap_out = DESKTOP / \"E-MTAB-6134_expression_ASSAY.csv\"\n",
    "expr.to_csv(remap_out)\n",
    "print(f\"✅ Saved remapped expression: {remap_out} (genes={expr.shape[0]}, samples={expr.shape[1]})\")\n",
    "\n",
    "# Report mapping quality\n",
    "mapped_n = sum(1 for c in mapped if c in sdrf[\"_id\"].values)\n",
    "print(f\"[MAP] columns matching Assay Name now: {mapped_n} / {len(mapped)}\")\n",
    "\n",
    "if unmapped:\n",
    "    print(\"\\n[UNMAPPED sample columns] showing up to 12:\")\n",
    "    for u in unmapped[:12]:\n",
    "        print(\"  -\", u)\n",
    "\n",
    "# Overlap with survival\n",
    "if SURV.exists():\n",
    "    surv = pd.read_csv(SURV, index_col=0)\n",
    "    surv.index = surv.index.astype(str).str.strip()\n",
    "    common = expr.columns.intersection(surv.index)\n",
    "    print(f\"\\n[OVERLAP] expression vs survival: {len(common)} / {expr.shape[1]}\")\n",
    "    if len(common) < 10 and unmapped:\n",
    "        print(\"Tip: the above UNMAPPED column examples will help refine mapping if needed.\")\n",
    "else:\n",
    "    print(f\"[NOTE] Survival not found at {SURV}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "75be115b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SDRF] direct PANC→Assay matches: 309\n",
      "[TOTAL MAP] PANC→Assay entries: 309\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/mh/r2nrb73509z0t_wjbx9r5fg00000gn/T/ipykernel_92012/924114064.py:128: FutureWarning: DataFrame.groupby with axis=1 is deprecated. Do `frame.T.groupby(...)` without axis instead.\n",
      "  expr = expr.groupby(expr.columns, axis=1).mean(numeric_only=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved remapped expression: /Users/scottpowers/Desktop/E-MTAB-6134_expression_ASSAY.csv (genes=49386, samples=308)\n",
      "[MAP] columns mapped to Assay Name: 308 / 308\n",
      "[OVERLAP] expression vs survival: 287 / 308\n"
     ]
    }
   ],
   "source": [
    "# --- Build PANC### → Assay Name mapping, remap expression columns, and re-check overlap ---\n",
    "import re, pandas as pd, numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "DESKTOP = Path(\"~/Desktop\").expanduser()\n",
    "SDRF = DESKTOP / \"E-MTAB-6134.sdrf.txt\"\n",
    "EXPR = DESKTOP / \"E-MTAB-6134_expression.csv\"            # (genes x samples) columns = PANC###\n",
    "SURV = DESKTOP / \"Puleo_survival_from_SDRF.csv\"\n",
    "UNZ  = DESKTOP / \"E-MTAB-6134_processed\" / \"unzipped\"    # extracted files live here\n",
    "\n",
    "# ---- helpers ----\n",
    "PANC_RE = re.compile(r\"^PANC\\d+$\", re.I)\n",
    "\n",
    "def norm(s): return str(s).strip()\n",
    "\n",
    "def collect_panc_in_df(df):\n",
    "    \"\"\"Return dict {PANC#: True} if any entries look like PANC IDs.\"\"\"\n",
    "    vals = set()\n",
    "    for col in df.columns:\n",
    "        ser = df[col].astype(str)\n",
    "        vals |= {v for v in ser[ser.str.match(PANC_RE, na=False)]}\n",
    "    return {v: True for v in vals}\n",
    "\n",
    "def try_build_map_from_df(df, assay_series):\n",
    "    \"\"\"\n",
    "    Try to build {PANC#: AssayName} from a DF that contains a PANC column and a column we can tie to assay.\n",
    "    We use same-row matching via columns that frequently appear in SDRF/side files.\n",
    "    \"\"\"\n",
    "    cand_cols = [c for c in df.columns if df[c].astype(str).str.match(PANC_RE, na=False).any()]\n",
    "    if not cand_cols:\n",
    "        return {}\n",
    "    out = {}\n",
    "    # Try to find a column that equals Assay Name or can map to it via SDRF fields\n",
    "    # First: exact 'Assay Name'\n",
    "    for panc_col in cand_cols:\n",
    "        if \"Assay Name\" in df.columns:\n",
    "            for _, row in df[[panc_col, \"Assay Name\"]].iterrows():\n",
    "                p = str(row[panc_col]).strip()\n",
    "                a = str(row[\"Assay Name\"]).strip()\n",
    "                if PANC_RE.match(p) and a:\n",
    "                    out[p] = a\n",
    "        # Next: try via Array/Derived file → Assay Name map (using SDRF)\n",
    "        for file_col in [\"Array Data File\",\"Derived Array Data File\",\"filename\",\"file\",\"File\",\"FILE\"]:\n",
    "            if file_col in df.columns and file_col in sdrf.columns:\n",
    "                # Build filename->Assay map from SDRF\n",
    "                fname_map = {}\n",
    "                for _, srow in sdrf[[file_col, \"Assay Name\"]].dropna().iterrows():\n",
    "                    fn = str(srow[file_col]).split(\"/\")[-1]\n",
    "                    if fn:\n",
    "                        fname_map[fn] = str(srow[\"Assay Name\"]).strip()\n",
    "                for _, row in df[[panc_col, file_col]].iterrows():\n",
    "                    p = str(row[panc_col]).strip()\n",
    "                    fn = str(row[file_col]).split(\"/\")[-1]\n",
    "                    a = fname_map.get(fn, \"\")\n",
    "                    if PANC_RE.match(p) and a:\n",
    "                        out[p] = a\n",
    "    return out\n",
    "\n",
    "# ---- 1) Try to get mapping directly from SDRF ----\n",
    "sdrf = pd.read_csv(SDRF, sep=\"\\t\", dtype=str).fillna(\"\")\n",
    "if \"Assay Name\" not in sdrf.columns:\n",
    "    raise ValueError(\"SDRF lacks 'Assay Name' column unexpectedly.\")\n",
    "\n",
    "panc_map = {}\n",
    "# Search every SDRF column for PANC tokens and map row-wise to Assay Name\n",
    "for c in sdrf.columns:\n",
    "    if c == \"Assay Name\": \n",
    "        continue\n",
    "    col = sdrf[c].astype(str)\n",
    "    mask = col.str.match(PANC_RE, na=False)\n",
    "    if mask.any():\n",
    "        sub = sdrf.loc[mask, [c, \"Assay Name\"]]\n",
    "        for _, row in sub.iterrows():\n",
    "            panc = str(row[c]).strip()\n",
    "            assay = str(row[\"Assay Name\"]).strip()\n",
    "            if panc and assay:\n",
    "                panc_map[panc] = assay\n",
    "\n",
    "print(f\"[SDRF] direct PANC→Assay matches: {len(panc_map)}\")\n",
    "\n",
    "# ---- 2) If still empty, scan unzipped files for a mapping table ----\n",
    "if len(panc_map) == 0 and UNZ.exists():\n",
    "    for path in sorted(UNZ.glob(\"*\")):\n",
    "        if not path.suffix.lower() in [\".txt\", \".tsv\", \".csv\", \".gct\"]:\n",
    "            continue\n",
    "        try:\n",
    "            # try tsv first, fallback to csv\n",
    "            sep = \"\\t\" if path.suffix.lower() != \".csv\" else \",\"\n",
    "            df = pd.read_csv(path, sep=sep, dtype=str).fillna(\"\")\n",
    "            if df.shape[1] > 1:\n",
    "                # quick check: does this file contain PANC IDs\n",
    "                panc_vals = collect_panc_in_df(df)\n",
    "                if not panc_vals:\n",
    "                    continue\n",
    "                # try to build mapping from this file\n",
    "                df_cols_lower = {c.lower(): c for c in df.columns}\n",
    "                # harmonize column names for convenience\n",
    "                for alias in [\"assay name\",\"AssayName\",\"assay\",\"ASSAY_NAME\"]:\n",
    "                    if alias in df_cols_lower:\n",
    "                        df.rename(columns={df_cols_lower[alias]:\"Assay Name\"}, inplace=True)\n",
    "                        break\n",
    "                # attempt mapping\n",
    "                m = try_build_map_from_df(df, sdrf[\"Assay Name\"])\n",
    "                if m:\n",
    "                    panc_map.update(m)\n",
    "                    print(f\"[MAPPING] found {len(m)} mappings in {path.name}\")\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "print(f\"[TOTAL MAP] PANC→Assay entries: {len(panc_map)}\")\n",
    "\n",
    "# ---- 3) Apply mapping to expression columns ----\n",
    "expr = pd.read_csv(EXPR, index_col=0)\n",
    "cols = expr.columns.astype(str)\n",
    "\n",
    "mapped_cols = []\n",
    "mapped_count = 0\n",
    "for c in cols:\n",
    "    key = c.strip()\n",
    "    if key in panc_map:\n",
    "        mapped_cols.append(panc_map[key])\n",
    "        mapped_count += 1\n",
    "    else:\n",
    "        mapped_cols.append(c)  # keep original if not mapped\n",
    "\n",
    "expr.columns = pd.Index(mapped_cols, name=\"sample_id\")\n",
    "# collapse duplicates if multiple PANC map to same assay\n",
    "expr = expr.groupby(expr.columns, axis=1).mean(numeric_only=True)\n",
    "\n",
    "remap_out = DESKTOP / \"E-MTAB-6134_expression_ASSAY.csv\"\n",
    "expr.to_csv(remap_out)\n",
    "print(f\"✅ Saved remapped expression: {remap_out} (genes={expr.shape[0]}, samples={expr.shape[1]})\")\n",
    "print(f\"[MAP] columns mapped to Assay Name: {mapped_count} / {len(cols)}\")\n",
    "\n",
    "# ---- 4) Overlap with survival ----\n",
    "if SURV.exists():\n",
    "    surv = pd.read_csv(SURV, index_col=0)\n",
    "    surv.index = surv.index.astype(str).str.strip()\n",
    "    common = expr.columns.intersection(surv.index)\n",
    "    print(f\"[OVERLAP] expression vs survival: {len(common)} / {expr.shape[1]}\")\n",
    "    if len(common) == 0:\n",
    "        # help: dump first 50 PANC IDs to inspect\n",
    "        panc_list = [c for c in cols if PANC_RE.match(c)]\n",
    "        dump = DESKTOP / \"E-MTAB-6134_PANC_unmapped_preview.txt\"\n",
    "        with open(dump, \"w\") as f:\n",
    "            f.write(\"\\n\".join(panc_list[:50]))\n",
    "        print(f\"[AID] Wrote first 50 expression column IDs to {dump} — \"\n",
    "              f\"send me this alongside any SDRF column that contains PANC values, and I'll hard-wire mapping.\")\n",
    "else:\n",
    "    print(f\"[NOTE] Survival not found at {SURV}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "282cb099",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[IL2] UP=106  DOWN=23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/mh/r2nrb73509z0t_wjbx9r5fg00000gn/T/ipykernel_92012/3983449935.py:13: FutureWarning: unique with argument that is not not a Series, Index, ExtensionArray, or np.ndarray is deprecated and will raise in a future version.\n",
      "  return pd.unique([g.strip().upper() for g in txt.splitlines() if g.strip()])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PULEO] expr numeric shape: (19749, 357)\n",
      "[PULEO] example cols: ['GSM1843893', 'GSM1843894', 'GSM1843895', 'GSM1843896', 'GSM1843897']\n",
      "[COVERAGE] UP 81/106 | DOWN 12/23\n",
      "[SCORES] non-NA: 357 of 357 samples\n",
      "[SAVE] out_puleo_IL2/Puleo_IL2_scores.csv\n",
      "[SAVE] out_puleo_IL2/Puleo_IL2_scores_Z.csv\n",
      "[SAVE] out_puleo_IL2/Puleo_IL2_scores_with_quartiles.csv\n",
      "[SAVE] out_puleo_IL2/Puleo_IL2_scores_hist.png\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd, numpy as np\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ================== Paths ==================\n",
    "DESKTOP = Path.home() / \"Desktop\"\n",
    "PULEO_EXPR = DESKTOP / \"Puleo_expr.csv\"\n",
    "PULEO_META = DESKTOP / \"Puleo_meta.csv\"\n",
    "OUTDIR = Path(\"./out_puleo_IL2\"); OUTDIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# ================== IL2 gene lists ==================\n",
    "def parse_genes(txt: str):\n",
    "    return pd.unique([g.strip().upper() for g in txt.splitlines() if g.strip()])\n",
    "\n",
    "UP_TEXT = \"\"\"ABHD15-AS1\n",
    "AC007780.1\n",
    "AC008105.3\n",
    "AC008964.1\n",
    "AC016831.1\n",
    "AC016831.5\n",
    "AC090772.1\n",
    "AC108863.2\n",
    "ADARB1\n",
    "ALOX5AP\n",
    "ANKH\n",
    "ANKRD44\n",
    "APOBEC3G\n",
    "ARHGDIB\n",
    "ARL6IP5\n",
    "ARSG\n",
    "ATP10D\n",
    "BCL11B\n",
    "BORCS5\n",
    "CAMK1D\n",
    "CD4\n",
    "CD84\n",
    "CD96\n",
    "CDC42EP3\n",
    "CELF2\n",
    "CERS4\n",
    "CLEC2D\n",
    "CNOT6L\n",
    "CRYBG1\n",
    "CTSW\n",
    "DSE\n",
    "FGD3\n",
    "FMNL1\n",
    "FOXN3\n",
    "FOXO1\n",
    "FYB1\n",
    "GFI1\n",
    "GNAO1\n",
    "GPRIN3\n",
    "HOPX\n",
    "IGF1\n",
    "IKZF3\n",
    "IL18R1\n",
    "INKA2\n",
    "INSYN2B\n",
    "IQSEC1\n",
    "ITPRIPL1\n",
    "JAK3\n",
    "KLRC2\n",
    "KLRC3\n",
    "KLRF1\n",
    "KLRG1\n",
    "LAPTM5\n",
    "LCP1\n",
    "LEPROTL1\n",
    "LINC00513\n",
    "LINC01237\n",
    "MAN1A1\n",
    "MAPRE2\n",
    "MPHOSPH9\n",
    "MPP7\n",
    "MVB12B\n",
    "MYO5A\n",
    "NIN\n",
    "PARP11\n",
    "PARP15\n",
    "PCED1B-AS1\n",
    "PDE3B\n",
    "PIP4K2A\n",
    "PLCL1\n",
    "PLEKHA2\n",
    "PPP3CC\n",
    "PRKCH\n",
    "PRKCQ\n",
    "PRKD3\n",
    "PRKX\n",
    "PTPN22\n",
    "RAC2\n",
    "RASGRF2\n",
    "RFX3\n",
    "RIPOR2\n",
    "RNF166\n",
    "S1PR4\n",
    "SAMD3\n",
    "SENP7\n",
    "SH2B3\n",
    "SH2D2A\n",
    "SMARCA2\n",
    "SNHG26\n",
    "SPOCK2\n",
    "SRGN\n",
    "ST8SIA1\n",
    "STAT5A\n",
    "STAT5B\n",
    "STIM1\n",
    "STK17A\n",
    "TMEM200A\n",
    "TMX4\n",
    "TRBC2\n",
    "TRDC\n",
    "TRIM22\n",
    "TTN\n",
    "VAV3\n",
    "WNT5A-AS1\n",
    "ZNF101\n",
    "ZNF471\n",
    "\"\"\"\n",
    "DOWN_TEXT = \"\"\"RBP7\n",
    "OVCA2\n",
    "PLAC4\n",
    "AC026785.3\n",
    "LINC02212\n",
    "LINC00605\n",
    "AC246817.2\n",
    "FOXCUT\n",
    "VGLL2\n",
    "ZIC4\n",
    "FOLR3\n",
    "ECEL1\n",
    "AC024337.1\n",
    "C5orf58\n",
    "AC060814.3\n",
    "B4GALNT1\n",
    "UCHL1\n",
    "VAX1\n",
    "AL451042.1\n",
    "COMMD8\n",
    "IFI30\n",
    "AL096794.1\n",
    "RGS10\n",
    "\"\"\"\n",
    "UP = parse_genes(UP_TEXT); DN = parse_genes(DOWN_TEXT)\n",
    "print(f\"[IL2] UP={len(UP)}  DOWN={len(DN)}\")\n",
    "\n",
    "# ================== Robust loader for Puleo ==================\n",
    "def load_puleo_expr(expr_path: Path, meta_path: Path) -> pd.DataFrame:\n",
    "    # Read as strings first to avoid dtype traps, then coerce\n",
    "    expr_raw = pd.read_csv(expr_path, index_col=0, dtype=str, low_memory=False)\n",
    "    # Drop obvious non-gene rows: empty index or index that equals the header label like \"ID_REF\"\n",
    "    bad_idx = expr_raw.index.isna() | (expr_raw.index.astype(str).str.upper().isin([\"\", \"ID_REF\", \"FEATURE\", \"PROBE\", \"NA\"]))\n",
    "    if bad_idx.any():\n",
    "        expr_raw = expr_raw.loc[~bad_idx]\n",
    "\n",
    "    # Coerce to numeric; non-numeric becomes NaN\n",
    "    expr_num = expr_raw.apply(pd.to_numeric, errors=\"coerce\")\n",
    "\n",
    "    # Drop columns that are entirely NaN (e.g., if some header row slipped in)\n",
    "    before_cols = expr_num.shape[1]\n",
    "    expr_num = expr_num.loc[:, expr_num.notna().any(axis=0)]\n",
    "    after_cols = expr_num.shape[1]\n",
    "\n",
    "    # Uppercase gene symbols and collapse duplicates\n",
    "    expr_num.index = expr_num.index.astype(str).str.upper()\n",
    "    expr_num = expr_num.groupby(expr_num.index, sort=False).mean(numeric_only=True)\n",
    "\n",
    "    # Align to meta geo_accession if present (keeps ordering and filters to valid samples)\n",
    "    try:\n",
    "        meta = pd.read_csv(meta_path, dtype=str)\n",
    "        if \"geo_accession\" in meta.columns:\n",
    "            gacc = meta[\"geo_accession\"].astype(str)\n",
    "            keep = gacc[gacc.isin(expr_num.columns)]\n",
    "            if len(keep):\n",
    "                expr_num = expr_num.loc[:, keep]\n",
    "    except Exception as e:\n",
    "        print(\"[META] warning, could not refine by meta:\", e)\n",
    "\n",
    "    # Final clean: drop rows/cols all-NaN\n",
    "    expr_num = expr_num.dropna(how=\"all\", axis=0).dropna(how=\"all\", axis=1)\n",
    "    return expr_num\n",
    "\n",
    "expr = load_puleo_expr(PULEO_EXPR, PULEO_META)\n",
    "print(f\"[PULEO] expr numeric shape: {expr.shape}\")\n",
    "print(f\"[PULEO] example cols: {list(expr.columns[:5])}\")\n",
    "\n",
    "if expr.shape[1] == 0:\n",
    "    raise RuntimeError(\"Expression matrix has 0 usable columns after numeric coercion. \"\n",
    "                       \"Open the CSV and confirm the GSM columns are numeric (no stray header rows).\")\n",
    "\n",
    "# ================== Score function ==================\n",
    "def z_per_gene(df: pd.DataFrame):\n",
    "    # z across samples per gene\n",
    "    return df.apply(lambda x: (x - x.mean()) / (x.std(ddof=0) + 1e-9), axis=1)\n",
    "\n",
    "def score_signed(df: pd.DataFrame, up, dn, min_genes=10):\n",
    "    Z = z_per_gene(df)\n",
    "    up_i = pd.Index(up).intersection(Z.index)\n",
    "    dn_i = pd.Index(dn).intersection(Z.index)\n",
    "    cov = {\"up_used\": int(up_i.size), \"up_total\": len(up),\n",
    "           \"down_used\": int(dn_i.size), \"down_total\": len(dn)}\n",
    "    if up_i.size < min_genes or dn_i.size < min_genes:\n",
    "        return pd.Series(np.nan, index=Z.columns, name=\"IL2_score\"), cov\n",
    "    s = (Z.loc[up_i].mean(axis=0) - Z.loc[dn_i].mean(axis=0)).rename(\"IL2_score\")\n",
    "    return s, cov\n",
    "\n",
    "scores, cov = score_signed(expr, UP, DN, min_genes=10)\n",
    "print(f\"[COVERAGE] UP {cov['up_used']}/{cov['up_total']} | DOWN {cov['down_used']}/{cov['down_total']}\")\n",
    "print(f\"[SCORES] non-NA: {scores.notna().sum()} of {scores.shape[0]} samples\")\n",
    "\n",
    "# If everything became NaN, show quick gene overlap debug and bail\n",
    "if scores.notna().sum() == 0:\n",
    "    up_overlap = pd.Index(UP).intersection(expr.index)\n",
    "    dn_overlap = pd.Index(DN).intersection(expr.index)\n",
    "    print(\"[DEBUG] UP overlap:\", len(up_overlap), \"example:\", list(up_overlap[:10]))\n",
    "    print(\"[DEBUG] DN overlap:\", len(dn_overlap), \"example:\", list(dn_overlap[:10]))\n",
    "    raise RuntimeError(\"All scores are NaN; likely too few genes overlapped or expression still non-numeric.\")\n",
    "\n",
    "# ================== Save outputs ==================\n",
    "def zscore_series(s: pd.Series):\n",
    "    mu, sd = s.mean(), s.std(ddof=0)\n",
    "    return (s - mu) / (sd if (sd is not None and sd != 0 and not np.isnan(sd)) else 1.0)\n",
    "\n",
    "raw_path = OUTDIR / \"Puleo_IL2_scores.csv\"\n",
    "z_path   = OUTDIR / \"Puleo_IL2_scores_Z.csv\"\n",
    "q_path   = OUTDIR / \"Puleo_IL2_scores_with_quartiles.csv\"\n",
    "png_path = OUTDIR / \"Puleo_IL2_scores_hist.png\"\n",
    "\n",
    "scores.to_csv(raw_path)\n",
    "\n",
    "scores_z = zscore_series(scores).rename(\"IL2_score_Z\")\n",
    "scores_z.to_csv(z_path)\n",
    "\n",
    "q25, q75 = scores.quantile(0.25), scores.quantile(0.75)\n",
    "labels = pd.Series(np.where(scores >= q75, \"Top25%\",\n",
    "                     np.where(scores <= q25, \"Bottom25%\", \"Middle\")),\n",
    "                   index=scores.index, name=\"quartile\")\n",
    "out_tbl = pd.concat([scores, scores_z, labels], axis=1)\n",
    "out_tbl.to_csv(q_path)\n",
    "\n",
    "plt.figure(figsize=(6,4))\n",
    "plt.hist(scores.dropna().values, bins=30)\n",
    "plt.title(\"Puleo IL2 signed score\")\n",
    "plt.xlabel(\"IL2 score\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(png_path, dpi=160)\n",
    "plt.close()\n",
    "\n",
    "print(f\"[SAVE] {raw_path}\")\n",
    "print(f\"[SAVE] {z_path}\")\n",
    "print(f\"[SAVE] {q_path}\")\n",
    "print(f\"[SAVE] {png_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "da4bfea7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TCGA] Loading expression from: PAAD_RSEM_genes_normalized_CLEAN.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/mh/r2nrb73509z0t_wjbx9r5fg00000gn/T/ipykernel_92012/1272072538.py:66: FutureWarning: DataFrame.groupby with axis=1 is deprecated. Do `frame.T.groupby(...)` without axis instead.\n",
      "  df = df.groupby(df.columns, axis=1).mean(numeric_only=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TCGA] patient-level shape (genes x patients): (20502, 178)\n",
      "IGE scores loaded. Shape: (178,) NA: 0\n"
     ]
    }
   ],
   "source": [
    "# --- Recreate IGE scores (drop-in) ---\n",
    "\n",
    "# Load expression again (if not in memory)\n",
    "expr = load_tcga_expr(expr_paths)\n",
    "\n",
    "# Gene lists (same ones from your IL2/IGE scripts)\n",
    "IGE_UP = [\n",
    "\"PFN2\",\"SET\",\"LGALS1\",\"PDLIM4\",\"EIF5A\",\"F8A1\",\"BANF1\",\"CTDNEP1\",\"TRAPPC1\",\"AMZ2\",\"PTGES3\",\"ST13\",\"FTH1\",\"PCBP1\",\n",
    "\"NAA10\",\"ARPC5L\",\"ETFB\",\"CCDC124\",\"SSR2\",\"PGLS\",\"SELENOH\",\"GSTP1\",\"NDUFB7\",\"AURKAIP1\",\"GCHFR\",\"MYL6\",\"AP2S1\",\n",
    "\"S100A13\",\"C9orf16\",\"KRT8\",\"PRKCSH\",\"CST3\",\"PET100\",\"DNAJA2\",\"VPS35\",\"VDAC1\",\"MGST3\",\"PRR13\",\"OCIAD2\",\"FUOM\",\"MIA\",\n",
    "\"RPN1\",\"FUCA2\",\"TMED4\",\"ERGIC3\",\"DDOST\",\"NAXE\",\"SNRPD1\",\"SKP1\",\"CNBP\",\"ATP5MC3\",\"SLC25A5\",\"LSM4\",\"NDUFAB1\",\"PCBD1\",\n",
    "\"HINT1\",\"ADI1\",\"NENF\",\"MRPL43\",\"VKORC1\",\"EMC4\",\"COA3\",\"NEDD8\",\"CHCHD2\",\"PRDX5\",\"WDR83OS\",\"NDUFA4\",\"GABARAP\",\"PHPT1\",\n",
    "\"UFC1\",\"MDH1\",\"ATP5F1E\",\"MRPL41\",\"UBL5\",\"COX5B\",\"ELOB\",\"ATP5ME\",\"UQCRB\",\"SEM1\",\"NDUFB1\",\"COX6C\",\"ATP6V1F\",\"HNRNPA1\",\n",
    "\"HIGD2A\",\"POLR2I\",\"METTL26\",\"NDUFB4\",\"OST4\",\"C19orf53\",\"RPL36AL\",\"PPIA\",\"COPS9\",\"COX8A\",\"COX5A\",\"RPL36\",\"RPS15\",\n",
    "\"RPS27\",\"RPS11\",\"FTL\",\"SNHG29\",\"NACA\",\"RPS17\",\"RPL23\",\"RPL39\",\"RPS21\",\"RPL9\",\"RPL15\",\"RPL34\",\"RPL27A\",\"RPL36A\",\n",
    "\"RPL38\",\"RPS26\",\"RPS14\",\"RPL35\",\"RPL37A\",\"RPL37\",\"RPL12\",\"RPS29\"\n",
    "]\n",
    "\n",
    "IGE_DOWN = [\"STN1\",\"NRG4\",\"IQSEC2\",\"IYD\",\"CHD9\",\"APBB1IP\",\"TMEM238\",\"REX1BD\",\"IFI27\",\"CYBA\",\"METRNL\",\"AKR7A2\",\n",
    "            \"SULT1A1\",\"ARHGEF35\",\"AC008397.1\",\"KLK11\",\"DELE1\",\"MISP\",\"FAM234A\",\"CMBL\"]\n",
    "\n",
    "# Recompute signed IGE scores\n",
    "ige_scores, ige_cov = score_signed(expr, IGE_UP, IGE_DOWN, min_genes=10, name=\"IGE\")\n",
    "print(\"IGE scores loaded. Shape:\", ige_scores.shape, \"NA:\", ige_scores.isna().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "f2152d14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[COMBO ANALYSIS] N with all 4 modules + OS: 177\n",
      "\n",
      "[COX MULTIVARIABLE RESULTS]\n",
      "               beta        HR         p\n",
      "covariate                              \n",
      "SAT_Z      0.132908  1.142144  0.339553\n",
      "MPC_Z      0.005679  1.005695  0.975132\n",
      "IL2_Z      0.069517  1.071991  0.691925\n",
      "IGE_Z     -0.076826  0.926051  0.592142\n",
      "\n",
      "[COX] Saved combined risk score to: /Users/scottpowers/Desktop/TCGA_PADD_module_cox_combined_score.csv\n"
     ]
    }
   ],
   "source": [
    "# --- Contribution of each module to survival (multivariable Cox) ---\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from lifelines import CoxPHFitter\n",
    "\n",
    "# 1) Merge modules + clinical on patientId\n",
    "df_mod = pd.concat(\n",
    "    [\n",
    "        sat_scores.rename(\"SAT\"),\n",
    "        mpc_scores.rename(\"MPC\"),\n",
    "        il2_scores.rename(\"IL2\"),\n",
    "        ige_scores.rename(\"IGE\"),\n",
    "        clin[[\"OS_time_months\", \"OS_event\"]],\n",
    "    ],\n",
    "    axis=1,\n",
    "    join=\"inner\",\n",
    ")\n",
    "\n",
    "# Keep only rows with all four modules and OS info\n",
    "df_mod = df_mod.dropna(subset=[\"SAT\", \"MPC\", \"IL2\", \"IGE\", \"OS_time_months\", \"OS_event\"])\n",
    "print(\"[COMBO ANALYSIS] N with all 4 modules + OS:\", df_mod.shape[0])\n",
    "\n",
    "# 2) Z-score each module so coefficients are comparable\n",
    "for col in [\"SAT\", \"MPC\", \"IL2\", \"IGE\"]:\n",
    "    mu = df_mod[col].mean()\n",
    "    sd = df_mod[col].std(ddof=0)\n",
    "    if sd == 0 or np.isnan(sd):\n",
    "        df_mod[col + \"_Z\"] = 0.0\n",
    "    else:\n",
    "        df_mod[col + \"_Z\"] = (df_mod[col] - mu) / sd\n",
    "\n",
    "# 3) Fit multivariable Cox model with all four z-scored modules\n",
    "cph = CoxPHFitter()\n",
    "cph.fit(\n",
    "    df_mod[[\"OS_time_months\", \"OS_event\", \"SAT_Z\", \"MPC_Z\", \"IL2_Z\", \"IGE_Z\"]],\n",
    "    duration_col=\"OS_time_months\",\n",
    "    event_col=\"OS_event\",\n",
    ")\n",
    "\n",
    "print(\"\\n[COX MULTIVARIABLE RESULTS]\")\n",
    "print(\n",
    "    cph.summary[[\"coef\", \"exp(coef)\", \"p\"]]\n",
    "    .rename(columns={\"coef\": \"beta\", \"exp(coef)\": \"HR\"})\n",
    ")\n",
    "\n",
    "# Interpretation:\n",
    "# - beta > 0 (HR > 1): higher module score = worse survival (risk module)\n",
    "# - beta < 0 (HR < 1): higher module score = better survival (protective module)\n",
    "# Magnitude of |beta| tells you relative contribution per 1 SD change.\n",
    "\n",
    "# 4) Cox-based combined risk score (linear predictor / partial hazard)\n",
    "df_mod[\"COX_COMBINED\"] = cph.predict_partial_hazard(df_mod)\n",
    "\n",
    "out_path = Path.home() / \"Desktop\" / \"TCGA_PADD_module_cox_combined_score.csv\"\n",
    "df_mod[[\"COX_COMBINED\"]].to_csv(out_path)\n",
    "print(f\"\\n[COX] Saved combined risk score to: {out_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "a3e6ef46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   SAT     IGE_Z  OS_time_months  OS_event\n",
      "patientId                                                 \n",
      "TCGA-2J-AAB1 -0.255525 -0.805599        2.169839       1.0\n",
      "TCGA-2J-AAB4 -0.426443 -0.348372       23.966861       0.0\n",
      "TCGA-2J-AAB6  0.072369  0.958580        9.632771       1.0\n",
      "TCGA-2J-AAB8  0.104286  0.065783        2.630108       0.0\n",
      "TCGA-2J-AAB9  0.155583  0.255268       20.613473       1.0\n"
     ]
    }
   ],
   "source": [
    "# 1) Recompute z-scored IGE for all patients\n",
    "ige_raw = df_ige[\"IGE\"]                    # raw IGE module scores\n",
    "ige_z_all = zscore_series(ige_raw)        # z-score across patients\n",
    "\n",
    "# 2) Align to the DataFrame you're using for KM (your current `df`)\n",
    "#    df currently has index = patientId and columns: ['SAT', 'OS_time_months', 'OS_event']\n",
    "ige_z_aligned = ige_z_all.loc[df.index]\n",
    "\n",
    "# 3) Add it as a new column\n",
    "df[\"IGE_Z\"] = ige_z_aligned\n",
    "print(df[[\"SAT\", \"IGE_Z\", \"OS_time_months\", \"OS_event\"]].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "5d558a1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N rows after merge + dropna: 177\n",
      "[IGE optimal] cut = 0.918, logrank p = 0.0721\n",
      "Saved → TCGA_IGE_KM_optimal.png\n"
     ]
    }
   ],
   "source": [
    "from lifelines import KaplanMeierFitter\n",
    "from lifelines.statistics import logrank_test\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ---------------------------------------------------\n",
    "# 1) Build a clean survival DF for IGE\n",
    "#     (uses existing objects: ige_scores, OS_time, OS_event)\n",
    "# ---------------------------------------------------\n",
    "df_ige_opt = (\n",
    "    pd.concat(\n",
    "        [\n",
    "            ige_scores.rename(\"IGE\"),\n",
    "            OS_time.rename(\"OS_time_months\"),\n",
    "            OS_event.rename(\"OS_event\"),\n",
    "        ],\n",
    "        axis=1,\n",
    "        join=\"inner\",\n",
    "    )\n",
    "    .dropna()\n",
    ")\n",
    "\n",
    "print(f\"N rows after merge + dropna: {len(df_ige_opt)}\")\n",
    "\n",
    "# ---------------------------------------------------\n",
    "# 2) Recompute IGE Z-score\n",
    "# ---------------------------------------------------\n",
    "mu = df_ige_opt[\"IGE\"].mean()\n",
    "sd = df_ige_opt[\"IGE\"].std(ddof=0)\n",
    "df_ige_opt[\"IGE_Z\"] = (df_ige_opt[\"IGE\"] - mu) / sd\n",
    "\n",
    "# Standardize column names for downstream code\n",
    "df = df_ige_opt.rename(columns={\n",
    "    \"OS_time_months\": \"os_months\",\n",
    "    \"OS_event\": \"os_event\"\n",
    "})\n",
    "\n",
    "# ---------------------------------------------------\n",
    "# 3) Scan for optimal IGE_Z cutoff (log-rank)\n",
    "# ---------------------------------------------------\n",
    "vals   = df[\"IGE_Z\"].values\n",
    "times  = df[\"os_months\"].values\n",
    "events = df[\"os_event\"].values\n",
    "\n",
    "# Candidate cutpoints between 10th and 90th percentile\n",
    "cand = np.linspace(\n",
    "    np.quantile(vals, 0.10),\n",
    "    np.quantile(vals, 0.90),\n",
    "    50\n",
    ")\n",
    "\n",
    "best_cut, best_p = None, 1.0\n",
    "for c in cand:\n",
    "    hi = vals >= c\n",
    "    lo = ~hi\n",
    "    # require reasonable group sizes\n",
    "    if hi.sum() < 10 or lo.sum() < 10:\n",
    "        continue\n",
    "\n",
    "    res = logrank_test(\n",
    "        times[hi], times[lo],\n",
    "        event_observed_A=events[hi],\n",
    "        event_observed_B=events[lo]\n",
    "    )\n",
    "    p = res.p_value\n",
    "    if p < best_p:\n",
    "        best_p, best_cut = p, c\n",
    "\n",
    "print(f\"[IGE optimal] cut = {best_cut:.3f}, logrank p = {best_p:.3g}\")\n",
    "\n",
    "# ---------------------------------------------------\n",
    "# 4) KM plot using the optimal cutoff\n",
    "# ---------------------------------------------------\n",
    "df[\"IGE_high\"] = (df[\"IGE_Z\"] >= best_cut).astype(int)\n",
    "\n",
    "km_hi = KaplanMeierFitter()\n",
    "km_lo = KaplanMeierFitter()\n",
    "\n",
    "mask_hi = df[\"IGE_high\"] == 1\n",
    "mask_lo = ~mask_hi\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(5,5))\n",
    "\n",
    "km_hi.fit(df.loc[mask_hi, \"os_months\"],\n",
    "          df.loc[mask_hi, \"os_event\"],\n",
    "          label=\"High IGE (z ≥ cut)\")\n",
    "km_lo.fit(df.loc[mask_lo, \"os_months\"],\n",
    "          df.loc[mask_lo, \"os_event\"],\n",
    "          label=\"Low IGE (z < cut)\")\n",
    "\n",
    "km_hi.plot(ax=ax, ci_show=False)\n",
    "km_lo.plot(ax=ax, ci_show=False)\n",
    "\n",
    "ax.set_xlabel(\"Overall survival (months)\")\n",
    "ax.set_ylabel(\"Survival probability\")\n",
    "ax.set_title(\n",
    "    f\"TCGA-PAAD: IGE module (optimal z-score split)\\n\"\n",
    "    f\"cut = {best_cut:.2f}, logrank p = {best_p:.3g}\"\n",
    ")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"TCGA_IGE_KM_optimal.png\", dpi=300)\n",
    "plt.close()\n",
    "\n",
    "print(\"Saved → TCGA_IGE_KM_optimal.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2949c5c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "ac1177a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable                      Type                       Data/Info\n",
      "------------------------------------------------------------------\n",
      "A                             DataFrame                               ccle_name  1<...>n[33 rows x 1449 columns]\n",
      "ABS_R                         float                      0.2\n",
      "ABS_R_MIN                     float                      0.05\n",
      "ANNO                          PosixPath                  /Users/scottpowers/Desktop/GPL13667-15572.txt\n",
      "ASSAYS                        set                        {'A2299_077', 'H08G2028_A<...>268155_H03', 'A2299_011'}\n",
      "BASE                          PosixPath                  /Users/scottpowers/Librar<...>u/My Drive/Imputed Folder\n",
      "C                             DataFrame                  module       SAT       IG<...>49642  0.767857       NaN\n",
      "CBAR_LABEL                    str                        Correlation\n",
      "CHRON                         DataFrame                      Unnamed: 0      A1BG <...>[45 rows x 17917 columns]\n",
      "CLEAN_PATH                    PosixPath                  /Users/scottpowers/Deskto<...>enes_normalized_CLEAN.csv\n",
      "COMPASS_EXPR                  PosixPath                  /path/to/clin/COMPASS_expr.csv\n",
      "COMPASS_META                  PosixPath                  /path/to/clin/COMPASS_meta.csv\n",
      "CSV_IN                        str                        all_dependencies.csv\n",
      "CSV_PATH                      str                        all_dependencies.csv\n",
      "C_ord                         ndarray                    4x4: 16 elems, type `float64`, 128 bytes\n",
      "CoxPHFitter                   type                       <class 'lifelines.fitters<...>oxph_fitter.CoxPHFitter'>\n",
      "DEP_CHRON                     PosixPath                  /Users/scottpowers/Librar<...>DAC_gene_dependencies.csv\n",
      "DEP_EXP                       PosixPath                  /Users/scottpowers/Librar<...>_celllines_expression.csv\n",
      "DEP_PRISM                     DataFrame                  ccle_name                <...>n[1449 rows x 33 columns]\n",
      "DEP_PRISM_PATH                PosixPath                  out_modules_notebook/PRIS<...>AC_drugs_by_celllines.csv\n",
      "DESKTOP                       PosixPath                  /Users/scottpowers/Desktop\n",
      "DN                            ndarray                    23: 23 elems, type `object`, 184 bytes\n",
      "DOWN_TEXT                     str                        RBP7\\nOVCA2\\nPLAC4\\nAC026<...>FI30\\nAL096794.1\\nRGS10\\n\n",
      "D_condensed                   ndarray                    6: 6 elems, type `float64`, 48 bytes\n",
      "Dict                          _SpecialGenericAlias       typing.Dict\n",
      "EXCLUDE_GENES                 set                        {'KIF4B', 'OR1Q1', 'LHFPL1', 'C16orf89', 'ASPM'}\n",
      "EXP                           DataFrame                      Unnamed: 0     NEMP2 <...>[51 rows x 19099 columns]\n",
      "EXPR                          PosixPath                  /Users/scottpowers/Deskto<...>-MTAB-6134_expression.csv\n",
      "FDR_MAX                       float                      0.9\n",
      "G                             Graph                      Graph with 4 nodes and 0 edges\n",
      "GENES_BY_MODULE               dict                       n=4\n",
      "GridSpec                      type                       <class 'matplotlib.gridspec.GridSpec'>\n",
      "HIT_METHOD                    str                        fdr\n",
      "IGE_DOWN                      list                       n=20\n",
      "IGE_UP                        list                       n=118\n",
      "IL2_DOWN                      list                       n=23\n",
      "IL2_UP                        list                       n=106\n",
      "IL2_Z                         Series                     patientId\\nTCGA-2J-AAB1  <...>ngth: 178, dtype: float64\n",
      "IN                            str                        dependency_hits.csv\n",
      "J                             ndarray                    4x4: 16 elems, type `float64`, 128 bytes\n",
      "J_plot                        ndarray                    4x4: 16 elems, type `float64`, 128 bytes\n",
      "KEEP_NEG                      bool                       True\n",
      "KaplanMeierFitter             type                       <class 'lifelines.fitters<...>itter.KaplanMeierFitter'>\n",
      "List                          _SpecialGenericAlias       typing.List\n",
      "M                             ndarray                    16x4: 64 elems, type `float64`, 512 bytes\n",
      "MATRIX_URL                    str                        https://ftp.ncbi.nlm.nih.<...>1729_series_matrix.txt.gz\n",
      "MODULES                       list                       n=4\n",
      "MODULE_COLORS                 dict                       n=4\n",
      "MPC_DOWN                      list                       n=14\n",
      "MPC_UP                        list                       n=304\n",
      "MPC_Z                         Series                     patientId\\nTCGA-2J-AAB1  <...>ngth: 178, dtype: float64\n",
      "MaxNLocator                   type                       <class 'matplotlib.ticker.MaxNLocator'>\n",
      "N                             int                        357\n",
      "Nint                          ndarray                    4x4: 16 elems, type `int64`, 128 bytes\n",
      "OS_event                      Series                     patientId\\nTCGA-3A-A9IN  <...>ngth: 184, dtype: float64\n",
      "OS_time                       Series                     patientId\\nTCGA-3A-A9IN  <...>ngth: 184, dtype: float64\n",
      "OUT                           PosixPath                  /Users/scottpowers/Deskto<...>al_out/IGE_opt/KM_IGE.png\n",
      "OUTDIR                        PosixPath                  /Users/scottpowers/Deskto<...>dule_survival_out/SAT_opt\n",
      "OUTDIR_COMBO4                 PosixPath                  /Users/scottpowers/Deskto<...>p/tcga_paad_COMBO4_KM_out\n",
      "OUT_BASENAME                  str                        Fig6A_StrongDeps_vertical\n",
      "OUT_PNG                       str                        Fig6A_StrongDependencies.png\n",
      "PANC_RE                       Pattern                    re.compile('^PANC\\\\d+$', re.IGNORECASE)\n",
      "PATH                          str                        shared_dependencies.csv\n",
      "PRISM_LONG                    PosixPath                  /Users/scottpowers/Deskto<...>p/PRISM_AUC_PDAC_long.csv\n",
      "PRISM_MATRIX                  PosixPath                  /Users/scottpowers/Deskto<...>PRISM_AUC_PDAC_matrix.csv\n",
      "PRISM_PARAMS                  PosixPath                  /Users/scottpowers/Deskto<...>onse-curve-parameters.csv\n",
      "PULEO_EXPR                    PosixPath                  /Users/scottpowers/Desktop/Puleo_expr.csv\n",
      "PULEO_META                    PosixPath                  /path/to/clin/Puleo_meta.csv\n",
      "Path                          type                       <class 'pathlib.Path'>\n",
      "Q                             ndarray                    4x4: 16 elems, type `float64`, 128 bytes\n",
      "Q_MAX                         float                      0.1\n",
      "RAW                           PosixPath                  /Users/scottpowers/Deskto<...>d/ProcessedExpression.tsv\n",
      "S                             dict                       n=4\n",
      "SAT_DOWN                      list                       n=25\n",
      "SAT_UP                        list                       n=185\n",
      "SAT_Z                         Series                     patientId\\nTCGA-2J-AAB1  <...>ngth: 178, dtype: float64\n",
      "SDRF                          PosixPath                  /Users/scottpowers/Desktop/E-MTAB-6134.sdrf.txt\n",
      "SDRF_URL                      str                        https://www.ebi.ac.uk/arr<...>6134/E-MTAB-6134.sdrf.txt\n",
      "SURV                          PosixPath                  /Users/scottpowers/Deskto<...>eo_survival_from_SDRF.csv\n",
      "TCGA_EXPR                     PosixPath                  /Users/scottpowers/Deskto<...>enes_normalized_CLEAN.csv\n",
      "TCGA_META                     PosixPath                  /Users/scottpowers/Desktop/PAAD.clin.merged.txt\n",
      "TITLE                         str                        Strong Dependency Signatures by Module\n",
      "TOP_INTERSECTIONS             int                        15\n",
      "TOP_N                         int                        100\n",
      "TOP_N_PER_MODULE              int                        4\n",
      "Tuple                         _TupleType                 typing.Tuple\n",
      "TwoSlopeNorm                  type                       <class 'matplotlib.colors.TwoSlopeNorm'>\n",
      "UNZ                           PosixPath                  /Users/scottpowers/Deskto<...>B-6134_processed/unzipped\n",
      "UP                            ndarray                    106: 106 elems, type `object`, 848 bytes\n",
      "UP_TEXT                       str                        ABHD15-AS1\\nAC007780.1\\nA<...>T5A-AS1\\nZNF101\\nZNF471\\n\n",
      "Z                             ndarray                    3x4: 12 elems, type `float64`, 96 bytes\n",
      "a                             str                        IGE\n",
      "active                        list                       n=4\n",
      "active_rows                   list                       n=4\n",
      "ad_med                        float64                    -0.12832894411020326\n",
      "add_cand                      function                   <function add_cand at 0x2c5782980>\n",
      "ai                            ndarray                    322: 322 elems, type `int64`, 2576 bytes\n",
      "aj                            ndarray                    322: 322 elems, type `int64`, 2576 bytes\n",
      "all_genes                     list                       n=322\n",
      "all_text                      DataFrame                      Source Name Character<...>\\n[309 rows x 51 columns]\n",
      "anno                          DataFrame                                      ID   <...>[49386 rows x 43 columns]\n",
      "annot                         DataFrame                                           <...>\\n[1448 rows x 2 columns]\n",
      "arrays                        dict                       n=0\n",
      "assay                         str                        G028985_D09\n",
      "assay_col                     str                        Assay Name\n",
      "ax                            Axes                       Axes(0.158734,0.172445;0.80198x0.664888)\n",
      "ax1                           Axes                       Axes(0.0715278,0.169682;0.323256x0.53876)\n",
      "ax2                           Axes                       Axes(0.568481,0.169682;0.323256x0.53876)\n",
      "ax_band                       Axes                       Axes(0.125,0.11;0.0963575x0.77)\n",
      "ax_bar                        Axes                       Axes(0.0778472,0.738193;0.678964x0.187826)\n",
      "ax_cb                         Axes                       Axes(0.835762,0.11;0.0642383x0.77)\n",
      "ax_dleft                      Axes                       Axes(0.020625,0.03125;0.18711x0.707318)\n",
      "ax_dots                       Axes                       Axes(0.0778472,0.241859;0.678964x0.0676172)\n",
      "ax_dtop                       Axes                       Axes(0.279263,0.76718;0.623699x0.212195)\n",
      "ax_hm                         Axes                       Axes(0.282313,0.11;0.492494x0.77)\n",
      "ax_set                        Axes                       Axes(0.828339,0.241859;0.136583x0.68416)\n",
      "axes                          ndarray                    2: 2 elems, type `object`, 16 bytes\n",
      "b                             str                        SAT\n",
      "basename                      function                   <function basename at 0x2c5783240>\n",
      "begin_idx                     int                        68\n",
      "best_cut                      float                      0.19400999499702265\n",
      "best_p                        float                      0.38711776921505847\n",
      "buf                           StringIO                   <_io.StringIO object at 0x28dbed510>\n",
      "c                             str                        OS_event\n",
      "c_norms                       set                        {'panc99'}\n",
      "cand_to_assay                 dict                       n=620\n",
      "candidates                    Series                     patientId\\nTCGA-S4-A8RP  <...>ngth: 106, dtype: float64\n",
      "cax                           Axes                       Axes(0.86,0.17;0.03x0.67)\n",
      "cbar                          Colorbar                   <matplotlib.colorbar.Colo<...>ar object at 0x2867bf490>\n",
      "cbar1                         Colorbar                   <matplotlib.colorbar.Colo<...>ar object at 0x3425325d0>\n",
      "cbar2                         Colorbar                   <matplotlib.colorbar.Colo<...>ar object at 0x29fa42950>\n",
      "char_arrays                   list                       n=0\n",
      "ci                            DataFrame                             Low IGE_lower_<...>\\n\\n[87 rows x 2 columns]\n",
      "clin                          DataFrame                                OS_time_mon<...>n\\n[184 rows x 2 columns]\n",
      "clin_cbio                     DataFrame                                           <...>\\n[184 rows x 60 columns]\n",
      "clin_like_regex               Pattern                    re.compile('(characterist<...>months?)', re.IGNORECASE)\n",
      "clin_path                     PosixPath                  /Users/scottpowers/Deskto<...>as_2018_clinical_data.csv\n",
      "cm                            module                     <module 'matplotlib.cm' f<...>ckages/matplotlib/cm.py'>\n",
      "cmap                          LinearSegmentedColormap    <matplotlib.colors.Linear<...>ap object at 0x29f64c490>\n",
      "cmap1                         ListedColormap             <matplotlib.colors.Listed<...>ap object at 0x2a80b8dd0>\n",
      "cmap2                         ListedColormap             <matplotlib.colors.Listed<...>ap object at 0x28568a990>\n",
      "cohorts                       list                       n=2\n",
      "col                           str                        IGE\n",
      "col_i                         int                        14\n",
      "collect_panc_in_df            function                   <function collect_panc_in_df at 0x2c5783f60>\n",
      "color                         str                        #fb6a4a\n",
      "cols                          list                       n=4\n",
      "cols_to_keep                  list                       n=3\n",
      "combinations                  type                       <class 'itertools.combinations'>\n",
      "combo                         Series                     patientId\\nTCGA-2J-AAB1  <...>ngth: 178, dtype: float64\n",
      "common                        Index                      Index(['A11_C05', 'A12_D0<...>='sample_id', length=287)\n",
      "core                          list                       n=3\n",
      "corr                          DataFrame                  module       SAT       IG<...>49642  0.767857  1.000000\n",
      "counts                        DataFrame                  module   IGE  SAT  IL2  M<...>\\n[1805 rows x 5 columns]\n",
      "cov                           dict                       n=4\n",
      "cph                           CoxPHFitter                <lifelines.CoxPHFitter: f<...>ht-censored observations>\n",
      "crit                          Series                     0        False\\n1        <...>ength: 71664, dtype: bool\n",
      "csv_path                      PosixPath                  out_tcga_ige_survival/TCG<...>A_IGE_scores_OS_group.csv\n",
      "curves                        dict                       n=2\n",
      "cut                           float                      0.14439319910447584\n",
      "den                           int                        49386\n",
      "dendrogram                    function                   <function dendrogram at 0x154304400>\n",
      "derive_tcga_survival_auto     function                   <function derive_tcga_sur<...>ival_auto at 0x2a5a1b560>\n",
      "df                            DataFrame                                     SAT  O<...>n\\n[177 rows x 3 columns]\n",
      "df_check                      DataFrame                                     SAT   <...>n\\n[177 rows x 5 columns]\n",
      "df_combo                      DataFrame                                COMBO_SCORE<...>n\\n[177 rows x 4 columns]\n",
      "df_ige                        DataFrame                                     IGE  O<...>n\\n[177 rows x 4 columns]\n",
      "df_il2                        DataFrame                                     IL2  O<...>n\\n[177 rows x 4 columns]\n",
      "df_mod                        DataFrame                                     SAT   <...>\\n[177 rows x 11 columns]\n",
      "df_mpc                        DataFrame                                     MPC  O<...>n\\n[177 rows x 4 columns]\n",
      "df_out                        DataFrame                                     IL2  O<...>n\\n[177 rows x 4 columns]\n",
      "df_sat                        DataFrame                                     SAT  O<...>n\\n[177 rows x 4 columns]\n",
      "df_sym                        DataFrame                                           <...>51163 rows x 310 columns]\n",
      "df_tcga                       DataFrame                                    TCGA-2J<...>20532 rows x 183 columns]\n",
      "display_rows                  list                       n=16\n",
      "dleft                         dict                       n=6\n",
      "down_cov                      int                        0\n",
      "dst                           PosixPath                  /Users/scottpowers/Deskto<...>d/ProcessedExpression.tsv\n",
      "dtop                          dict                       n=6\n",
      "end_idx                       int                        19819\n",
      "ev                            Series                     A11_C05           0\\nA12_<...>Length: 288, dtype: int64\n",
      "event_col                     str                        Characteristics[os.event]\n",
      "event_vals                    Series                     0      1.0\\n1      1.0\\n2<...>ngth: 309, dtype: float64\n",
      "exclusive_intersections       function                   <function exclusive_intersections at 0x382a6bec0>\n",
      "expr                          DataFrame                  patientId  TCGA-2J-AAB1  <...>20502 rows x 178 columns]\n",
      "expr_cols                     Index                      Index(['PANC1', 'PANC10',<...>ype='object', length=308)\n",
      "expr_df                       DataFrame                  sample  GSM1843893  GSM18<...>19749 rows x 357 columns]\n",
      "expr_out                      PosixPath                  /Users/scottpowers/Desktop/Puleo_expr.csv\n",
      "expr_paths                    list                       n=2\n",
      "expr_probes                   DataFrame                                    A11_C05<...>49386 rows x 309 columns]\n",
      "expr_puleo                    DataFrame                          GSM1843893  GSM18<...>19749 rows x 357 columns]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "expr_sym                      DataFrame                                A11_C05   A<...>20182 rows x 309 columns]\n",
      "expr_sym_col                  DataFrame                              gene_symbol  <...>20182 rows x 310 columns]\n",
      "expr_tcga                     DataFrame                  patientId  TCGA-2J-AAB1  <...>20502 rows x 178 columns]\n",
      "ext                           str                        pdf\n",
      "extract_dir                   PosixPath                  /Users/scottpowers/Deskto<...>B-6134_processed/unzipped\n",
      "f                             str                        organism_ch1\n",
      "fh                            TextIOWrapper              <_io.TextIOWrapper name='<...>txt.gz' encoding='utf-8'>\n",
      "fields_wanted                 list                       n=4\n",
      "fig                           Figure                     Figure(840x700)\n",
      "fig_path                      PosixPath                  out_tcga_ige_survival/TCGA_IGE_KM.png\n",
      "file_cols                     list                       n=2\n",
      "find_tcga_expr                function                   <function find_tcga_expr at 0x28b78ed40>\n",
      "first_col                     str                        PANC102\n",
      "fishers_exact                 function                   <function fishers_exact at 0x2860f1f80>\n",
      "fn                            str                        ProcessedExpression.tsv\n",
      "fname_to_assay                dict                       n=310\n",
      "font_manager                  module                     <module 'matplotlib.font_<...>plotlib/font_manager.py'>\n",
      "free                          Series                     _id\\nH08C5473_E09      {}<...>ength: 309, dtype: object\n",
      "g                             str                        ADCY4\n",
      "gene_col                      str                        Hybridization REF\n",
      "gene_like                     bool_                      True\n",
      "genes                         list                       n=4\n",
      "get_array                     function                   <function get_array at 0x2e85789a0>\n",
      "group                         str                        Combined low\n",
      "group_label                   str                        Combined low\n",
      "grp                           str                        IGE low\n",
      "gs                            GridSpec                   GridSpec(1, 3, width_ratios=[0.18, 0.92, 0.12])\n",
      "gzip                          module                     <module 'gzip' from '/Lib<...>/lib/python3.11/gzip.py'>\n",
      "hi                            DataFrame                                     IGE  O<...>      18.673768       1.0\n",
      "hi_e                          Series                     patientId\\nTCGA-2J-AABP  <...> OS_event, dtype: float64\n",
      "high_cut                      float64                    0.16138437907872633\n",
      "hint_cols                     list                       n=24\n",
      "hit                           NoneType                   None\n",
      "hits                          dict                       n=4\n",
      "i                             int                        356\n",
      "id_col                        str                        ID\n",
      "idx                           Index                      Index(['A1BG', 'A1CF', 'A<...>e='ID_REF', length=19749)\n",
      "ige                           DataFrame                                         Un<...>n\\n[183 rows x 2 columns]\n",
      "ige_col                       NoneType                   None\n",
      "ige_cov                       dict                       n=4\n",
      "ige_scores                    Series                     patientId\\nTCGA-2J-AAB1  <...>ngth: 178, dtype: float64\n",
      "il2_cov                       dict                       n=4\n",
      "il2_scores                    Series                     patientId\\nTCGA-2J-AAB1  <...>ngth: 178, dtype: float64\n",
      "im                            AxesImage                  AxesImage(shape=(16, 4))\n",
      "im1                           AxesImage                  AxesImage(shape=(4, 4))\n",
      "im2                           AxesImage                  AxesImage(shape=(4, 4))\n",
      "infer_cols                    function                   <function infer_cols at 0x29fce9300>\n",
      "info                          ZipInfo                    <ZipInfo filename='Proces<...> compress_size=120602935>\n",
      "inter                         int                        100\n",
      "inter_df                      DataFrame                         intersection  k  c<...>SAT+IGE+IL2+MPC  4      0\n",
      "inter_name                    str                        SAT+IGE+IL2+MPC\n",
      "inter_top                     DataFrame                         intersection  k  c<...>SAT+IGE+IL2+MPC  4      0\n",
      "io                            module                     <module 'io' (frozen)>\n",
      "is_days                       Series                     0      False\\n1      Fals<...> Length: 309, dtype: bool\n",
      "itertools                     module                     <module 'itertools' (built-in)>\n",
      "ix                            int                        15\n",
      "j                             int                        3\n",
      "jaccard                       function                   <function jaccard at 0x2c5791f80>\n",
      "jv                            float                      1.0\n",
      "k                             int                        4\n",
      "kept                          DataFrame                      module      gene     <...>n\\n[100 rows x 5 columns]\n",
      "key                           str                        PANC99\n",
      "km                            KaplanMeierFitter          <lifelines.KaplanMeierFit<...>ht-censored observations>\n",
      "km_from_times_events          function                   <function km_from_times_events at 0x29fce9da0>\n",
      "km_plot_and_logrank           function                   <function km_plot_and_logrank at 0x2c5793380>\n",
      "km_plot_and_logrank_optimal   function                   <function km_plot_and_log<...>k_optimal at 0x2c5791940>\n",
      "label                         str                        PULEO\n",
      "label_order                   list                       n=4\n",
      "label_var                     str                        TCGA\n",
      "labels                        list                       n=4\n",
      "labels_ord                    list                       n=4\n",
      "leaves                        list                       n=4\n",
      "lifelines_ok                  bool                       True\n",
      "line                          Line2D                     Line2D(Low IGE)\n",
      "lines                         list                       n=19820\n",
      "linkage                       function                   <function linkage at 0x154302ac0>\n",
      "lo                            DataFrame                                     IGE  O<...>n\\n[140 rows x 3 columns]\n",
      "lo_e                          Series                     patientId\\nTCGA-2J-AAB1  <...>ngth: 140, dtype: float64\n",
      "load_clin                     function                   <function load_clin at 0x381a0eb60>\n",
      "load_expr_matrix              function                   <function load_expr_matrix at 0x28b78f240>\n",
      "load_puleo_expr               function                   <function load_puleo_expr at 0x2994ac0e0>\n",
      "load_tcga_clin_pan_can        function                   <function load_tcga_clin_pan_can at 0x2a58fccc0>\n",
      "load_tcga_expr                function                   <function load_tcga_expr at 0x2c57e8180>\n",
      "local_zips                    list                       n=1\n",
      "logrank_test                  function                   <function logrank_test at 0x2ae980d60>\n",
      "low_cut                       float64                    -0.14521353435363543\n",
      "lp                            PosixPath                  /Users/scottpowers/Deskto<...>MTAB-6134.processed.1.zip\n",
      "lr                            StatisticalResult          <lifelines.StatisticalRes<...>      0.41 0.52      0.93\n",
      "m                             str                        MPC\n",
      "make_module_df                function                   <function make_module_df at 0x2a7f2cd60>\n",
      "mal_med                       float64                    0.21106168126826785\n",
      "map_df                        DataFrame                                           <...>n[51163 rows x 3 columns]\n",
      "map_df_present                DataFrame                                           <...>n[51163 rows x 3 columns]\n",
      "mapped                        list                       n=308\n",
      "mapped_cols                   list                       n=308\n",
      "mapped_count                  int                        308\n",
      "mapped_n                      int                        0\n",
      "mapped_ok                     int                        0\n",
      "mask                          Series                     0      False\\n1      Fals<...> Length: 309, dtype: bool\n",
      "mask_bad                      ndarray                    49386: 49386 elems, type `bool`, 49386 bytes\n",
      "mask_junk                     ndarray                    19749: 19749 elems, type `bool`, 19749 bytes\n",
      "mat                           DataFrame                  module        IGE       S<...>n[17916 rows x 4 columns]\n",
      "matplotlib                    module                     <module 'matplotlib' from<...>/matplotlib/__init__.py'>\n",
      "matrix_gz_path                PosixPath                  /Users/scottpowers/Deskto<...>1729_series_matrix.txt.gz\n",
      "max_q                         float                      0.8\n",
      "mdf                           DataFrame                             SAT    IGE    <...>n\\n[322 rows x 4 columns]\n",
      "med                           float                      0.019771231258939065\n",
      "merged                        DataFrame                                       SAT <...>n\\n[288 rows x 4 columns]\n",
      "meta                          DataFrame                                           <...>[1321 rows x 186 columns]\n",
      "meta_df                       DataFrame                             title source_n<...>n\\n[357 rows x 4 columns]\n",
      "meta_out                      PosixPath                  /Users/scottpowers/Desktop/Puleo_meta.csv\n",
      "meta_rows                     list                       n=357\n",
      "mi                            str                        MPC\n",
      "min_q                         float                      0.2\n",
      "missing                       set                        set()\n",
      "missing_down                  list                       n=10\n",
      "missing_up                    list                       n=73\n",
      "mj                            str                        MPC\n",
      "mod                           str                        MPC\n",
      "mods                          list                       n=4\n",
      "modules                       list                       n=4\n",
      "modules_df                    DataFrame                                     SAT   <...>n\\n[178 rows x 4 columns]\n",
      "mpc_cov                       dict                       n=4\n",
      "mpc_scores                    Series                     patientId\\nTCGA-2J-AAB1  <...>ngth: 178, dtype: float64\n",
      "mu                            float64                    0.004950528190232438\n",
      "multi                         DataFrame                  module   IGE  SAT  IL2  M<...>n\\n[177 rows x 5 columns]\n",
      "n                             int                        177\n",
      "name                          str                        E-MTAB-6134.processed.1.zip\n",
      "need                          list                       n=5\n",
      "neg                           DataFrame                        module     gene\\n40<...>\\n[1993 rows x 2 columns]\n",
      "neglogQ                       ndarray                    4x4: 16 elems, type `float64`, 128 bytes\n",
      "norm                          TwoSlopeNorm               <matplotlib.colors.TwoSlo<...>rm object at 0x342b9c590>\n",
      "norm_cols                     dict                       n=43\n",
      "norm_key                      function                   <function norm_key at 0x137d51580>\n",
      "norm_label                    function                   <function norm_label at 0x2a6477ba0>\n",
      "normalize_gene_index          function                   <function normalize_gene_index at 0x2a63158a0>\n",
      "normalize_url                 function                   <function normalize_url at 0x2c5782ac0>\n",
      "np                            module                     <module 'numpy' from '/Li<...>kages/numpy/__init__.py'>\n",
      "nx                            module                     <module 'networkx' from '<...>es/networkx/__init__.py'>\n",
      "offdiag_J                     ndarray                    12: 12 elems, type `float64`, 96 bytes\n",
      "offdiag_neglog                ndarray                    12: 12 elems, type `float64`, 96 bytes\n",
      "order                         ndarray                    6: 6 elems, type `int64`, 48 bytes\n",
      "os                            module                     <module 'os' (frozen)>\n",
      "os_status                     Series                     patientId\\nTCGA-3A-A9IN  <...>ength: 184, dtype: object\n",
      "out_csv                       PosixPath                  /Users/scottpowers/Deskto<...>normalized__data.data.csv\n",
      "out_path                      PosixPath                  /Users/scottpowers/Deskto<...>le_cox_combined_score.csv\n",
      "out_png                       PosixPath                  /Users/scottpowers/Deskto<...>_KM_out/COMBO4_KM_opt.png\n",
      "out_tbl                       DataFrame                              IL2_score  IL<...>n\\n[357 rows x 3 columns]\n",
      "p                             float                      0.038365137174561165\n",
      "pair_df                       DataFrame                        pair  overlap_n  si<...>00000       NaN     528.0\n",
      "pair_rows                     list                       n=6\n",
      "pairs                         list                       n=6\n",
      "panc                          str                        PANC306\n",
      "panc_map                      dict                       n=309\n",
      "params                        DataFrame                                        bro<...>701004 rows x 20 columns]\n",
      "parse_field_to_list           function                   <function parse_field_to_list at 0x137cc0e00>\n",
      "parse_free_row                function                   <function parse_free_row at 0x2c5782660>\n",
      "parse_genes                   function                   <function parse_genes at 0x2c5783c40>\n",
      "parts                         NoneType                   None\n",
      "path                          PosixPath                  /Users/scottpowers/Deskto<...>d/ProcessedExpression.tsv\n",
      "path_var                      str                        TCGA_EXPR\n",
      "pd                            module                     <module 'pandas' from '/L<...>ages/pandas/__init__.py'>\n",
      "picked                        PosixPath                  /Users/scottpowers/Deskto<...>d/ProcessedExpression.tsv\n",
      "picked_cols                   list                       n=22\n",
      "plot_km_module                function                   <function plot_km_module at 0x2a7f2e340>\n",
      "plt                           module                     <module 'matplotlib.pyplo<...>es/matplotlib/pyplot.py'>\n",
      "png_path                      PosixPath                  out_puleo_IL2/Puleo_IL2_scores_hist.png\n",
      "present                       Index                      Index(['affx-hsac07/x0035<...>],\\n      dtype='object')\n",
      "present_mask                  Series                     0        True\\n1        T<...>ength: 51163, dtype: bool\n",
      "probe_to_symbol               Series                     probe_id\\n1007_s_at      <...>gth: 45773, dtype: object\n",
      "puleo                         DataFrame                          GSM1843893  GSM18<...>19736 rows x 357 columns]\n",
      "puleo_meta                    DataFrame                           sample title sou<...>n\\n[357 rows x 5 columns]\n",
      "pvals                         ndarray                    6: 6 elems, type `float64`, 48 bytes\n",
      "q                             str                        High MAL / Low IGE\n",
      "q25                           float64                    -0.3182629795855956\n",
      "q75                           float64                    0.2596481951601884\n",
      "q_path                        PosixPath                  out_puleo_IL2/Puleo_IL2_scores_with_quartiles.csv\n",
      "q_sorted                      ndarray                    6: 6 elems, type `float64`, 48 bytes\n",
      "qmax                          int                        141\n",
      "qmin                          int                        35\n",
      "quad                          function                   <function quad at 0x2c57e8680>\n",
      "quad_colors                   dict                       n=4\n",
      "quadrant                      function                   <function quadrant at 0x2ffd1fd80>\n",
      "quadrant_label                function                   <function quadrant_label at 0x342cf19e0>\n",
      "qv                            float64                    2.360229648120995e-06\n",
      "r                             Series                     module         MPC\\ngene <...>ame: 71319, dtype: object\n",
      "ranks                         ndarray                    6: 6 elems, type `int64`, 48 bytes\n",
      "raw_path                      PosixPath                  out_modules_notebook/PULEO_IGE_signed_scores.csv\n",
      "raw_png                       PosixPath                  out_modules_notebook/PULE<...>GE_signed_scores_hist.png\n",
      "re                            module                     <module 're' from '/Libra<...>thon3.11/re/__init__.py'>\n",
      "read_any                      function                   <function read_any at 0x2abb78e00>\n",
      "remap_out                     PosixPath                  /Users/scottpowers/Deskto<...>6134_expression_ASSAY.csv\n",
      "requests                      module                     <module 'requests' from '<...>es/requests/__init__.py'>\n",
      "required                      list                       n=4\n",
      "res                           StatisticalResult          <lifelines.StatisticalRes<...>      0.01 0.93      0.10\n",
      "row                           dict                       n=4\n",
      "row_i                         int                        3\n",
      "row_labels                    list                       n=16\n",
      "row_modules                   list                       n=16\n",
      "s                             str                        \n",
      "sat_cov                       dict                       n=4\n",
      "sat_scores                    Series                     patientId\\nTCGA-2J-AAB1  <...>ngth: 178, dtype: float64\n",
      "score_cohort                  function                   <function score_cohort at 0x2bdbd1260>\n",
      "score_signed                  function                   <function score_signed at 0x381a0f880>\n",
      "score_signed_module           function                   <function score_signed_module at 0x2acf4f740>\n",
      "scores                        Series                     patientId\\nTCGA-2J-AAB1  <...>ngth: 178, dtype: float64\n",
      "scores_sorted                 Series                     patientId\\nTCGA-S4-A8RM  <...>ngth: 177, dtype: float64\n",
      "scores_z                      Series                     GSM1843893    1.526081\\nG<...>ngth: 357, dtype: float64\n",
      "sd                            float64                    0.6389715532371499\n",
      "sdrf                          DataFrame                      Source Name Character<...>\\n[309 rows x 51 columns]\n",
      "ser                           Series                     0         Desmoplastic\\n1<...>ength: 309, dtype: object\n",
      "set_sizes                     Series                     SAT    100\\nIGE    100\\nI<...>nMPC    100\\ndtype: int64\n",
      "sets                          list                       n=4\n",
      "sf                            DataFrame                              Low IGE\\ntime<...>\\n\\n[87 rows x 1 columns]\n",
      "shutil                        module                     <module 'shutil' from '/L<...>ib/python3.11/shutil.py'>\n",
      "sizes_sorted                  Series                     SAT    100\\nIGE    100\\nI<...>nMPC    100\\ndtype: int64\n",
      "smart_read_expr               function                   <function smart_read_expr at 0x103db5760>\n",
      "spine                         Spine                      Spine\n",
      "squareform                    function                   <function squareform at 0x2a877fa60>\n",
      "st                            str                        ProcessedExpression\n",
      "stars                         function                   <function stars at 0x29fbd22a0>\n",
      "start                         int                        12\n",
      "status_labels                 list                       n=2\n",
      "stem                          function                   <function stem at 0x2c5782840>\n",
      "stems                         Index                      Index(['PANC103', 'PANC10<...>ype='object', length=308)\n",
      "strip_ext                     function                   <function strip_ext at 0x2c5783380>\n",
      "sub                           DataFrame                                     IGE  O<...>n\\n[128 rows x 4 columns]\n",
      "surv                          DataFrame                                  time_mont<...>n\\n[288 rows x 2 columns]\n",
      "sym_col                       str                        Gene Symbol\n",
      "sym_out_col                   PosixPath                  /Users/scottpowers/Deskto<...>_with_gene_symbol_col.csv\n",
      "sym_out_idx                   PosixPath                  /Users/scottpowers/Deskto<...>xpression_GENESxASSAY.csv\n",
      "t                             ndarray                    87: 87 elems, type `float64`, 696 bytes\n",
      "table_block                   str                        \"ID_REF\"\t\"GSM1843893\"\t\"GS<...>2.309\t5.288\t3.620\t3.831\\n\n",
      "tcga                          DataFrame                                     TCGA-2<...>20502 rows x 183 columns]\n",
      "tcga_surv                     DataFrame                                    OS_time<...>n\\n[184 rows x 2 columns]\n",
      "tick_labels                   list                       n=4\n",
      "tick_positions                list                       n=4\n",
      "time_col                      str                        Characteristics[os.delay]\n",
      "time_day_labels               list                       n=0\n",
      "time_month_labels             list                       n=0\n",
      "time_vals                     ndarray                    309: 309 elems, type `float64`, 2472 bytes\n",
      "tm                            Series                     A11_C05           49.90\\n<...>ngth: 288, dtype: float64\n",
      "to_assay                      function                   <function to_assay at 0x2ffd1c9a0>\n",
      "to_event                      function                   <function to_event at 0x2c5782ca0>\n",
      "to_float_num                  function                   <function to_float_num at 0x2aadf99e0>\n",
      "to_num                        function                   <function to_num at 0x2c5782700>\n",
      "tri_df                        DataFrame                          triple  overlap_n<...>2  IGE∩IL2∩MPC          0\n",
      "tri_rows                      list                       n=4\n",
      "try_build_map_from_df         function                   <function try_build_map_from_df at 0x2994ac040>\n",
      "try_load                      function                   <function try_load at 0x1203abd80>\n",
      "try_read                      function                   <function try_read at 0x2c5782a20>\n",
      "u                             str                        PANC11\n",
      "union                         set                        {'FAU', 'GFOD1', 'CDK4', <...>rf16', 'POLR3H', 'FAM3A'}\n",
      "unit_col                      str                        Unit[time unit].1\n",
      "units                         Series                     0      month\\n1      mont<...>ength: 309, dtype: object\n",
      "unmapped                      list                       n=308\n",
      "up_cov                        int                        0\n",
      "url_col                       str                        Comment [Derived ArrayExpress FTP file]\n",
      "v                             str                        ProcessedExpression\n",
      "v2                            str                        ProcessedExpression\n",
      "val                           int64                      0\n",
      "vmax                          float                      1.0\n",
      "vmax1                         float64                    0.13636363636363635\n",
      "vmax2                         float64                    17.263645038907473\n",
      "vmin                          float                      -1.0\n",
      "vmin1                         float                      0.0\n",
      "vmin2                         float                      0.0\n",
      "where                         ndarray                    15: 15 elems, type `bool`, 15 bytes\n",
      "wide                          DataFrame                          gene  SAT  IGE  I<...>n\\n[322 rows x 5 columns]\n",
      "wide_map                      dict                       n=22\n",
      "x                             ndarray                    15: 15 elems, type `int64`, 120 bytes\n",
      "xi                            int64                      14\n",
      "y                             ndarray                    87: 87 elems, type `float64`, 696 bytes\n",
      "y0                            int64                      16\n",
      "ymax                          int64                      80\n",
      "z                             Series                     GSM1843893    1.303170\\nG<...>ngth: 357, dtype: float64\n",
      "z_path                        PosixPath                  out_modules_notebook/PULE<...>O_IGE_signed_scores_Z.csv\n",
      "z_per_gene                    function                   <function z_per_gene at 0x2c57834c0>\n",
      "z_png                         PosixPath                  out_modules_notebook/PULE<...>_signed_scores_Z_hist.png\n",
      "zf                            ZipFile                    <zipfile.ZipFile [closed]>\n",
      "zip_urls                      list                       n=1\n",
      "zipfile                       module                     <module 'zipfile' from '/<...>b/python3.11/zipfile.py'>\n",
      "zp                            PosixPath                  /Users/scottpowers/Deskto<...>MTAB-6134.processed.1.zip\n",
      "zscore                        function                   <function zscore at 0x3822f19e0>\n",
      "zscore_by_gene                function                   <function zscore_by_gene at 0x2bda1ac00>\n",
      "zscore_series                 function                   <function zscore_series at 0x381a0ec00>\n"
     ]
    }
   ],
   "source": [
    "whos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "410ff4f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[COMBO4] N with all 4 modules + OS: 177\n",
      "[COMBO4 KM] cut=-0.759, p=0.176 -> /Users/scottpowers/Desktop/tcga_paad_COMBO4_KM_out/COMBO4_KM_opt.png\n"
     ]
    }
   ],
   "source": [
    "# --- COMBO4 KM: SAT_Z + MPC_Z − IL2_Z − IGE_Z (optimal cut) ---\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from lifelines import KaplanMeierFitter\n",
    "from lifelines.statistics import logrank_test\n",
    "\n",
    "# Where to save\n",
    "DESKTOP = Path.home() / \"Desktop\"\n",
    "OUTDIR_COMBO4 = DESKTOP / \"tcga_paad_COMBO4_KM_out\"\n",
    "OUTDIR_COMBO4.mkdir(parents=True, exist_ok=True)\n",
    "out_png = OUTDIR_COMBO4 / \"COMBO4_KM_opt.png\"\n",
    "\n",
    "# Use Arial if available\n",
    "plt.rcParams[\"font.family\"] = \"Arial\"\n",
    "\n",
    "# ---------- 1) Align modules + clinical on common patients ----------\n",
    "required = [\n",
    "    sat_scores.rename(\"SAT\"),\n",
    "    mpc_scores.rename(\"MPC\"),\n",
    "    il2_scores.rename(\"IL2\"),\n",
    "    ige_scores.rename(\"IGE\"),\n",
    "]\n",
    "\n",
    "# Inner-join on index (patientId)\n",
    "modules_df = pd.concat(required, axis=1, join=\"inner\")\n",
    "\n",
    "# Bring in OS info and drop any missing\n",
    "df_combo = pd.concat(\n",
    "    [modules_df, clin[[\"OS_time_months\", \"OS_event\"]]],\n",
    "    axis=1,\n",
    "    join=\"inner\"\n",
    ").dropna(subset=[\"SAT\", \"MPC\", \"IL2\", \"IGE\", \"OS_time_months\", \"OS_event\"])\n",
    "\n",
    "print(f\"[COMBO4] N with all 4 modules + OS: {df_combo.shape[0]}\")\n",
    "\n",
    "if df_combo.shape[0] < 10:\n",
    "    print(\"[COMBO4] Not enough patients for KM; skipping.\")\n",
    "else:\n",
    "    # ---------- 2) Z-score each module ----------\n",
    "    def zscore(s):\n",
    "        mu = s.mean()\n",
    "        sd = s.std(ddof=0)\n",
    "        return s*0 if (sd == 0 or np.isnan(sd)) else (s - mu) / sd\n",
    "\n",
    "    df_combo[\"SAT_Z\"] = zscore(df_combo[\"SAT\"])\n",
    "    df_combo[\"MPC_Z\"] = zscore(df_combo[\"MPC\"])\n",
    "    df_combo[\"IL2_Z\"] = zscore(df_combo[\"IL2\"])\n",
    "    df_combo[\"IGE_Z\"] = zscore(df_combo[\"IGE\"])\n",
    "\n",
    "    # Combined “biologic burden” score:\n",
    "    # SAT & MPC = risk; IL2 & IGE = protective → subtract the protective ones\n",
    "    df_combo[\"COMBO4\"] = df_combo[\"SAT_Z\"] + df_combo[\"MPC_Z\"] - df_combo[\"IL2_Z\"] - df_combo[\"IGE_Z\"]\n",
    "\n",
    "    # ---------- 3) Optimal cut KM on COMBO4 ----------\n",
    "    scores = df_combo[\"COMBO4\"].dropna().sort_values()\n",
    "    n = len(scores)\n",
    "\n",
    "    best_cut, best_p = None, 1.0\n",
    "    min_q, max_q = 0.2, 0.8\n",
    "    qmin = int(n * min_q)\n",
    "    qmax = int(n * max_q)\n",
    "    candidates = scores.iloc[qmin:qmax]\n",
    "\n",
    "    for cut in candidates:\n",
    "        group = scores >= cut\n",
    "        hi = df_combo.loc[group, \"OS_time_months\"]\n",
    "        lo = df_combo.loc[~group, \"OS_time_months\"]\n",
    "        hi_e = df_combo.loc[group, \"OS_event\"]\n",
    "        lo_e = df_combo.loc[~group, \"OS_event\"]\n",
    "        if len(hi) < 5 or len(lo) < 5:\n",
    "            continue\n",
    "        lr = logrank_test(hi, lo, event_observed_A=hi_e, event_observed_B=lo_e)\n",
    "        if lr.p_value < best_p:\n",
    "            best_p = float(lr.p_value)\n",
    "            best_cut = float(cut)\n",
    "\n",
    "    if best_cut is None:\n",
    "        print(\"[COMBO4] No valid cut in 20–80% range; using median.\")\n",
    "        best_cut = float(scores.median())\n",
    "        best_p = float(\"nan\")\n",
    "\n",
    "    # Assign groups\n",
    "    df_combo[\"group\"] = np.where(df_combo[\"COMBO4\"] >= best_cut, \"Combined high\", \"Combined low\")\n",
    "\n",
    "    # ---------- 4) Plot KM ----------\n",
    "    km = KaplanMeierFitter()\n",
    "    fig, ax = plt.subplots(figsize=(6.5, 5), dpi=160)\n",
    "\n",
    "    for group_label in [\"Combined high\", \"Combined low\"]:\n",
    "        sub = df_combo[df_combo[\"group\"] == group_label]\n",
    "        if sub.empty:\n",
    "            continue\n",
    "        km.fit(sub[\"OS_time_months\"], sub[\"OS_event\"], label=f\"{group_label} (n={len(sub)})\")\n",
    "        sf = km.survival_function_.iloc[:, 0]\n",
    "        t = sf.index.values\n",
    "        y = sf.values\n",
    "        ax.step(t, y, where=\"post\", label=km._label)\n",
    "        ci = km.confidence_interval_\n",
    "        ax.fill_between(\n",
    "            t,\n",
    "            ci.iloc[:, 0].values,\n",
    "            ci.iloc[:, 1].values,\n",
    "            step=\"post\",\n",
    "            alpha=0.20,\n",
    "        )\n",
    "\n",
    "    ax.set_xlabel(\"Time (months)\")\n",
    "    ax.set_ylabel(\"Overall survival probability\")\n",
    "    ax.set_title(f\"TCGA-PAAD: Combined module score (COMBO4)\\n\"\n",
    "                 f\"SAT_Z + MPC_Z − IL2_Z − IGE_Z\\n\"\n",
    "                 f\"optimal cut={best_cut:.3f}, p={best_p:.3g}\")\n",
    "    ax.legend()\n",
    "    fig.tight_layout()\n",
    "    fig.savefig(out_png, bbox_inches=\"tight\")\n",
    "    plt.close(fig)\n",
    "\n",
    "    print(f\"[COMBO4 KM] cut={best_cut:.3f}, p={best_p:.3g} -> {out_png}\")\n",
    "    # Optional: save the dataframe with group labels\n",
    "    df_combo.to_csv(OUTDIR_COMBO4 / \"COMBO4_scores_OS_group_opt.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "88054f99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[COMBO INTERACTION] N with all 4 modules + OS: 177\n",
      "\n",
      "[GROUP COUNTS]\n",
      "group\n",
      "High MAL / High ADAPT    46\n",
      "Low MAL / Low ADAPT      45\n",
      "Low MAL / High ADAPT     43\n",
      "High MAL / Low ADAPT     43\n",
      "Name: count, dtype: int64\n",
      "\n",
      "[OUTPUT] Saved 4-group interaction KM to: /Users/scottpowers/Desktop/TCGA_PADD_COMBO_4way_MAL_ADAPT_KM.png\n"
     ]
    }
   ],
   "source": [
    "# --- Combined module interaction KM: Maladaptive vs Adaptive ---\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from lifelines import KaplanMeierFitter\n",
    "from lifelines.statistics import logrank_test\n",
    "\n",
    "# Use Arial if available\n",
    "plt.rcParams[\"font.family\"] = \"Arial\"\n",
    "\n",
    "# 1) Merge modules + clinical on patientId\n",
    "df_mod = pd.concat(\n",
    "    [\n",
    "        sat_scores.rename(\"SAT\"),\n",
    "        mpc_scores.rename(\"MPC\"),\n",
    "        il2_scores.rename(\"IL2\"),\n",
    "        ige_scores.rename(\"IGE\"),\n",
    "        clin[[\"OS_time_months\", \"OS_event\"]],\n",
    "    ],\n",
    "    axis=1,\n",
    "    join=\"inner\",\n",
    ")\n",
    "\n",
    "# Keep only rows with all four modules + OS info\n",
    "df_mod = df_mod.dropna(subset=[\"SAT\", \"MPC\", \"IL2\", \"IGE\", \"OS_time_months\", \"OS_event\"])\n",
    "print(\"[COMBO INTERACTION] N with all 4 modules + OS:\", df_mod.shape[0])\n",
    "\n",
    "# 2) Z-score each module\n",
    "for col in [\"SAT\", \"MPC\", \"IL2\", \"IGE\"]:\n",
    "    mu = df_mod[col].mean()\n",
    "    sd = df_mod[col].std(ddof=0)\n",
    "    if sd == 0 or np.isnan(sd):\n",
    "        df_mod[col + \"_Z\"] = 0.0\n",
    "    else:\n",
    "        df_mod[col + \"_Z\"] = (df_mod[col] - mu) / sd\n",
    "\n",
    "# 3) Define axes\n",
    "# Maladaptive axis: SAT + MPC - IL2 (higher = worse biology)\n",
    "df_mod[\"MAL_Z\"] = df_mod[\"SAT_Z\"] + df_mod[\"MPC_Z\"] - df_mod[\"IL2_Z\"]\n",
    "\n",
    "# Adaptive axis: IGE (higher = better biology)\n",
    "df_mod[\"ADAPT_Z\"] = df_mod[\"IGE_Z\"]\n",
    "\n",
    "# 4) Dichotomize both axes at their medians\n",
    "mal_med = df_mod[\"MAL_Z\"].median()\n",
    "ad_med  = df_mod[\"ADAPT_Z\"].median()\n",
    "\n",
    "def quadrant_label(row):\n",
    "    mal = \"High MAL\" if row[\"MAL_Z\"] >= mal_med else \"Low MAL\"\n",
    "    ad  = \"High ADAPT\" if row[\"ADAPT_Z\"] >= ad_med else \"Low ADAPT\"\n",
    "    return f\"{mal} / {ad}\"\n",
    "\n",
    "df_mod[\"group\"] = df_mod.apply(quadrant_label, axis=1)\n",
    "\n",
    "print(\"\\n[GROUP COUNTS]\")\n",
    "print(df_mod[\"group\"].value_counts())\n",
    "\n",
    "# (Optional) collapse labels into more intuitive wording in the legend\n",
    "label_order = [\n",
    "    \"Low MAL / High ADAPT\",   # expected best prognosis\n",
    "    \"Low MAL / Low ADAPT\",\n",
    "    \"High MAL / High ADAPT\",\n",
    "    \"High MAL / Low ADAPT\",   # expected worst prognosis\n",
    "]\n",
    "\n",
    "# 5) KM plot for the four interaction groups\n",
    "km = KaplanMeierFitter()\n",
    "fig, ax = plt.subplots(figsize=(6.5, 5), dpi=160)\n",
    "\n",
    "for label in label_order:\n",
    "    sub = df_mod[df_mod[\"group\"] == label]\n",
    "    if sub.empty:\n",
    "        continue\n",
    "    km.fit(\n",
    "        durations=sub[\"OS_time_months\"],\n",
    "        event_observed=sub[\"OS_event\"],\n",
    "        label=f\"{label} (n={len(sub)})\",\n",
    "    )\n",
    "    km.plot_survival_function(ax=ax, ci_show=True)\n",
    "\n",
    "ax.set_xlabel(\"Time (months)\")\n",
    "ax.set_ylabel(\"Overall survival probability\")\n",
    "ax.set_title(\"TCGA-PAAD: Interaction of module burden\\n(Maladaptive vs Adaptive axes)\")\n",
    "ax.legend()\n",
    "fig.tight_layout()\n",
    "\n",
    "out_path = Path.home() / \"Desktop\" / \"TCGA_PADD_COMBO_4way_MAL_ADAPT_KM.png\"\n",
    "fig.savefig(out_path, bbox_inches=\"tight\")\n",
    "plt.close(fig)\n",
    "\n",
    "print(f\"\\n[OUTPUT] Saved 4-group interaction KM to: {out_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2fecd2ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[RAW] shape: (49386, 309)\n",
      "[RAW] example columns: ['PANC102', 'PANC103', 'PANC104', 'PANC105', 'PANC106', 'PANC107', 'PANC108', 'PANC109', 'PANC110', 'PANC111']\n",
      "[STEP] probes×samples after assay remap: (49386, 309)\n",
      "[MAP] Symbols for 10 / 49386 probes (~0.0%).\n",
      "[STEP] symbols×samples: (3, 309)\n",
      "✅ Saved: /Users/scottpowers/Desktop/E-MTAB-6134_expression_GENESxASSAY.csv\n",
      "✅ Saved: /Users/scottpowers/Desktop/E-MTAB-6134_expression_GENESxASSAY_with_gene_symbol_col.csv\n",
      "[COVERAGE] SAT up 0 / 185 | down 0 / 25 (insufficient)\n",
      "[MERGE] N = 0\n",
      "Expr symbols: 3 Assays: 309\n",
      "UP found: 0 / 185\n",
      "DN found: 0 / 25\n"
     ]
    }
   ],
   "source": [
    "# --- E-MTAB-6134: probes→symbols, remap to Assay, save, score SAT, merge survival ---\n",
    "\n",
    "import re, pandas as pd, numpy as np\n",
    "from pathlib import Path\n",
    "import io, gzip\n",
    "\n",
    "# ===== Paths =====\n",
    "DESKTOP = Path(\"~/Desktop\").expanduser()\n",
    "SDRF = DESKTOP / \"E-MTAB-6134.sdrf.txt\"\n",
    "UNZ  = DESKTOP / \"E-MTAB-6134_processed\" / \"unzipped\"\n",
    "RAW  = UNZ / \"ProcessedExpression.tsv\"                  # from the zip\n",
    "SURV = DESKTOP / \"Puleo_survival_from_SDRF.csv\"\n",
    "ANNO = DESKTOP / \"GPL570-55999.txt\"                     # <-- set to your GPL570 annotation file (csv/tsv/txt/gz ok)\n",
    "\n",
    "assert RAW.exists(), f\"Missing {RAW}\"\n",
    "assert SDRF.exists(), f\"Missing {SDRF}\"\n",
    "assert SURV.exists(), f\"Missing {SURV}\"\n",
    "assert ANNO.exists(), f\"Missing annotation: {ANNO} (put your GPL570 annot here)\"\n",
    "\n",
    "# ===== Load SDRF and helpers (PANC### → Assay Name) =====\n",
    "sdrf = pd.read_csv(SDRF, sep=\"\\t\", dtype=str).fillna(\"\")\n",
    "assay_col = \"Assay Name\" if \"Assay Name\" in sdrf.columns else None\n",
    "if assay_col is None:\n",
    "    for c in [\"Sample Name\",\"Source Name\"]:\n",
    "        if c in sdrf.columns: assay_col = c; break\n",
    "if assay_col is None:\n",
    "    raise ValueError(\"No Assay/Sample ID column found in SDRF.\")\n",
    "\n",
    "ASSAYS = set(sdrf[assay_col].astype(str).str.strip())\n",
    "PANC_RE = re.compile(r\"^PANC\\d+$\", re.I)\n",
    "\n",
    "panc_map = {}\n",
    "for c in sdrf.columns:\n",
    "    if c == assay_col: \n",
    "        continue\n",
    "    ser = sdrf[c].astype(str)\n",
    "    mask = ser.str.match(PANC_RE, na=False)\n",
    "    if mask.any():\n",
    "        sub = sdrf.loc[mask, [c, assay_col]]\n",
    "        for _, row in sub.iterrows():\n",
    "            panc_map[str(row[c]).strip()] = str(row[assay_col]).strip()\n",
    "\n",
    "def to_assay(colname: str) -> str:\n",
    "    c = str(colname).strip()\n",
    "    if c in ASSAYS: \n",
    "        return c\n",
    "    if PANC_RE.match(c) and c in panc_map:\n",
    "        return panc_map[c]\n",
    "    return c  # leave as-is\n",
    "\n",
    "# ===== 1) Load ProcessedExpression as probes × samples =====\n",
    "df = pd.read_csv(RAW, sep=\"\\t\", index_col=0)\n",
    "print(\"[RAW] shape:\", df.shape)\n",
    "print(\"[RAW] example columns:\", df.columns[:10].tolist())\n",
    "if df.shape[0] == 0 or df.shape[1] == 0:\n",
    "    raise RuntimeError(\"ProcessedExpression.tsv loaded empty; check the file.\")\n",
    "\n",
    "# coerce numeric\n",
    "df = df.apply(pd.to_numeric, errors=\"coerce\")\n",
    "\n",
    "# ===== 2) Remap columns PANC### → Assay Name and collapse duplicates =====\n",
    "df.columns = [to_assay(c) for c in map(str, df.columns)]\n",
    "expr_probes = (df.T.groupby(level=0).mean(numeric_only=True)).T\n",
    "print(\"[STEP] probes×samples after assay remap:\", expr_probes.shape)\n",
    "\n",
    "# ===== 3) Probe → Symbol using GPL570 annotation =====\n",
    "def _open_any(path: Path):\n",
    "    b = path.read_bytes()\n",
    "    if len(b) >= 2 and b[0] == 0x1F and b[1] == 0x8B:\n",
    "        return io.StringIO(gzip.decompress(b).decode(\"utf-8\", errors=\"replace\"))\n",
    "    return io.StringIO(b.decode(\"utf-8\", errors=\"replace\"))\n",
    "\n",
    "def _clean_symbol_field(s: str) -> str:\n",
    "    if s is None: return \"\"\n",
    "    s = str(s).strip()\n",
    "    if not s or s in {\"---\",\".\",\"NA\",\"na\",\"NaN\"}: return \"\"\n",
    "    s = (s.replace(\"///\",\"|\").replace(\"//\",\"|\").replace(\";\", \"|\")\n",
    "           .replace(\",\", \"|\").replace(\"\\t\",\"|\"))\n",
    "    toks = [t.strip().upper() for t in s.split(\"|\") if t.strip()]\n",
    "    toks = [re.sub(r\"\\.\\d+$\",\"\", t) for t in toks]  # drop version suffixes like AC018521.5\n",
    "    ok = [t for t in toks if re.fullmatch(r\"[A-Z0-9][A-Z0-9\\.\\-]{1,19}\", t)]\n",
    "    if not ok: return \"\"\n",
    "    non_mi = [t for t in ok if not t.startswith(\"MIR\")]\n",
    "    return non_mi[0] if non_mi else ok[0]\n",
    "\n",
    "# normalize probe IDs to lowercase for matching (GPL files typically lowercase)\n",
    "expr_probes.index = expr_probes.index.astype(str).str.strip().str.lower()\n",
    "\n",
    "buf = _open_any(ANNO)\n",
    "buf.seek(0)\n",
    "anno = pd.read_csv(buf, sep=None, engine=\"python\", dtype=str)\n",
    "norm_cols = {re.sub(r\"\\W+\",\"\", c).lower(): c for c in anno.columns}\n",
    "\n",
    "id_col = None\n",
    "for k in [\"id\",\"probesetid\",\"probeset\",\"probesetname\",\"probe_set_id\"]:\n",
    "    if k in norm_cols: id_col = norm_cols[k]; break\n",
    "if id_col is None:\n",
    "    raise ValueError(\"No probe ID column (e.g., 'ID') found in the annotation.\")\n",
    "\n",
    "sym_col = None\n",
    "for k in [\"genesymbol\",\"symbol\",\"gene_symbol\",\"hugosymbol\",\"hgnc\"]:\n",
    "    if k in norm_cols: sym_col = norm_cols[k]; break\n",
    "if sym_col is None:\n",
    "    raise ValueError(\"No 'Gene Symbol' column found in the annotation.\")\n",
    "\n",
    "map_df = anno[[id_col, sym_col]].rename(columns={id_col:\"probe_id\", sym_col:\"gene_symbol\"}).dropna()\n",
    "map_df[\"probe_id\"] = map_df[\"probe_id\"].astype(str).str.strip().str.lower()\n",
    "map_df[\"gene_symbol\"] = map_df[\"gene_symbol\"].map(_clean_symbol_field)\n",
    "map_df = map_df[map_df[\"gene_symbol\"] != \"\"].drop_duplicates(subset=[\"probe_id\"], keep=\"first\")\n",
    "probe_to_symbol = map_df.set_index(\"probe_id\")[\"gene_symbol\"]\n",
    "\n",
    "present = probe_to_symbol.index.intersection(expr_probes.index)\n",
    "den = max(1, expr_probes.shape[0])  # safe for logging\n",
    "print(f\"[MAP] Symbols for {present.size} / {expr_probes.shape[0]} probes (~{present.size/den:.1%}).\")\n",
    "if present.size == 0:\n",
    "    # helpful peek\n",
    "    print(\"Examples (matrix probe → in annot?):\", [(p, p in probe_to_symbol.index) for p in expr_probes.index[:5]])\n",
    "    raise RuntimeError(\"No probe IDs matched the annotation; check ANNO matches platform (GPL570) and file columns.\")\n",
    "\n",
    "# collapse to symbols (median across probes per gene)\n",
    "df_sym = expr_probes.loc[present].copy()\n",
    "df_sym.insert(0, \"gene_symbol\", probe_to_symbol.loc[present].values)\n",
    "expr_sym = df_sym.groupby(\"gene_symbol\").median(numeric_only=True)\n",
    "print(\"[STEP] symbols×samples:\", expr_sym.shape)\n",
    "\n",
    "# ===== 4) Save matrices (with and without explicit gene_symbol column) =====\n",
    "sym_out_idx = DESKTOP / \"E-MTAB-6134_expression_GENESxASSAY.csv\"\n",
    "expr_sym.to_csv(sym_out_idx)\n",
    "expr_sym_col = expr_sym.copy()\n",
    "expr_sym_col.insert(0, \"gene_symbol\", expr_sym_col.index.astype(str))\n",
    "sym_out_col = DESKTOP / \"E-MTAB-6134_expression_GENESxASSAY_with_gene_symbol_col.csv\"\n",
    "expr_sym_col.to_csv(sym_out_col, index=False)\n",
    "print(\"✅ Saved:\", sym_out_idx)\n",
    "print(\"✅ Saved:\", sym_out_col)\n",
    "\n",
    "# ===== 5) SAT scoring =====\n",
    "SAT_UP = [\n",
    "    \"ABHD8\",\"AC004870.4\",\"AC005920.1\",\"AC009041.1\",\"AC009309.1\",\"AC011498.1\",\"AC012447.1\",\"AC018521.5\",\n",
    "    \"AC018754.1\",\"AC027237.2\",\"AC068338.2\",\"AC072061.1\",\"AC079305.3\",\"AC079807.1\",\"AC087623.2\",\"AC090403.1\",\n",
    "    \"AC091271.1\",\"AC092287.1\",\"AC092910.3\",\"AC093323.1\",\"AC099778.1\",\"AC107959.2\",\"AC125611.3\",\"AC144652.1\",\n",
    "    \"AC239799.2\",\"AC253572.2\",\"ACBD7\",\"AFMID\",\"AHCY\",\"AL021155.5\",\"AL022069.1\",\"AL031963.3\",\"AL049869.2\",\n",
    "    \"AL121574.1\",\"AL133523.1\",\"AL139106.1\",\"AL139246.5\",\"AL355075.4\",\"AL360012.1\",\"AL365436.2\",\"AL592295.5\",\n",
    "    \"AL662844.4\",\"AP001160.1\",\"AP002381.2\",\"AP002813.1\",\"ARL4D\",\"ATP2B1-AS1\",\"ATRIP\",\"BAMBI\",\"BHLHE40-AS1\",\n",
    "    \"BOLA1\",\"BUD23\",\"C12orf65\",\"C19orf48\",\"C2CD4B\",\"C6orf120\",\"CABYR\",\"CCDC9\",\"CCNE2\",\"CDKN2AIP\",\"CHCHD7\",\n",
    "    \"CITED2\",\"CROCC\",\"CSKMT\",\"CTH\",\"DALRD3\",\"DRAIC\",\"DUSP28\",\"EAF2\",\"EIF4A3\",\"FOXA3\",\"FOXL1\",\"GADD45B\",\"GLA\",\n",
    "    \"GOT1\",\"GRPEL1\",\"GTF2A1\",\"GTF2B\",\"HEXIM1\",\"HIST1H2AG\",\"HIST1H2AH\",\"HIST1H2AL\",\"HIST1H2BJ\",\"HIST1H2BN\",\n",
    "    \"HIST1H3A\",\"HIST1H3J\",\"HIST1H4A\",\"HIST1H4C\",\"HIST1H4E\",\"HIST2H2AC\",\"HIST2H3PS2\",\"HIST3H2A\",\"HIST4H4\",\"HMBS\",\n",
    "    \"HSPA2\",\"ID2\",\"IDI1\",\"ING1\",\"KCTD5\",\"KIF9\",\"KLHL11\",\"LAP3\",\"LIFR-AS1\",\"LINC01970\",\"LINC02029\",\"LINC02363\",\n",
    "    \"LRG1\",\"LRTOMT\",\"MAFB\",\"MED29\",\"MEPCE\",\"MIR17HG\",\"MORF4L2-AS1\",\"MTHFD2\",\"MYCL\",\"MYOSLID\",\"NANOS1\",\"NPW\",\n",
    "    \"NRARP\",\"OAT\",\"OSER1-DT\",\"OSGIN1\",\"PHYH\",\"PICART1\",\"PIEZO1\",\"PIK3R3\",\"PLIN5\",\"PLK2\",\"PMAIP1\",\"PMEL\",\"PNKD\",\n",
    "    \"POU3F1\",\"PPP1R3C\",\"PRMT5-AS1\",\"PRR3\",\"PTCH2\",\"PTPN6\",\"RAB26\",\"RALY-AS1\",\"RASL11A\",\"RND1\",\"RNF223\",\"RUVBL2\",\n",
    "    \"SAE1\",\"SENP8\",\"SIAH2-AS1\",\"SIRT2\",\"SLC7A5\",\"SNHG12\",\"SNHG5\",\"SNHG8\",\"SREBF2-AS1\",\"SRSF7\",\"STARD5\",\"TBPL1\",\n",
    "    \"TCTA\",\"THAP9\",\"TLCD1\",\"TM7SF2\",\"TMEM107\",\"TMEM171\",\"TMEM69\",\"TNFRSF10D\",\"TNK1\",\"TRAM2-AS1\",\"TTC33\",\"UAP1\",\n",
    "    \"UBAC2-AS1\",\"UBE2D3-AS1\",\"UBE2S\",\"UGDH\",\"WDR74\",\"Z93241.1\",\"Z99127.4\",\"ZC3H10\",\"ZCWPW1\",\"ZFAS1\",\"ZFX-AS1\",\n",
    "    \"ZNF574\",\"ZNF584\",\"ZNF622\",\"ZNF687-AS1\",\"ZNF844\",\"ZNF92\",\"ZSWIM3\"\n",
    "]\n",
    "SAT_DOWN = [\n",
    "    \"PAX5\",\"AC117386.2\",\"PRSS55\",\"RPS16\",\"GDF7\",\"PAK4\",\"AC022144.1\",\"AC092745.5\",\"AL670729.3\",\n",
    "    \"DLEU2L\",\"ELP3\",\"KCNC2\",\"MAP4K1\",\"AL161729.4\",\"SV2C\",\"RGS11\",\"AC005498.1\",\"WFDC5\",\"PSENEN\",\n",
    "    \"LINC01956\",\"AC115485.1\",\"CYSLTR2\",\"ASMTL-AS1\",\"AP002001.3\",\"FAM153B\"\n",
    "]\n",
    "SAT_UP = [g.strip().upper() for g in SAT_UP]\n",
    "SAT_DOWN = [g.strip().upper() for g in SAT_DOWN]\n",
    "\n",
    "def score_signed(expr_df, up_genes, down_genes, min_genes=10):\n",
    "    # Row-wise Z\n",
    "    mu = expr_df.mean(axis=1)\n",
    "    sd = expr_df.std(axis=1, ddof=0).replace(0, np.nan)\n",
    "    Z = expr_df.sub(mu, axis=0).div(sd, axis=0)\n",
    "\n",
    "    up = pd.Index(up_genes).intersection(Z.index)\n",
    "    dn = pd.Index(down_genes).intersection(Z.index)\n",
    "    cov = {\"up_used\": int(up.size), \"up_total\": len(up_genes),\n",
    "           \"down_used\": int(dn.size), \"down_total\": len(down_genes)}\n",
    "    if up.size < min_genes or dn.size < min_genes:\n",
    "        print(f\"[COVERAGE] SAT up {cov['up_used']} / {cov['up_total']} | down {cov['down_used']} / {cov['down_total']} (insufficient)\")\n",
    "        return pd.Series(np.nan, index=Z.columns, name=\"SAT\"), cov\n",
    "    score = Z.loc[up].mean(axis=0) - Z.loc[dn].mean(axis=0)\n",
    "    score.name = \"SAT\"\n",
    "    print(f\"[COVERAGE] SAT up {cov['up_used']} / {cov['up_total']} | down {cov['down_used']} / {cov['down_total']}\")\n",
    "    return score, cov\n",
    "\n",
    "sat_scores, cov = score_signed(expr_sym, SAT_UP, SAT_DOWN, min_genes=10)\n",
    "\n",
    "# ===== 6) Survival merge =====\n",
    "surv = pd.read_csv(SURV, index_col=0)\n",
    "surv.index = pd.Index([to_assay(str(x).strip()) for x in surv.index], name=\"Assay Name\")\n",
    "merged = pd.concat([sat_scores.rename(\"SAT\"), surv[[\"time_months\",\"event\"]]], axis=1, join=\"inner\").dropna()\n",
    "print(\"[MERGE] N =\", merged.shape[0])\n",
    "\n",
    "# ===== Quick diags =====\n",
    "if sat_scores.notna().any():\n",
    "    s = sat_scores.dropna().sort_values()\n",
    "    print(\"[SAT] lowest 5:\", list(zip(s.index[:5], s.values[:5])))\n",
    "    print(\"[SAT] highest 5:\", list(zip(s.index[-5:], s.values[-5:])))\n",
    "else:\n",
    "    # show coverage and a few found genes for debugging\n",
    "    print(\"Expr symbols:\", expr_sym.shape[0], \"Assays:\", expr_sym.shape[1])\n",
    "    print(\"UP found:\", sum(g in expr_sym.index for g in SAT_UP), \"/\", len(SAT_UP))\n",
    "    print(\"DN found:\", sum(g in expr_sym.index for g in SAT_DOWN), \"/\", len(SAT_DOWN))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "1f7b5c46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SCATTER] N with all 4 modules: 178\n",
      "[OUTPUT] Saved scatter plot to: /Users/scottpowers/Desktop/TCGA_PADD_MAL_vs_IGE_scatter.png\n"
     ]
    }
   ],
   "source": [
    "# --- 2D scatter: Maladaptive vs Adaptive (IGE) ---\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "\n",
    "# Use Arial if available\n",
    "plt.rcParams[\"font.family\"] = \"Arial\"\n",
    "plt.rcParams[\"axes.spines.right\"] = False\n",
    "plt.rcParams[\"axes.spines.top\"] = False\n",
    "\n",
    "# 1) Merge modules + clinical for alignment\n",
    "df_mod = pd.concat(\n",
    "    [\n",
    "        sat_scores.rename(\"SAT\"),\n",
    "        mpc_scores.rename(\"MPC\"),\n",
    "        il2_scores.rename(\"IL2\"),\n",
    "        ige_scores.rename(\"IGE\"),\n",
    "    ],\n",
    "    axis=1,\n",
    "    join=\"inner\",\n",
    ").dropna()\n",
    "\n",
    "print(\"[SCATTER] N with all 4 modules:\", df_mod.shape[0])\n",
    "\n",
    "# 2) Z-score each module\n",
    "def z(s):\n",
    "    sd = s.std(ddof=0)\n",
    "    return s*0 if (sd == 0 or np.isnan(sd)) else (s - s.mean()) / sd\n",
    "\n",
    "df_mod[\"SAT_Z\"] = z(df_mod[\"SAT\"])\n",
    "df_mod[\"MPC_Z\"] = z(df_mod[\"MPC\"])\n",
    "df_mod[\"IL2_Z\"] = z(df_mod[\"IL2\"])\n",
    "df_mod[\"IGE_Z\"] = z(df_mod[\"IGE\"])\n",
    "\n",
    "# 3) Define axes\n",
    "df_mod[\"MAL_Z\"]   = df_mod[\"SAT_Z\"] + df_mod[\"MPC_Z\"] - df_mod[\"IL2_Z\"]  # maladaptive, higher = worse\n",
    "df_mod[\"ADAPT_Z\"] = df_mod[\"IGE_Z\"]                                     # adaptive, higher = better\n",
    "\n",
    "# Medians for quadrant lines\n",
    "mal_med = df_mod[\"MAL_Z\"].median()\n",
    "ad_med  = df_mod[\"ADAPT_Z\"].median()\n",
    "\n",
    "# Optional quadrant labels\n",
    "def quadrant(r):\n",
    "    mal = \"High MAL\" if r[\"MAL_Z\"]   >= mal_med else \"Low MAL\"\n",
    "    ad  = \"High IGE\" if r[\"ADAPT_Z\"] >= ad_med  else \"Low IGE\"\n",
    "    return f\"{mal} / {ad}\"\n",
    "\n",
    "df_mod[\"quad\"] = df_mod.apply(quadrant, axis=1)\n",
    "\n",
    "# Colors per quadrant\n",
    "quad_colors = {\n",
    "    \"Low MAL / High IGE\":  \"#2b8cbe\",   # best prognosis (blue)\n",
    "    \"Low MAL / Low IGE\":   \"#a6bddb\",\n",
    "    \"High MAL / High IGE\": \"#fcae91\",\n",
    "    \"High MAL / Low IGE\":  \"#fb6a4a\",   # worst prognosis (red)\n",
    "}\n",
    "\n",
    "# 4) Scatter plot\n",
    "fig, ax = plt.subplots(figsize=(6.8, 6.2), dpi=160)\n",
    "\n",
    "for q, color in quad_colors.items():\n",
    "    sub = df_mod[df_mod[\"quad\"] == q]\n",
    "    ax.scatter(\n",
    "        sub[\"MAL_Z\"],\n",
    "        sub[\"ADAPT_Z\"],\n",
    "        s=28,\n",
    "        alpha=0.75,\n",
    "        color=color,\n",
    "        label=f\"{q} (n={len(sub)})\"\n",
    "    )\n",
    "\n",
    "# Median lines\n",
    "ax.axvline(mal_med, color=\"black\", lw=1.2, linestyle=\"--\", alpha=0.7)\n",
    "ax.axhline(ad_med,  color=\"black\", lw=1.2, linestyle=\"--\", alpha=0.7)\n",
    "\n",
    "ax.set_xlabel(\"Maladaptive burden (SAT + MPC − IL2)  — higher = worse\", fontsize=11)\n",
    "ax.set_ylabel(\"Adaptive housekeeping (IGE)  — higher = better\", fontsize=11)\n",
    "ax.set_title(\"TCGA-PAAD: Two-axis structure of PDAC transcriptional programs\", fontsize=13)\n",
    "ax.legend(frameon=False, fontsize=9, loc=\"upper left\")\n",
    "\n",
    "fig.tight_layout()\n",
    "out_path = Path.home() / \"Desktop\" / \"TCGA_PADD_MAL_vs_IGE_scatter.png\"\n",
    "fig.savefig(out_path, bbox_inches=\"tight\")\n",
    "plt.close(fig)\n",
    "\n",
    "print(f\"[OUTPUT] Saved scatter plot to: {out_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "505ab455",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N available: 177\n",
      "quad\n",
      "High MAL / High IGE    46\n",
      "Low MAL / Low IGE      45\n",
      "Low MAL / High IGE     43\n",
      "High MAL / Low IGE     43\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from lifelines import KaplanMeierFitter\n",
    "from lifelines.statistics import logrank_test\n",
    "\n",
    "# Output directory\n",
    "OUT = Path.home() / \"Desktop\" / \"PDAC_Fig6\"\n",
    "OUT.mkdir(exist_ok=True)\n",
    "\n",
    "# Font\n",
    "plt.rcParams[\"font.family\"] = \"Arial\"\n",
    "\n",
    "# Merge all modules + clinical for alignment\n",
    "df = pd.concat(\n",
    "    [\n",
    "        sat_scores.rename(\"SAT\"),\n",
    "        mpc_scores.rename(\"MPC\"),\n",
    "        il2_scores.rename(\"IL2\"),\n",
    "        ige_scores.rename(\"IGE\"),\n",
    "        clin[[\"OS_time_months\", \"OS_event\"]],\n",
    "    ],\n",
    "    axis=1,\n",
    "    join=\"inner\"\n",
    ").dropna()\n",
    "\n",
    "print(\"N available:\", df.shape[0])\n",
    "\n",
    "# Z-score all modules\n",
    "def z(s):\n",
    "    m, sd = s.mean(), s.std(ddof=0)\n",
    "    return (s - m) / sd if sd > 0 else s*0\n",
    "\n",
    "df[\"SAT_Z\"] = z(df[\"SAT\"])\n",
    "df[\"MPC_Z\"] = z(df[\"MPC\"])\n",
    "df[\"IL2_Z\"] = z(df[\"IL2\"])\n",
    "df[\"IGE_Z\"] = z(df[\"IGE\"])\n",
    "\n",
    "# Define axes\n",
    "df[\"MAL_Z\"]   = df[\"SAT_Z\"] + df[\"MPC_Z\"] - df[\"IL2_Z\"]      # maladaptive axis\n",
    "df[\"ADAPT_Z\"] = df[\"IGE_Z\"]                                   # adaptive / housekeeping axis\n",
    "\n",
    "# Median splits\n",
    "mal_med = df[\"MAL_Z\"].median()\n",
    "ad_med  = df[\"ADAPT_Z\"].median()\n",
    "\n",
    "def quad(row):\n",
    "    mal = \"High MAL\" if row[\"MAL_Z\"] >= mal_med else \"Low MAL\"\n",
    "    ad  = \"High IGE\" if row[\"ADAPT_Z\"] >= ad_med  else \"Low IGE\"\n",
    "    return f\"{mal} / {ad}\"\n",
    "\n",
    "df[\"quad\"] = df.apply(quad, axis=1)\n",
    "\n",
    "print(df[\"quad\"].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "224a1994",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FIG 6A — scatter of MAL_Z vs ADAPT_Z (quadrants)\n",
    "\n",
    "quad_colors = {\n",
    "    \"Low MAL / High IGE\":  \"#2b8cbe\",  # best prognosis (blue)\n",
    "    \"Low MAL / Low IGE\":   \"#9ecae1\",\n",
    "    \"High MAL / High IGE\": \"#fcae91\",\n",
    "    \"High MAL / Low IGE\":  \"#fb6a4a\",  # worst prognosis (red)\n",
    "}\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(6.5,6.0), dpi=160)\n",
    "\n",
    "for q, col in quad_colors.items():\n",
    "    sub = df[df[\"quad\"] == q]\n",
    "    ax.scatter(sub[\"MAL_Z\"], sub[\"ADAPT_Z\"], s=32, alpha=0.8, color=col, label=f\"{q} (n={len(sub)})\")\n",
    "\n",
    "# Median lines\n",
    "ax.axvline(mal_med, color=\"black\", lw=1.1, ls=\"--\", alpha=0.6)\n",
    "ax.axhline(ad_med,  color=\"black\", lw=1.1, ls=\"--\", alpha=0.6)\n",
    "\n",
    "ax.set_xlabel(\"Maladaptive burden (SAT_Z + MPC_Z − IL2_Z)\", fontsize=12)\n",
    "ax.set_ylabel(\"Adaptive housekeeping (IGE_Z)\", fontsize=12)\n",
    "ax.set_title(\"Figure 6A — Two functional axes of PDAC adaptation\", fontsize=13)\n",
    "ax.legend(frameon=False, fontsize=9, loc=\"upper left\")\n",
    "\n",
    "fig.tight_layout()\n",
    "fig.savefig(OUT / \"Fig6A_scatter_axes.png\", bbox_inches=\"tight\")\n",
    "plt.close(fig)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "bd5158f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ANNOT] using ID col: ID | Symbol col: Gene Symbol | rows: 54675\n",
      "KRT17 → False\n",
      "GATA6 → False\n",
      "MTHFD2 → False\n",
      "ID2 → False\n"
     ]
    }
   ],
   "source": [
    "print(\"[ANNOT] using ID col:\", id_col, \"| Symbol col:\", sym_col, \"| rows:\", len(anno))\n",
    "assert expr_sym.shape[0] > 0 and expr_sym.shape[1] > 0, \"Symbol matrix is empty after mapping.\"\n",
    "for g in [\"KRT17\",\"GATA6\",\"MTHFD2\",\"ID2\"]:\n",
    "    print(g, \"→\", g in expr_sym.index)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8b50676f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[RAW] shape: (49386, 309)\n",
      "[RAW] example columns: ['PANC102', 'PANC103', 'PANC104', 'PANC105', 'PANC106', 'PANC107', 'PANC108', 'PANC109', 'PANC110', 'PANC111']\n",
      "[STEP] probes×samples after assay remap: (49386, 309)\n",
      "[ANNOT] using ID col: ID | Symbol col: Gene Symbol | rows: 49386\n",
      "[MAP] Probe rows with ≥1 symbol: 48673 matching probes of 49386 (~98.6%).\n",
      "[STEP] symbols×samples: (20182, 309)\n",
      "KRT17 in expr_sym? True\n",
      "GATA6 in expr_sym? True\n",
      "MTHFD2 in expr_sym? True\n",
      "ID2 in expr_sym? True\n",
      "HIST1H3G in expr_sym? True\n",
      "✅ Saved: /Users/scottpowers/Desktop/E-MTAB-6134_expression_GENESxASSAY.csv\n",
      "✅ Saved: /Users/scottpowers/Desktop/E-MTAB-6134_expression_GENESxASSAY_with_gene_symbol_col.csv\n",
      "[COVERAGE] SAT up 112 / 185 | down 15 / 25\n",
      "[MERGE] N = 288\n",
      "[SAT] lowest 5: [('G047678_C07', -1.2835547656656825), ('B00212558.C22_C02', -1.0775002499936461), ('A2299_050', -0.8433922927205977), ('H08C7056_A02', -0.8186897380064072), ('G014418_G01', -0.7374385476688932)]\n",
      "[SAT] highest 5: [('B00190698.B5_A09', 0.7329528356944204), ('A2299_051', 0.7464374991559077), ('H06C16746_D07', 0.8567014971473941), ('G047936_H12', 0.8686473441164104), ('H08C1912_D04', 1.0520937514723627)]\n"
     ]
    }
   ],
   "source": [
    "# --- E-MTAB-6134 (HG-U219/GPL13667): probes→symbols (multi-symbol), remap to Assay, save, score SAT, merge survival ---\n",
    "\n",
    "import re, pandas as pd, numpy as np\n",
    "from pathlib import Path\n",
    "import io, gzip\n",
    "\n",
    "# ===== Paths =====\n",
    "DESKTOP = Path(\"~/Desktop\").expanduser()\n",
    "SDRF = DESKTOP / \"E-MTAB-6134.sdrf.txt\"\n",
    "UNZ  = DESKTOP / \"E-MTAB-6134_processed\" / \"unzipped\"\n",
    "RAW  = UNZ / \"ProcessedExpression.tsv\"                  # from the zip\n",
    "SURV = DESKTOP / \"Puleo_survival_from_SDRF.csv\"\n",
    "ANNO = DESKTOP / \"GPL13667-15572.txt\"                  # <-- your HG-U219 annotation\n",
    "\n",
    "assert RAW.exists(), f\"Missing {RAW}\"\n",
    "assert SDRF.exists(), f\"Missing {SDRF}\"\n",
    "assert SURV.exists(), f\"Missing {SURV}\"\n",
    "assert ANNO.exists(), f\"Missing annotation: {ANNO}\"\n",
    "\n",
    "# ===== Load SDRF and helpers (PANC### → Assay Name) =====\n",
    "sdrf = pd.read_csv(SDRF, sep=\"\\t\", dtype=str).fillna(\"\")\n",
    "assay_col = \"Assay Name\" if \"Assay Name\" in sdrf.columns else None\n",
    "if assay_col is None:\n",
    "    for c in [\"Sample Name\",\"Source Name\"]:\n",
    "        if c in sdrf.columns: assay_col = c; break\n",
    "if assay_col is None:\n",
    "    raise ValueError(\"No Assay/Sample ID column found in SDRF.\")\n",
    "\n",
    "ASSAYS = set(sdrf[assay_col].astype(str).str.strip())\n",
    "PANC_RE = re.compile(r\"^PANC\\d+$\", re.I)\n",
    "\n",
    "panc_map = {}\n",
    "for c in sdrf.columns:\n",
    "    if c == assay_col: \n",
    "        continue\n",
    "    ser = sdrf[c].astype(str)\n",
    "    mask = ser.str.match(PANC_RE, na=False)\n",
    "    if mask.any():\n",
    "        sub = sdrf.loc[mask, [c, assay_col]]\n",
    "        for _, row in sub.iterrows():\n",
    "            panc_map[str(row[c]).strip()] = str(row[assay_col]).strip()\n",
    "\n",
    "def to_assay(colname: str) -> str:\n",
    "    c = str(colname).strip()\n",
    "    if c in ASSAYS: \n",
    "        return c\n",
    "    if PANC_RE.match(c) and c in panc_map:\n",
    "        return panc_map[c]\n",
    "    return c  # leave as-is\n",
    "\n",
    "# ===== 1) Load ProcessedExpression as probes × samples =====\n",
    "df = pd.read_csv(RAW, sep=\"\\t\", index_col=0)\n",
    "print(\"[RAW] shape:\", df.shape)\n",
    "print(\"[RAW] example columns:\", df.columns[:10].tolist())\n",
    "if df.shape[0] == 0 or df.shape[1] == 0:\n",
    "    raise RuntimeError(\"ProcessedExpression.tsv loaded empty; check the file.\")\n",
    "\n",
    "# coerce numeric\n",
    "df = df.apply(pd.to_numeric, errors=\"coerce\")\n",
    "\n",
    "# ===== 2) Remap columns PANC### → Assay Name and collapse duplicate assays =====\n",
    "df.columns = [to_assay(c) for c in map(str, df.columns)]\n",
    "expr_probes = (df.T.groupby(level=0).mean(numeric_only=True)).T\n",
    "expr_probes.index = expr_probes.index.astype(str).str.strip().str.lower()  # match annot casing\n",
    "print(\"[STEP] probes×samples after assay remap:\", expr_probes.shape)\n",
    "\n",
    "# ===== 3) Probe → Symbol using GPL13667 (skip '#' comment lines; multi-symbol aware) =====\n",
    "def _parse_symbol_tokens(s: str) -> list[str]:\n",
    "    if s is None:\n",
    "        return []\n",
    "    s = str(s).strip()\n",
    "    if not s or s in {\"---\",\".\",\"NA\",\"na\",\"NaN\"}:\n",
    "        return []\n",
    "    s = (s.replace(\"///\",\"|\").replace(\"//\",\"|\").replace(\";\", \"|\")\n",
    "           .replace(\",\", \"|\").replace(\"\\t\",\"|\"))\n",
    "    toks = [t.strip().upper() for t in s.split(\"|\") if t.strip()]\n",
    "    toks = [re.sub(r\"\\.\\d+$\",\"\", t) for t in toks]  # drop trailing .1, .2\n",
    "    ok = [t for t in toks if re.fullmatch(r\"[A-Z0-9][A-Z0-9\\.\\-]{1,19}\", t)]\n",
    "    if not ok:\n",
    "        return []\n",
    "    non_mi = [t for t in ok if not t.startswith(\"MIR\")]\n",
    "    return non_mi if non_mi else ok\n",
    "\n",
    "# Read annotation: tab-delimited, with many '#' comment lines to skip\n",
    "anno = pd.read_csv(ANNO, sep=\"\\t\", dtype=str, comment=\"#\", engine=\"python\")\n",
    "norm_cols = {re.sub(r\"\\W+\",\"\", c).lower(): c for c in anno.columns}\n",
    "\n",
    "id_col = None\n",
    "for k in [\"id\",\"probesetid\",\"probeset\",\"probesetname\",\"probe_set_id\"]:\n",
    "    if k in norm_cols: id_col = norm_cols[k]; break\n",
    "sym_col = None\n",
    "for k in [\"genesymbol\",\"symbol\",\"gene_symbol\",\"hugosymbol\",\"hgnc\"]:\n",
    "    if k in norm_cols: sym_col = norm_cols[k]; break\n",
    "if not id_col or not sym_col:\n",
    "    raise ValueError(f\"Could not find ID/Symbol columns in {ANNO.name}\")\n",
    "\n",
    "print(f\"[ANNOT] using ID col: {id_col} | Symbol col: {sym_col} | rows: {len(anno)}\")\n",
    "\n",
    "map_df = anno[[id_col, sym_col]].rename(columns={id_col:\"probe_id\", sym_col:\"gene_symbol_raw\"}).dropna()\n",
    "map_df[\"probe_id\"] = map_df[\"probe_id\"].astype(str).str.strip().str.lower()\n",
    "map_df[\"gene_symbol\"] = map_df[\"gene_symbol_raw\"].map(_parse_symbol_tokens)\n",
    "map_df = map_df.explode(\"gene_symbol\").dropna(subset=[\"gene_symbol\"]).drop_duplicates(subset=[\"probe_id\",\"gene_symbol\"])\n",
    "\n",
    "present_mask = map_df[\"probe_id\"].isin(expr_probes.index)\n",
    "map_df_present = map_df.loc[present_mask].copy()\n",
    "den = max(1, expr_probes.shape[0])\n",
    "print(f\"[MAP] Probe rows with ≥1 symbol: {map_df_present['probe_id'].nunique()} \"\n",
    "      f\"matching probes of {expr_probes.shape[0]} (~{map_df_present['probe_id'].nunique()/den:.1%}).\")\n",
    "\n",
    "if map_df_present.empty:\n",
    "    # show a few probes for debugging if needed\n",
    "    check = [(p, p in set(map_df['probe_id'])) for p in expr_probes.index[:10]]\n",
    "    print(\"[DEBUG] first 10 probes present in annotation?:\", check)\n",
    "    raise RuntimeError(\"No probe IDs from the matrix matched the annotation indices. Check file & casing.\")\n",
    "\n",
    "# Join expression, replicate rows for multi-symbol probes, then collapse to symbol median\n",
    "df_sym = expr_probes.loc[map_df_present[\"probe_id\"].unique()].copy()\n",
    "df_sym = df_sym.join(map_df_present.set_index(\"probe_id\")[\"gene_symbol\"], how=\"left\")\n",
    "expr_sym = df_sym.groupby(\"gene_symbol\").median(numeric_only=True)\n",
    "expr_sym.index = expr_sym.index.str.upper()\n",
    "print(\"[STEP] symbols×samples:\", expr_sym.shape)\n",
    "\n",
    "# quick sanity for a few genes (KRT17 is on HG-U219 as 205157_s_at with 'JUP /// KRT17')\n",
    "for g in [\"KRT17\",\"GATA6\",\"MTHFD2\",\"ID2\",\"HIST1H3G\"]:\n",
    "    print(g, \"in expr_sym?\", g in expr_sym.index)\n",
    "assert expr_sym.shape[0] > 0 and expr_sym.shape[1] > 0, \"Symbol matrix is empty after mapping.\"\n",
    "\n",
    "# ===== 4) Save matrices (with and without explicit gene_symbol column) =====\n",
    "sym_out_idx = DESKTOP / \"E-MTAB-6134_expression_GENESxASSAY.csv\"\n",
    "expr_sym.to_csv(sym_out_idx)\n",
    "expr_sym_col = expr_sym.copy()\n",
    "expr_sym_col.insert(0, \"gene_symbol\", expr_sym_col.index.astype(str))\n",
    "sym_out_col = DESKTOP / \"E-MTAB-6134_expression_GENESxASSAY_with_gene_symbol_col.csv\"\n",
    "expr_sym_col.to_csv(sym_out_col, index=False)\n",
    "print(\"✅ Saved:\", sym_out_idx)\n",
    "print(\"✅ Saved:\", sym_out_col)\n",
    "\n",
    "# ===== 5) SAT scoring =====\n",
    "SAT_UP = [\n",
    "    \"ABHD8\",\"AC004870.4\",\"AC005920.1\",\"AC009041.1\",\"AC009309.1\",\"AC011498.1\",\"AC012447.1\",\"AC018521.5\",\n",
    "    \"AC018754.1\",\"AC027237.2\",\"AC068338.2\",\"AC072061.1\",\"AC079305.3\",\"AC079807.1\",\"AC087623.2\",\"AC090403.1\",\n",
    "    \"AC091271.1\",\"AC092287.1\",\"AC092910.3\",\"AC093323.1\",\"AC099778.1\",\"AC107959.2\",\"AC125611.3\",\"AC144652.1\",\n",
    "    \"AC239799.2\",\"AC253572.2\",\"ACBD7\",\"AFMID\",\"AHCY\",\"AL021155.5\",\"AL022069.1\",\"AL031963.3\",\"AL049869.2\",\n",
    "    \"AL121574.1\",\"AL133523.1\",\"AL139106.1\",\"AL139246.5\",\"AL355075.4\",\"AL360012.1\",\"AL365436.2\",\"AL592295.5\",\n",
    "    \"AL662844.4\",\"AP001160.1\",\"AP002381.2\",\"AP002813.1\",\"ARL4D\",\"ATP2B1-AS1\",\"ATRIP\",\"BAMBI\",\"BHLHE40-AS1\",\n",
    "    \"BOLA1\",\"BUD23\",\"C12orf65\",\"C19orf48\",\"C2CD4B\",\"C6orf120\",\"CABYR\",\"CCDC9\",\"CCNE2\",\"CDKN2AIP\",\"CHCHD7\",\n",
    "    \"CITED2\",\"CROCC\",\"CSKMT\",\"CTH\",\"DALRD3\",\"DRAIC\",\"DUSP28\",\"EAF2\",\"EIF4A3\",\"FOXA3\",\"FOXL1\",\"GADD45B\",\"GLA\",\n",
    "    \"GOT1\",\"GRPEL1\",\"GTF2A1\",\"GTF2B\",\"HEXIM1\",\"HIST1H2AG\",\"HIST1H2AH\",\"HIST1H2AL\",\"HIST1H2BJ\",\"HIST1H2BN\",\n",
    "    \"HIST1H3A\",\"HIST1H3J\",\"HIST1H4A\",\"HIST1H4C\",\"HIST1H4E\",\"HIST2H2AC\",\"HIST2H3PS2\",\"HIST3H2A\",\"HIST4H4\",\"HMBS\",\n",
    "    \"HSPA2\",\"ID2\",\"IDI1\",\"ING1\",\"KCTD5\",\"KIF9\",\"KLHL11\",\"LAP3\",\"LIFR-AS1\",\"LINC01970\",\"LINC02029\",\"LINC02363\",\n",
    "    \"LRG1\",\"LRTOMT\",\"MAFB\",\"MED29\",\"MEPCE\",\"MIR17HG\",\"MORF4L2-AS1\",\"MTHFD2\",\"MYCL\",\"MYOSLID\",\"NANOS1\",\"NPW\",\n",
    "    \"NRARP\",\"OAT\",\"OSER1-DT\",\"OSGIN1\",\"PHYH\",\"PICART1\",\"PIEZO1\",\"PIK3R3\",\"PLIN5\",\"PLK2\",\"PMAIP1\",\"PMEL\",\"PNKD\",\n",
    "    \"POU3F1\",\"PPP1R3C\",\"PRMT5-AS1\",\"PRR3\",\"PTCH2\",\"PTPN6\",\"RAB26\",\"RALY-AS1\",\"RASL11A\",\"RND1\",\"RNF223\",\"RUVBL2\",\n",
    "    \"SAE1\",\"SENP8\",\"SIAH2-AS1\",\"SIRT2\",\"SLC7A5\",\"SNHG12\",\"SNHG5\",\"SNHG8\",\"SREBF2-AS1\",\"SRSF7\",\"STARD5\",\"TBPL1\",\n",
    "    \"TCTA\",\"THAP9\",\"TLCD1\",\"TM7SF2\",\"TMEM107\",\"TMEM171\",\"TMEM69\",\"TNFRSF10D\",\"TNK1\",\"TRAM2-AS1\",\"TTC33\",\"UAP1\",\n",
    "    \"UBAC2-AS1\",\"UBE2D3-AS1\",\"UBE2S\",\"UGDH\",\"WDR74\",\"Z93241.1\",\"Z99127.4\",\"ZC3H10\",\"ZCWPW1\",\"ZFAS1\",\"ZFX-AS1\",\n",
    "    \"ZNF574\",\"ZNF584\",\"ZNF622\",\"ZNF687-AS1\",\"ZNF844\",\"ZNF92\",\"ZSWIM3\"\n",
    "]\n",
    "SAT_DOWN = [\n",
    "    \"PAX5\",\"AC117386.2\",\"PRSS55\",\"RPS16\",\"GDF7\",\"PAK4\",\"AC022144.1\",\"AC092745.5\",\"AL670729.3\",\n",
    "    \"DLEU2L\",\"ELP3\",\"KCNC2\",\"MAP4K1\",\"AL161729.4\",\"SV2C\",\"RGS11\",\"AC005498.1\",\"WFDC5\",\"PSENEN\",\n",
    "    \"LINC01956\",\"AC115485.1\",\"CYSLTR2\",\"ASMTL-AS1\",\"AP002001.3\",\"FAM153B\"\n",
    "]\n",
    "SAT_UP = [g.strip().upper() for g in SAT_UP]\n",
    "SAT_DOWN = [g.strip().upper() for g in SAT_DOWN]\n",
    "\n",
    "def score_signed(expr_df, up_genes, down_genes, min_genes=10):\n",
    "    # Row-wise Z\n",
    "    mu = expr_df.mean(axis=1)\n",
    "    sd = expr_df.std(axis=1, ddof=0).replace(0, np.nan)\n",
    "    Z = expr_df.sub(mu, axis=0).div(sd, axis=0)\n",
    "\n",
    "    up = pd.Index(up_genes).intersection(Z.index)\n",
    "    dn = pd.Index(down_genes).intersection(Z.index)\n",
    "    cov = {\"up_used\": int(up.size), \"up_total\": len(up_genes),\n",
    "           \"down_used\": int(dn.size), \"down_total\": len(down_genes)}\n",
    "    if up.size < min_genes or dn.size < min_genes:\n",
    "        print(f\"[COVERAGE] SAT up {cov['up_used']} / {cov['up_total']} | down {cov['down_used']} / {cov['down_total']} (insufficient)\")\n",
    "        return pd.Series(np.nan, index=Z.columns, name=\"SAT\"), cov\n",
    "    score = Z.loc[up].mean(axis=0) - Z.loc[dn].mean(axis=0)\n",
    "    score.name = \"SAT\"\n",
    "    print(f\"[COVERAGE] SAT up {cov['up_used']} / {cov['up_total']} | down {cov['down_used']} / {cov['down_total']}\")\n",
    "    return score, cov\n",
    "\n",
    "sat_scores, cov = score_signed(expr_sym, SAT_UP, SAT_DOWN, min_genes=10)\n",
    "\n",
    "# ===== 6) Survival merge =====\n",
    "surv = pd.read_csv(SURV, index_col=0)\n",
    "surv.index = pd.Index([to_assay(str(x).strip()) for x in surv.index], name=\"Assay Name\")\n",
    "merged = pd.concat([sat_scores.rename(\"SAT\"), surv[[\"time_months\",\"event\"]]], axis=1, join=\"inner\").dropna()\n",
    "print(\"[MERGE] N =\", merged.shape[0])\n",
    "\n",
    "# ===== Quick diags =====\n",
    "if sat_scores.notna().any():\n",
    "    s = sat_scores.dropna().sort_values()\n",
    "    print(\"[SAT] lowest 5:\", list(zip(s.index[:5], s.values[:5])))\n",
    "    print(\"[SAT] highest 5:\", list(zip(s.index[-5:], s.values[-5:])))\n",
    "else:\n",
    "    print(\"Expr symbols:\", expr_sym.shape[0], \"Assays:\", expr_sym.shape[1])\n",
    "    print(\"UP found:\", sum(g in expr_sym.index for g in SAT_UP), \"/\", len(SAT_UP))\n",
    "    print(\"DN found:\", sum(g in expr_sym.index for g in SAT_DOWN), \"/\", len(SAT_DOWN))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "35d6e0ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "expr_sym.to_csv(DESKTOP / \"E-MTAB-6134_expr_SYMBOLSxASSAY.csv\")\n",
    "pd.concat([sat_scores.rename(\"SAT\")], axis=1).to_csv(DESKTOP / \"E-MTAB-6134_SAT_scores.csv\")\n",
    "merged.to_csv(DESKTOP / \"E-MTAB-6134_SAT_survival_merged.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d288c9a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing SAT_UP: 73 → ['AC004870.4', 'AC005920.1', 'AC009041.1', 'AC009309.1', 'AC011498.1', 'AC012447.1', 'AC018521.5', 'AC018754.1', 'AC027237.2', 'AC068338.2', 'AC072061.1', 'AC079305.3', 'AC079807.1', 'AC087623.2', 'AC090403.1']\n",
      "Missing SAT_DOWN: 10 → ['AC005498.1', 'AC022144.1', 'AC092745.5', 'AC115485.1', 'AC117386.2', 'AL161729.4', 'AL670729.3', 'AP002001.3', 'ASMTL-AS1', 'LINC01956']\n"
     ]
    }
   ],
   "source": [
    "missing_up  = sorted(set(SAT_UP)   - set(expr_sym.index))\n",
    "missing_down= sorted(set(SAT_DOWN) - set(expr_sym.index))\n",
    "print(\"Missing SAT_UP:\", len(missing_up), \"→\", missing_up[:15])\n",
    "print(\"Missing SAT_DOWN:\", len(missing_down), \"→\", missing_down[:15])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0ab673ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "event\n",
      "0.0    288\n",
      "Name: count, dtype: int64\n",
      "event\n",
      "0    288\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "surv = pd.read_csv(SURV, index_col=0)\n",
    "\n",
    "# inspect unique event values\n",
    "print(surv[\"event\"].value_counts(dropna=False))\n",
    "\n",
    "# map common patterns to 0/1\n",
    "m = {\"dead\": 1, \"death\": 1, \"deceased\": 1, \"true\": 1, \"1\": 1,\n",
    "     \"alive\": 0, \"censored\": 0, \"false\": 0, \"0\": 0, \"\": 0}\n",
    "surv[\"event\"] = surv[\"event\"].astype(str).str.strip().str.lower().map(m).fillna(0).astype(int)\n",
    "\n",
    "print(surv[\"event\"].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a496e247",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[KM] events value_counts: {0: 288}\n",
      "[KM] time range (months): 1.12 → 146.4\n",
      "[KM] No events present; KM curves will be flat at 1.0\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 700x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# --- 1) Coerce event to 0/1 robustly ---\n",
    "_event = merged[\"event\"]\n",
    "if _event.dtype == object:\n",
    "    m = {\n",
    "        \"dead\": 1, \"death\": 1, \"deceased\": 1, \"event\": 1, \"true\": 1, \"1\": 1, 1: 1,\n",
    "        \"alive\": 0, \"censored\": 0, \"false\": 0, \"0\": 0, 0: 0, \"na\": 0, \"\": 0\n",
    "    }\n",
    "    ev = _event.astype(str).str.strip().str.lower().map(m).astype(float)\n",
    "else:\n",
    "    ev = pd.to_numeric(_event, errors=\"coerce\").fillna(0.0)\n",
    "\n",
    "ev = (ev > 0).astype(int)  # ensure 0/1\n",
    "tm = pd.to_numeric(merged[\"time_months\"], errors=\"coerce\")\n",
    "\n",
    "merged = merged.assign(event=ev, time_months=tm).dropna(subset=[\"time_months\",\"event\"])\n",
    "\n",
    "# Quick sanity prints\n",
    "print(\"[KM] events value_counts:\", merged[\"event\"].value_counts().to_dict())\n",
    "print(\"[KM] time range (months):\", float(merged[\"time_months\"].min()), \"→\", float(merged[\"time_months\"].max()))\n",
    "\n",
    "# If no events, KM will be flat by definition\n",
    "if merged[\"event\"].sum() == 0:\n",
    "    print(\"[KM] No events present; KM curves will be flat at 1.0\")\n",
    "    \n",
    "# --- 2) Tertile groups from SAT ---\n",
    "low_cut  = merged[\"SAT\"].quantile(1/3)\n",
    "high_cut = merged[\"SAT\"].quantile(2/3)\n",
    "\n",
    "def _sat_group(x):\n",
    "    if x <= low_cut:  return \"Low SAT\"\n",
    "    if x >= high_cut: return \"High SAT\"\n",
    "    return \"Mid SAT\"\n",
    "\n",
    "merged[\"SAT_group\"] = merged[\"SAT\"].apply(_sat_group)\n",
    "\n",
    "# --- 3) KM estimator at unique times ---\n",
    "def km_from_times_events(times: pd.Series, events: pd.Series):\n",
    "    \"\"\"Return stepwise KM curve: unique times, survival probs (post step).\"\"\"\n",
    "    # sort by time\n",
    "    ord_idx = np.argsort(times.values)\n",
    "    t = times.values[ord_idx]\n",
    "    e = events.values[ord_idx].astype(int)\n",
    "\n",
    "    # unique event/censor times\n",
    "    uniq_t, idx_start = np.unique(t, return_index=True)\n",
    "    # counts at each time\n",
    "    d_at_t = np.zeros_like(uniq_t, dtype=float)  # events\n",
    "    n_at_t = np.zeros_like(uniq_t, dtype=float)  # at risk just before time\n",
    "\n",
    "    # precompute counts <= each time (cum)\n",
    "    # n_at_risk at time u is # with time >= u\n",
    "    # compute cumulative number with time < u, then n_at_risk = N - cum\n",
    "    N = len(t)\n",
    "    # counts exactly at each unique time\n",
    "    counts_at_t = np.diff(np.append(idx_start, len(t)))\n",
    "    # events exactly at each unique time\n",
    "    # for each block of identical times, sum e\n",
    "    e_cumsum = np.cumsum(e)\n",
    "    prev_end = 0\n",
    "    for i, start in enumerate(idx_start):\n",
    "        end = start + counts_at_t[i]\n",
    "        d_at_t[i] = e_cumsum[end-1] - (e_cumsum[prev_end-1] if prev_end>0 else 0)\n",
    "        prev_end = end\n",
    "    # n_at_t computed from counts of times < u\n",
    "    cum_counts_before = np.cumsum(np.append([0], counts_at_t[:-1]))\n",
    "    n_at_t = N - cum_counts_before\n",
    "\n",
    "    # KM product\n",
    "    S = np.ones_like(uniq_t, dtype=float)\n",
    "    surv = 1.0\n",
    "    for i in range(len(uniq_t)):\n",
    "        if n_at_t[i] > 0:\n",
    "            surv *= (n_at_t[i] - d_at_t[i]) / n_at_t[i]\n",
    "        S[i] = surv\n",
    "\n",
    "    # build step arrays for plotting (start at 0 with 1.0)\n",
    "    step_t = np.concatenate([[0.0], uniq_t])\n",
    "    step_s = np.concatenate([[1.0], S])\n",
    "    return step_t, step_s\n",
    "\n",
    "# --- 4) Plot KM for tertiles ---\n",
    "plt.figure(figsize=(7,5))\n",
    "for grp in [\"Low SAT\", \"Mid SAT\", \"High SAT\"]:\n",
    "    sub = merged.loc[merged[\"SAT_group\"] == grp, [\"time_months\",\"event\"]].dropna()\n",
    "    if sub.empty:\n",
    "        continue\n",
    "    t, s = km_from_times_events(sub[\"time_months\"], sub[\"event\"])\n",
    "    plt.step(t, s, where=\"post\", label=f\"{grp} (n={len(sub)})\")\n",
    "\n",
    "plt.title(\"Kaplan–Meier survival by SAT tertiles\")\n",
    "plt.xlabel(\"Time (months)\")\n",
    "plt.ylabel(\"Survival probability\")\n",
    "plt.legend()\n",
    "plt.grid(alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "286d3906",
   "metadata": {},
   "source": [
    "## 3) Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "628b92f7",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unexpected character after line continuation character (2253102615.py, line 30)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[36], line 30\u001b[0;36m\u001b[0m\n\u001b[0;31m    \\\"\\\"\\\"expr: genes x samples -> returns modules x samples.\\\"\\\"\\\"\u001b[0m\n\u001b[0m     ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unexpected character after line continuation character\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from __future__ import annotations\n",
    "import numpy as np\n",
    "from typing import Dict, List\n",
    "from scipy import stats\n",
    "\n",
    "# Optional packages\n",
    "try:\n",
    "    import gseapy as gp\n",
    "except Exception:\n",
    "    gp = None\n",
    "\n",
    "def bh_fdr(p: pd.Series) -> pd.Series:\n",
    "    p = pd.Series(p).astype(float)\n",
    "    n = p.notna().sum()\n",
    "    order = p.sort_values().index\n",
    "    ranks = pd.Series(range(1, n + 1), index=order)\n",
    "    q = p.copy()\n",
    "    q.loc[order] = (p.loc[order] * n / ranks).cummin().clip(upper=1.0)\n",
    "    return q\n",
    "\n",
    "def zscore_mat(M: pd.DataFrame, axis: int = 0) -> pd.DataFrame:\n",
    "    return M.apply(lambda x: (x - x.mean()) / (x.std(ddof=0) + 1e-9), axis=axis)\n",
    "\n",
    "def intersect_genes(genes: List[str], ref_index: pd.Index) -> List[str]:\n",
    "    s = pd.Index(genes).dropna().astype(str)\n",
    "    inter = s.intersection(ref_index.astype(str))\n",
    "    return inter.tolist()\n",
    "\n",
    "def module_scores_ssgsea(expr: pd.DataFrame, modules: Dict[str, List[str]], force_mean_z: bool=False) -> pd.DataFrame:\n",
    "    \\\"\\\"\\\"expr: genes x samples -> returns modules x samples.\\\"\\\"\\\"\n",
    "    if force_mean_z or gp is None:\n",
    "        Z = zscore_mat(expr, axis=1)\n",
    "        out = {}\n",
    "        for m, g in modules.items():\n",
    "            keep = intersect_genes(g, Z.index)\n",
    "            out[m] = Z.loc[keep].mean(axis=0)\n",
    "        return pd.DataFrame(out).T\n",
    "\n",
    "    x = expr.T\n",
    "    ss = gp.ssgsea(data=x, gene_sets=modules, sample_norm_method=None, outdir=None, processes=4, format=\"png\")\n",
    "    df = pd.DataFrame({k: pd.Series(v) for k, v in ss.res2dn.items()}).T\n",
    "    return df\n",
    "\n",
    "def corr_against_matrix(module_scores: pd.Series, M: pd.DataFrame, method: str = \"spearman\") -> pd.DataFrame:\n",
    "    common = module_scores.index.intersection(M.columns)\n",
    "    if len(common) < 5:\n",
    "        raise ValueError(\"Too few overlapping samples for correlation.\")\n",
    "    y = module_scores.loc[common]\n",
    "    X = M.loc[:, common]\n",
    "\n",
    "    rs, ps, feats = [], [], []\n",
    "    for feat, row in X.iterrows():\n",
    "        feats.append(feat)\n",
    "        if method == \"spearman\":\n",
    "            r, p = stats.spearmanr(row.values, y.values, nan_policy='omit')\n",
    "        else:\n",
    "            r, p = stats.pearsonr(row.values, y.values)\n",
    "        rs.append(r); ps.append(p)\n",
    "    out = pd.DataFrame({\"rho\": rs, \"p\": ps}, index=feats)\n",
    "    out[\"q\"] = bh_fdr(out[\"p\"])\n",
    "    return out.sort_values(\"rho\", ascending=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e9a7390",
   "metadata": {},
   "source": [
    "## 4) DepMap integration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63fdb982",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "# ==================== CONFIG ====================\n",
    "BASE = Path(\"~/Desktop\").expanduser()\n",
    "MATRIX_PATH = BASE / \"gene_dependency_matrix.csv\"   # your ACH-xxx gene dependency file\n",
    "OUT_PATH    = BASE / \"gene_dependency_with_names.csv\"\n",
    "\n",
    "# --- Manual mapping (from your list) ---\n",
    "mapping_dict = {\n",
    "    \"ACH-000022\": \"PATU8988S\",\n",
    "    \"ACH-000023\": \"PATU8988T\",\n",
    "    \"ACH-000094\": \"HPAFII\",\n",
    "    \"ACH-000108\": \"KP3\",\n",
    "    \"ACH-000114\": \"SU8686\",\n",
    "    \"ACH-000118\": \"HUPT3\",\n",
    "    \"ACH-000138\": \"CFPAC1\",\n",
    "    \"ACH-000178\": \"HS766T\",\n",
    "    \"ACH-000205\": \"PK59\",\n",
    "    \"ACH-000213\": \"HUPT4\",\n",
    "    \"ACH-000222\": \"ASPC1\",\n",
    "    \"ACH-000265\": \"KP4\",\n",
    "    \"ACH-000307\": \"PK1\",\n",
    "    \"ACH-000332\": \"YAPC\",\n",
    "    \"ACH-000354\": \"CAPAN1\",\n",
    "    \"ACH-000502\": \"TCCPAN2\",\n",
    "    \"ACH-000517\": \"SNU410\",\n",
    "    \"ACH-000652\": \"SUIT2\",\n",
    "    \"ACH-000685\": \"L33\",\n",
    "    \"ACH-001376\": \"PACADD135\",\n",
    "    \"ACH-001379\": \"PACADD161\",\n",
    "    \"ACH-001380\": \"PACADD165\",\n",
    "    \"ACH-001382\": \"PACADD188\",\n",
    "    \"ACH-002039\": \"PK8\",\n",
    "    \"ACH-003161\": \"ABMT9430\",\n",
    "    \"ACH-003433\": \"CCLFPANC0019T\"\n",
    "}\n",
    "\n",
    "# ==================== LOAD MATRIX ====================\n",
    "df = pd.read_csv(MATRIX_PATH, index_col=0)\n",
    "df.index = df.index.astype(str).str.strip()\n",
    "\n",
    "# Map to cell line names, fallback to ACH ID if not found\n",
    "df.insert(0, \"cell_line_name\", df.index.map(lambda x: mapping_dict.get(x, x)))\n",
    "\n",
    "# Optional: reorder columns so cell line name comes first\n",
    "cols = [\"cell_line_name\"] + [c for c in df.columns if c != \"cell_line_name\"]\n",
    "df = df[cols]\n",
    "\n",
    "# ==================== SAVE ====================\n",
    "df.to_csv(OUT_PATH)\n",
    "print(f\"✅ Saved mapped file with cell line names: {OUT_PATH}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87cc543b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "from pathlib import Path\n",
    "import re\n",
    "\n",
    "# ==================== CONFIG ====================\n",
    "BASE = Path(\"~/Desktop\").expanduser()\n",
    "EXPR  = BASE / \"PDAC_celllines_expression.csv\"     # may be genes×lines OR lines×genes\n",
    "PRISM = BASE / \"PRISM_AUC_PDAC_matrix.csv\"         # drugs × cell lines (IDs or names)\n",
    "OUTDIR = BASE / \"prism_module_from_expression_out\"\n",
    "OUTDIR.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "# === DepMap_ID → human-readable cell line name (PDAC panel) ===\n",
    "CELLNAME_MAP = {\n",
    "    \"ACH-000022\": \"PATU8988S\",\n",
    "    \"ACH-000023\": \"PATU8988T\",\n",
    "    \"ACH-000094\": \"HPAFII\",\n",
    "    \"ACH-000108\": \"KP3\",\n",
    "    \"ACH-000114\": \"SU8686\",\n",
    "    \"ACH-000118\": \"HUPT3\",\n",
    "    \"ACH-000138\": \"CFPAC1\",\n",
    "    \"ACH-000178\": \"HS766T\",\n",
    "    \"ACH-000205\": \"PK59\",\n",
    "    \"ACH-000213\": \"HUPT4\",\n",
    "    \"ACH-000222\": \"ASPC1\",\n",
    "    \"ACH-000265\": \"KP4\",\n",
    "    \"ACH-000307\": \"PK1\",\n",
    "    \"ACH-000332\": \"YAPC\",\n",
    "    \"ACH-000354\": \"CAPAN1\",\n",
    "    \"ACH-000502\": \"TCCPAN2\",\n",
    "    \"ACH-000517\": \"SNU410\",\n",
    "    \"ACH-000652\": \"SUIT2\",\n",
    "    \"ACH-000685\": \"L33\",\n",
    "    \"ACH-001376\": \"PACADD135\",\n",
    "    \"ACH-001379\": \"PACADD161\",\n",
    "    \"ACH-001380\": \"PACADD165\",\n",
    "    \"ACH-001382\": \"PACADD188\",\n",
    "    \"ACH-002039\": \"PK8\",\n",
    "    \"ACH-003161\": \"ABMT9430\",\n",
    "    \"ACH-003433\": \"CCLFPANC0019T\",\n",
    "}\n",
    "NAME_TO_ID = {v: k for k, v in CELLNAME_MAP.items()}\n",
    "ACH_RE = re.compile(r\"^ACH-\\d{6}$\", re.I)\n",
    "\n",
    "# --- Define module gene sets (UP/DOWN) ---\n",
    "SAT_UP = [\n",
    "    \"ABHD8\",\"AC004870.4\",\"AC005920.1\",\"AC009041.1\",\"AC009309.1\",\"AC011498.1\",\"AC012447.1\",\"AC018521.5\",\n",
    "    \"AC018754.1\",\"AC027237.2\",\"AC068338.2\",\"AC072061.1\",\"AC079305.3\",\"AC079807.1\",\"AC087623.2\",\"AC090403.1\",\n",
    "    \"AC091271.1\",\"AC092287.1\",\"AC092910.3\",\"AC093323.1\",\"AC099778.1\",\"AC107959.2\",\"AC125611.3\",\"AC144652.1\",\n",
    "    \"AC239799.2\",\"AC253572.2\",\"ACBD7\",\"AFMID\",\"AHCY\",\"AL021155.5\",\"AL022069.1\",\"AL031963.3\",\"AL049869.2\",\n",
    "    \"AL121574.1\",\"AL133523.1\",\"AL139106.1\",\"AL139246.5\",\"AL355075.4\",\"AL360012.1\",\"AL365436.2\",\"AL592295.5\",\n",
    "    \"AL662844.4\",\"AP001160.1\",\"AP002381.2\",\"AP002813.1\",\"ARL4D\",\"ATP2B1-AS1\",\"ATRIP\",\"BAMBI\",\"BHLHE40-AS1\",\n",
    "    \"BOLA1\",\"BUD23\",\"C12orf65\",\"C19orf48\",\"C2CD4B\",\"C6orf120\",\"CABYR\",\"CCDC9\",\"CCNE2\",\"CDKN2AIP\",\"CHCHD7\",\n",
    "    \"CITED2\",\"CROCC\",\"CSKMT\",\"CTH\",\"DALRD3\",\"DRAIC\",\"DUSP28\",\"EAF2\",\"EIF4A3\",\"FOXA3\",\"FOXL1\",\"GADD45B\",\"GLA\",\n",
    "    \"GOT1\",\"GRPEL1\",\"GTF2A1\",\"GTF2B\",\"HEXIM1\",\"HIST1H2AG\",\"HIST1H2AH\",\"HIST1H2AL\",\"HIST1H2BJ\",\"HIST1H2BN\",\n",
    "    \"HIST1H3A\",\"HIST1H3J\",\"HIST1H4A\",\"HIST1H4C\",\"HIST1H4E\",\"HIST2H2AC\",\"HIST2H3PS2\",\"HIST3H2A\",\"HIST4H4\",\"HMBS\",\n",
    "    \"HSPA2\",\"ID2\",\"IDI1\",\"ING1\",\"KCTD5\",\"KIF9\",\"KLHL11\",\"LAP3\",\"LIFR-AS1\",\"LINC01970\",\"LINC02029\",\"LINC02363\",\n",
    "    \"LRG1\",\"LRTOMT\",\"MAFB\",\"MED29\",\"MEPCE\",\"MIR17HG\",\"MORF4L2-AS1\",\"MTHFD2\",\"MYCL\",\"MYOSLID\",\"NANOS1\",\"NPW\",\n",
    "    \"NRARP\",\"OAT\",\"OSER1-DT\",\"OSGIN1\",\"PHYH\",\"PICART1\",\"PIEZO1\",\"PIK3R3\",\"PLIN5\",\"PLK2\",\"PMAIP1\",\"PMEL\",\"PNKD\",\n",
    "    \"POU3F1\",\"PPP1R3C\",\"PRMT5-AS1\",\"PRR3\",\"PTCH2\",\"PTPN6\",\"RAB26\",\"RALY-AS1\",\"RASL11A\",\"RND1\",\"RNF223\",\"RUVBL2\",\n",
    "    \"SAE1\",\"SENP8\",\"SIAH2-AS1\",\"SIRT2\",\"SLC7A5\",\"SNHG12\",\"SNHG5\",\"SNHG8\",\"SREBF2-AS1\",\"SRSF7\",\"STARD5\",\"TBPL1\",\n",
    "    \"TCTA\",\"THAP9\",\"TLCD1\",\"TM7SF2\",\"TMEM107\",\"TMEM171\",\"TMEM69\",\"TNFRSF10D\",\"TNK1\",\"TRAM2-AS1\",\"TTC33\",\"UAP1\",\n",
    "    \"UBAC2-AS1\",\"UBE2D3-AS1\",\"UBE2S\",\"UGDH\",\"WDR74\",\"Z93241.1\",\"Z99127.4\",\"ZC3H10\",\"ZCWPW1\",\"ZFAS1\",\"ZFX-AS1\",\n",
    "    \"ZNF574\",\"ZNF584\",\"ZNF622\",\"ZNF687-AS1\",\"ZNF844\",\"ZNF92\",\"ZSWIM3\"\n",
    "]\n",
    "SAT_DOWN = [\n",
    "    \"PAX5\",\"AC117386.2\",\"PRSS55\",\"RPS16\",\"GDF7\",\"PAK4\",\"AC022144.1\",\"AC092745.5\",\"AL670729.3\",\n",
    "    \"DLEU2L\",\"ELP3\",\"KCNC2\",\"MAP4K1\",\"AL161729.4\",\"SV2C\",\"RGS11\",\"AC005498.1\",\"WFDC5\",\"PSENEN\",\n",
    "    \"LINC01956\",\"AC115485.1\",\"CYSLTR2\",\"ASMTL-AS1\",\"AP002001.3\",\"FAM153B\"\n",
    "]\n",
    "IGE_UP = [\n",
    "    \"PFN2\",\"SET\",\"LGALS1\",\"PDLIM4\",\"EIF5A\",\"F8A1\",\"BANF1\",\"CTDNEP1\",\"TRAPPC1\",\"AMZ2\",\"PTGES3\",\"ST13\",\n",
    "    \"FTH1\",\"PCBP1\",\"NAA10\",\"ARPC5L\",\"ETFB\",\"CCDC124\",\"SSR2\",\"PGLS\",\"SELENOH\",\"GSTP1\",\"NDUFB7\",\"AURKAIP1\",\n",
    "    \"GCHFR\",\"MYL6\",\"AP2S1\",\"S100A13\",\"C9ORF16\",\"KRT8\",\"PRKCSH\",\"CST3\",\"PET100\",\"DNAJA2\",\"VPS35\",\"VDAC1\",\n",
    "    \"MGST3\",\"PRR13\",\"OCIAD2\",\"FUOM\",\"MIA\",\"RPN1\",\"FUCA2\",\"TMED4\",\"ERGIC3\",\"DDOST\",\"NAXE\",\"SNRPD1\",\"SKP1\",\n",
    "    \"CNBP\",\"ATP5MC3\",\"SLC25A5\",\"LSM4\",\"NDUFAB1\",\"PCBD1\",\"HINT1\",\"ADI1\",\"NENF\",\"MRPL43\",\"VKORC1\",\"EMC4\",\n",
    "    \"COA3\",\"NEDD8\",\"CHCHD2\",\"PRDX5\",\"WDR83OS\",\"NDUFA4\",\"GABARAP\",\"PHPT1\",\"UFC1\",\"MDH1\",\"ATP5F1E\",\"MRPL41\",\n",
    "    \"UBL5\",\"COX5B\",\"ELOB\",\"ATP5ME\",\"UQCRB\",\"SEM1\",\"NDUFB1\",\"COX6C\",\"ATP6V1F\",\"HNRNPA1\",\"HIGD2A\",\"POLR2I\",\n",
    "    \"METTL26\",\"NDUFB4\",\"OST4\",\"C19ORF53\",\"RPL36AL\",\"PPIA\",\"COPS9\",\"COX8A\",\"COX5A\",\"RPL36\",\"RPS15\",\"RPS27\",\n",
    "    \"RPS11\",\"FTL\",\"SNHG29\",\"NACA\",\"RPS17\",\"RPL23\",\"RPL39\",\"RPS21\",\"RPL9\",\"RPL15\",\"RPL34\",\"RPL27A\",\"RPL36A\",\n",
    "    \"RPL38\",\"RPS26\",\"RPS14\",\"RPL35\",\"RPL37A\",\"RPL37\",\"RPL12\",\"RPS29\"\n",
    "]\n",
    "IGE_DOWN = [\n",
    "    \"STT3A\",\"SGPP1\",\"LINGO1\",\"ASS1\",\"CETN2\",\"HNRNPH1\",\"STN1\",\"NRG4\",\"IQSEC2\",\"IYD\",\"CHD9\",\"APBB1IP\",\n",
    "    \"TMEM238\",\"REX1BD\",\"IFI27\",\"CYBA\",\"METRNL\",\"AKR7A2\",\"SULT1A1\",\"ARHGEF35\",\"AC008397.1\",\"KLK11\",\n",
    "    \"DELE1\",\"MISP\",\"FAM234A\",\"CMBL\"\n",
    "]\n",
    "IL2_UP = [\n",
    "    \"ABHD15-AS1\",\"AC007780.1\",\"AC008105.3\",\"AC008964.1\",\"AC016831.1\",\"AC016831.5\",\"AC090772.1\",\"AC108863.2\",\n",
    "    \"ADARB1\",\"ALOX5AP\",\"ANKH\",\"ANKRD44\",\"APOBEC3G\",\"ARHGDIB\",\"ARL6IP5\",\"ARSG\",\"ATP10D\",\"BCL11B\",\"BORCS5\",\n",
    "    \"CAMK1D\",\"CD4\",\"CD84\",\"CD96\",\"CDC42EP3\",\"CELF2\",\"CERS4\",\"CLEC2D\",\"CNOT6L\",\"CRYBG1\",\"CTSW\",\"DSE\",\"FGD3\",\n",
    "    \"FMNL1\",\"FOXN3\",\"FOXO1\",\"FYB1\",\"GFI1\",\"GNAO1\",\"GPRIN3\",\"HOPX\",\"IGF1\",\"IKZF3\",\"IL18R1\",\"INKA2\",\"INSYN2B\",\n",
    "    \"IQSEC1\",\"ITPRIPL1\",\"JAK3\",\"KLRC2\",\"KLRC3\",\"KLRF1\",\"KLRG1\",\"LAPTM5\",\"LCP1\",\"LEPROTL1\",\"LINC00513\",\n",
    "    \"LINC01237\",\"MAN1A1\",\"MAPRE2\",\"MPHOSPH9\",\"MPP7\",\"MVB12B\",\"MYO5A\",\"NIN\",\"PARP11\",\"PARP15\",\"PCED1B-AS1\",\n",
    "    \"PDE3B\",\"PIP4K2A\",\"PLCL1\",\"PLEKHA2\",\"PPP3CC\",\"PRKCH\",\"PRKCQ\",\"PRKD3\",\"PRKX\",\"PTPN22\",\"RAC2\",\"RASGRF2\",\n",
    "    \"RFX3\",\"RIPOR2\",\"RNF166\",\"S1PR4\",\"SAMD3\",\"SENP7\",\"SH2B3\",\"SH2D2A\",\"SMARCA2\",\"SNHG26\",\"SPOCK2\",\"SRGN\",\n",
    "    \"ST8SIA1\",\"STAT5A\",\"STAT5B\",\"STIM1\",\"STK17A\",\"TMEM200A\",\"TMX4\",\"TRBC2\",\"TRDC\",\"TRIM22\",\"TTN\",\"VAV3\",\n",
    "    \"WNT5A-AS1\",\"ZNF101\",\"ZNF471\"\n",
    "]\n",
    "IL2_DOWN = [\n",
    "    \"RBP7\",\"OVCA2\",\"PLAC4\",\"AC026785.3\",\"LINC02212\",\"LINC00605\",\"AC246817.2\",\"FOXCUT\",\"VGLL2\",\"ZIC4\",\"FOLR3\",\n",
    "    \"ECEL1\",\"AC024337.1\",\"C5orf58\",\"AC060814.3\",\"B4GALNT1\",\"UCHL1\",\"VAX1\",\"AL451042.1\",\"COMMD8\",\"IFI30\",\n",
    "    \"AL096794.1\",\"RGS10\"\n",
    "]\n",
    "MPC_UP = [\n",
    "    \"KIAA1211L\",\"CASC4\",\"AHR\",\"YY1AP1\",\"COPA\",\"RELL1\",\"FBXW2\",\"CARMIL1\",\"NUBPL\",\"ZC3H18\",\"AGK\",\"HLCS\",\n",
    "    \"TMEM241\",\"URGCP\",\"CADPS2\",\"COBL\",\"ARHGAP42\",\"AC138305.1\",\"FAM135A\",\"SLC41A2\",\"TACC2\",\"MCU\",\"FMN1\",\n",
    "    \"LGR4\",\"BAIAP2L1\",\"SGPP2\",\"RGS12\",\"PTPN3\",\"IBTK\",\"SPRY4-AS1\",\"UGT8\",\"PNN\",\"SP140L\",\"PIK3CA\",\"CNOT2\",\n",
    "    \"ZFC3H1\",\"UBE2K\",\"STRN3\",\"STAG2\",\"KDM5A\",\"RC3H2\",\"TP53BP1\",\"SLC9A8\",\"ATF7IP\",\"MLLT10\",\"SCAPER\",\"CPSF6\",\n",
    "    \"KLC1\",\"HUWE1\",\"TAOK3\",\"ROCK1\",\"MAN2A1\",\"ZNF44\",\"ARGLU1\",\"EHMT1\",\"HTT\",\"SIN3A\",\"RSBN1L\",\"MLLT3\",\"RABGAP1\",\n",
    "    \"SCFD1\",\"NEMF\",\"DMXL1\",\"RCOR3\",\"NAA35\",\"WWP1\",\"VPS41\",\"PRRC2B\",\"STX16\",\"ANKRD11\",\"ARHGEF7\",\"SOS2\",\"SLAIN2\",\n",
    "    \"LUC7L2\",\"SRPK2\",\"TYW1\",\"HMBOX1\",\"LMBR1\",\"TCF12\",\"MBD5\",\"MON2\",\"COG5\",\"LONP2\",\"RAB3GAP2\",\"LARP4B\",\"NUMB\",\n",
    "    \"NF1\",\"NCOA2\",\"ZNF710\",\"CSNK1G1\",\"WDR37\",\"NUTM2B-AS1\",\"ITFG1\",\"UBE3C\",\"MFSD14C\",\"SPG11\",\"PTK2\",\"LPP\",\n",
    "    \"ZBTB20\",\"FCHO2\",\"PTPN12\",\"DCUN1D4\",\"KDM7A\",\"SLMAP\",\"KIF13B\",\"MIB1\",\"DIP2C\",\"LRCH1\",\"TNIK\",\"TNKS\",\"SMC5\",\n",
    "    \"ANKIB1\",\"RBM33\",\"TNPO3\",\"OSBPL3\",\"RAPGEF2\",\"MED13L\",\"FBXL20\",\"KIAA0232\",\"ITCH\",\"MARCH6\",\"ARID4B\",\"PLEKHA6\",\n",
    "    \"FNBP1L\",\"KIAA1217\",\"FARP2\",\"MAGI3\",\"DIAPH2\",\"VPS13A\",\"DGKH\",\"GNAQ\",\"ARHGEF12\",\"MYO1D\",\"CDC42BPA\",\"TTC7A\",\n",
    "    \"TRIM44\",\"NSD3\",\"NCOA3\",\"ADNP\",\"RUFY3\",\"RUNX1\",\"TRRAP\",\"PTBP2\",\"ZNF609\",\"CHD7\",\"PARP8\",\"ARIH1\",\"ZHX2\",\n",
    "    \"ETV6\",\"CUL1\",\"CDK13\",\"BRAF\",\"MBTD1\",\"AUH\",\"STX17\",\"POLR2J3\",\"KLHDC10\",\"TAF1\",\"TOGARAM1\",\"WRN\",\"ADK\",\n",
    "    \"TASOR2\",\"NUDCD3\",\"TBL1X\",\"MOSMO\",\"USP42\",\"CRCP\",\"GALNT11\",\"DDI2\",\"TTC14\",\"UPF2\",\"PDXDC1\",\"ETFDH\",\"SEL1L3\",\n",
    "    \"HEATR5A\",\"PSMD5\",\"TBC1D2B\",\"NUP214\",\"GAPVD1\",\"RNF19A\",\"SMURF2\",\"NRIP1\",\"WDFY2\",\"TBK1\",\"LCORL\",\"USP25\",\n",
    "    \"RABGEF1\",\"CASD1\",\"RBPJ\",\"AEBP2\",\"MALAT1\",\"MAML2\",\"RBMS1\",\"CRIM1\",\"SNX29\",\"PPFIBP1\",\"SVIL\",\"DDX24\",\"G2E3\",\n",
    "    \"RASA1\",\"FAM160A1\",\"RNF24\",\"ESYT2\",\"EPS8\",\"SESTD1\",\"ATP2B4\",\"PELI1\",\"RNF145\",\"B4GALT5\",\"PPP2R2A\",\"NOS1AP\",\n",
    "    \"EGFR\",\"CPNE8\",\"ARHGAP21\",\"SMAD3\",\"DAPK1\",\"IGF1R\",\"AFAP1\",\"KLF7\",\"DOCK5\",\"MINDY2\",\"ZXDC\",\"NEDD4\",\"METTL15\",\n",
    "    \"FNIP2\",\"NEAT1\",\"CELF1\",\"DANT2\",\"SYT17\",\"TMEM245\",\"ERICH1\",\"ADPGK\",\"LMBRD1\",\"MFSD11\",\"GOLGA2\",\"SCNN1A\",\n",
    "    \"XDH\",\"PLEKHA1\",\"PPP2CB\",\"GTF2E2\",\"KCNK1\",\"SPATS2L\",\"RTF1\",\"UACA\",\"VAV2\",\"MDFIC\",\"STAM\",\"CLIP4\",\"KYAT1\",\n",
    "    \"MECP2\",\"NUP160\",\"THOC1\",\"LINC-PINT\",\"MCPH1\",\"DISC1\",\"UBA6-AS1\",\"AAK1\",\"NRF1\",\"PHF20\",\"RNF216\",\"PCM1\",\"SAFB2\",\n",
    "    \"FAM133B\",\"NR6A1\",\"ATL2\",\"C1orf21\",\"MTUS1\",\"PARD3B\",\"EXT1\",\"ST5\",\"ABI2\",\"INTS6L\",\"TRIM56\",\"PTER\",\"PRR12\",\n",
    "    \"RSPH3\",\"TMC5\",\"MECOM\",\"ARHGEF10L\",\"HNF4G\",\"PPM1H\",\"AP005230.1\",\"AC119674.1\",\"ZSCAN18\",\"NOL4L\",\"PDPK1\",\n",
    "    \"RSU1\",\"TTC39C\",\"COL27A1\",\"SEC16B\",\"AC005162.3\",\"RASAL1\",\"IL17RA\",\"SPART-AS1\",\"CDC37\",\"MUCL3\",\"TMEM178B\",\n",
    "    \"LINC02614\",\"EREG\",\"ELK3\",\"TMTC1\",\"PALM2-AKAP2\",\"RAB31\",\"EMP3\"\n",
    "]\n",
    "MPC_DOWN = [\n",
    "    \"MRPS15\",\"TALDO1\",\"MDH2\",\"PSMB5\",\"PIK3CD-AS2\",\"DUSP9\",\"POPDC3\",\"AKR1C3\",\"MRPS18A\",\"EIF3H\",\"UQCRC2\",\n",
    "    \"IFT22\",\"RAB11B\",\"MBOAT7\"\n",
    "]\n",
    "\n",
    "MODULES = {\n",
    "    \"SAT\": (SAT_UP, SAT_DOWN),\n",
    "    \"IGE\": (IGE_UP, IGE_DOWN),\n",
    "    \"IL2\": (IL2_UP, IL2_DOWN),\n",
    "    \"MPC\": (MPC_UP, MPC_DOWN),\n",
    "}\n",
    "\n",
    "# ==================== HELPERS ====================\n",
    "def zscore_rows(df):\n",
    "    mu = df.mean(axis=1)\n",
    "    sd = df.std(axis=1, ddof=0).replace(0, np.nan)\n",
    "    return df.sub(mu, axis=0).div(sd, axis=0)\n",
    "\n",
    "def score_module(Z, up_genes, down_genes):\n",
    "    up = [g for g in up_genes if g in Z.index]\n",
    "    down = [g for g in down_genes if g in Z.index]\n",
    "    if len(up)==0 or len(down)==0:\n",
    "        return pd.Series(np.nan, index=Z.columns)\n",
    "    return Z.loc[up].mean(axis=0) - Z.loc[down].mean(axis=0)\n",
    "\n",
    "def hedges_g(x, y):\n",
    "    nx, ny = len(x), len(y)\n",
    "    if nx < 2 or ny < 2: return np.nan\n",
    "    sp2 = ((nx-1)*np.var(x, ddof=1)+(ny-1)*np.var(y, ddof=1)) / (nx+ny-2)\n",
    "    if sp2 <= 0 or np.isnan(sp2): return np.nan\n",
    "    d = (x.mean()-y.mean())/np.sqrt(sp2)\n",
    "    J = 1 - (3/(4*(nx+ny)-9))\n",
    "    return d*J\n",
    "\n",
    "def cliffs_delta(x,y):\n",
    "    x = x.reshape(-1,1); y = y.reshape(1,-1)\n",
    "    return ((x>y)-(x<y)).sum()/(x.size*y.size)\n",
    "\n",
    "def bh_fdr(p):\n",
    "    p = np.asarray(p, float); n = len(p)\n",
    "    order = np.argsort(p); ranked = np.empty_like(p); prev = 1\n",
    "    for i, idx in enumerate(order[::-1], start=1):\n",
    "        rank = n - i + 1\n",
    "        val = min(prev, p[idx] * n / rank)\n",
    "        ranked[idx] = val; prev = val\n",
    "    return ranked\n",
    "\n",
    "def map_any_to_ids(labels):\n",
    "    out = []\n",
    "    for c in labels:\n",
    "        c = str(c).strip()\n",
    "        if ACH_RE.match(c):              # already an ID\n",
    "            out.append(c.upper())\n",
    "        elif c in NAME_TO_ID:            # name -> ID\n",
    "            out.append(NAME_TO_ID[c])\n",
    "        else:\n",
    "            out.append(c)                # leave as-is\n",
    "    return out\n",
    "\n",
    "def ids_to_names(labels):\n",
    "    return [CELLNAME_MAP.get(str(c).strip(), str(c).strip()) for c in labels]\n",
    "\n",
    "def is_gene_like_list(vals):\n",
    "    vals = [str(v) for v in vals]\n",
    "    pat = re.compile(r\"^[A-Za-z0-9][A-Za-z0-9\\.\\-]{1,19}$\")\n",
    "    hits = sum(bool(pat.match(v)) for v in vals)\n",
    "    return hits / max(1, len(vals)) > 0.7\n",
    "\n",
    "def is_cellline_like_list(vals):\n",
    "    vals = [str(v) for v in vals]\n",
    "    ach = sum(bool(ACH_RE.match(v)) for v in vals)\n",
    "    names = sum(v in NAME_TO_ID for v in vals)\n",
    "    return (ach + names) / max(1, len(vals)) > 0.3\n",
    "\n",
    "# ==================== 1) LOAD EXPRESSION & FIX ORIENTATION ====================\n",
    "expr_raw = pd.read_csv(EXPR, index_col=0)\n",
    "idx, cols = list(expr_raw.index), list(expr_raw.columns)\n",
    "\n",
    "rows_look_like_cells = is_cellline_like_list(idx)\n",
    "cols_look_like_cells = is_cellline_like_list(cols)\n",
    "rows_look_like_genes = is_gene_like_list(idx)\n",
    "cols_look_like_genes = is_gene_like_list(cols)\n",
    "\n",
    "# Decide orientation: want genes × cell lines (columns are lines)\n",
    "if cols_look_like_cells and rows_look_like_genes:\n",
    "    expr = expr_raw.copy()\n",
    "elif rows_look_like_cells and cols_look_like_genes:\n",
    "    expr = expr_raw.T.copy()   # transpose to genes × lines\n",
    "else:\n",
    "    # fallback: if columns count < rows count and columns look like cells, keep; else transpose\n",
    "    expr = expr_raw if (len(cols) < len(idx) and cols_look_like_cells) else expr_raw.T.copy()\n",
    "\n",
    "# Normalize cell-line columns to DepMap_IDs\n",
    "expr.columns = pd.Index(map_any_to_ids(expr.columns), dtype=str)\n",
    "# Collapse duplicate IDs if any (mean)\n",
    "expr = (expr.T.groupby(level=0).mean(numeric_only=True)).T\n",
    "\n",
    "# Clean genes\n",
    "expr.index = pd.Index([str(g).upper().strip() for g in expr.index], dtype=str)\n",
    "print(f\"[EXPR] genes × lines: {expr.shape}\")\n",
    "\n",
    "Z = zscore_rows(expr)\n",
    "\n",
    "# ==================== 2) COMPUTE MODULE SCORES ====================\n",
    "module_scores = pd.DataFrame(index=expr.columns)\n",
    "for mod, (up, down) in MODULES.items():\n",
    "    module_scores[mod] = score_module(Z, up, down)\n",
    "\n",
    "module_scores_named = module_scores.copy()\n",
    "module_scores_named.index = ids_to_names(module_scores_named.index)\n",
    "module_scores_named.to_csv(OUTDIR / \"module_scores_with_names.csv\")\n",
    "print(\"[MODULE SCORES] saved module_scores_with_names.csv\")\n",
    "\n",
    "# ==================== 3) LOAD PRISM (drugs × lines) & NORMALIZE ====================\n",
    "prism = pd.read_csv(PRISM, index_col=0)\n",
    "prism.columns = pd.Index(map_any_to_ids(prism.columns), dtype=str)\n",
    "prism = prism.loc[:, ~prism.columns.duplicated()]  # just in case\n",
    "\n",
    "# Intersect on DepMap_IDs\n",
    "shared = sorted(set(prism.columns).intersection(module_scores.index))\n",
    "pd.DataFrame({\"DepMap_ID\": shared, \"cell_line_name\": ids_to_names(shared)}).to_csv(\n",
    "    OUTDIR / \"shared_cell_lines.csv\", index=False\n",
    ")\n",
    "\n",
    "prism = prism[shared]\n",
    "module_scores = module_scores.loc[shared]\n",
    "print(f\"[PRISM] {prism.shape[0]} drugs × {prism.shape[1]} shared PDAC lines\")\n",
    "\n",
    "# ==================== 4) ASSOCIATION TESTS ====================\n",
    "def run_assoc(mod, s, prism_mat, shared_ids):\n",
    "    lo, hi = s.quantile(1/3), s.quantile(2/3)\n",
    "    low_ids  = s.index[s <= lo]\n",
    "    high_ids = s.index[s >= hi]\n",
    "\n",
    "    results = []\n",
    "    for drug in prism_mat.index:\n",
    "        y = prism_mat.loc[drug, shared_ids].astype(float)\n",
    "        x = s.loc[shared_ids].astype(float)\n",
    "        ok = (~y.isna()) & (~x.isna())\n",
    "        if ok.sum() < 6:\n",
    "            continue\n",
    "\n",
    "        r, p_spear = stats.spearmanr(x[ok], y[ok])\n",
    "\n",
    "        yl = prism_mat.loc[drug, low_ids].dropna().values\n",
    "        yh = prism_mat.loc[drug, high_ids].dropna().values\n",
    "        p_u = g_eff = d_eff = np.nan\n",
    "        if (yl.size >= 4) and (yh.size >= 4):\n",
    "            try:\n",
    "                _, p_u = stats.mannwhitneyu(yl, yh, alternative=\"two-sided\")\n",
    "                g_eff = hedges_g(yh, yl)\n",
    "                d_eff = cliffs_delta(yh, yl)\n",
    "            except Exception:\n",
    "                pass\n",
    "\n",
    "        results.append([drug, r, p_spear, p_u, g_eff, d_eff])\n",
    "\n",
    "    if not results:\n",
    "        return pd.DataFrame(columns=[\"spearman_rho\",\"spearman_p\",\"spearman_q\",\"hedges_g\",\"u_p\",\"u_q\"])\n",
    "\n",
    "    out = pd.DataFrame(results, columns=[\"drug\",\"spearman_rho\",\"spearman_p\",\"u_p\",\"hedges_g\",\"cliffs_delta\"]).set_index(\"drug\")\n",
    "    # FDRs\n",
    "    out[\"spearman_q\"] = bh_fdr(out[\"spearman_p\"].fillna(1))\n",
    "    out[\"u_q\"]        = bh_fdr(out[\"u_p\"].fillna(1))\n",
    "    out = out.sort_values(\"spearman_p\")\n",
    "    return out\n",
    "\n",
    "for mod in MODULES.keys():\n",
    "    out = run_assoc(mod, module_scores[mod], prism, shared)\n",
    "    out.to_csv(OUTDIR / f\"prism_{mod}_association.csv\")\n",
    "    print(f\"[{mod}] top 5 (Spearman):\")\n",
    "    print(out.head(5)[[\"spearman_rho\",\"spearman_p\",\"spearman_q\",\"hedges_g\",\"u_p\",\"u_q\"]])\n",
    "\n",
    "print(\"✅ Done. Results written to:\", OUTDIR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81fb96e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re, pandas as pd\n",
    "from pathlib import Path\n",
    "BASE = Path(\"~/Desktop\").expanduser()\n",
    "\n",
    "EXPR  = pd.read_csv(BASE/\"PDAC_celllines_expression.csv\", index_col=0)\n",
    "PRISM = pd.read_csv(BASE/\"PRISM_AUC_PDAC_matrix.csv\",    index_col=0)\n",
    "\n",
    "ACH = re.compile(r\"^ACH-\\d{6}$\", re.I)\n",
    "expr_cols = list(map(str, EXPR.columns))\n",
    "expr_idx  = list(map(str, EXPR.index))\n",
    "prism_cols= list(map(str, PRISM.columns))\n",
    "\n",
    "print(\"[expr] shape\", EXPR.shape)\n",
    "print(\"[prism] shape\", PRISM.shape)\n",
    "\n",
    "print(\"expr columns look like ACH?:\", sum(bool(ACH.match(c)) for c in expr_cols))\n",
    "print(\"expr index   look like genes?:\", sum(bool(re.fullmatch(r\"[A-Za-z0-9][A-Za-z0-9.\\-]{1,19}\", g)) for g in expr_idx))\n",
    "\n",
    "print(\"prism columns ACH?:\", sum(bool(ACH.match(c)) for c in prism_cols))\n",
    "\n",
    "shared = sorted(set(c for c in expr_cols if ACH.match(c)).intersection(c for c in prism_cols if ACH.match(c)))\n",
    "print(\"shared ACH IDs:\", len(shared), shared[:10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "115f5687",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from glob import glob\n",
    "\n",
    "# --- expr already in memory (genes x ACH columns) ---\n",
    "print(\"[expr]\", expr.shape)\n",
    "print(\"expr ACH head:\", expr.columns[:5].tolist())\n",
    "\n",
    "HOME = Path.home()\n",
    "\n",
    "# ---- Locate long-format PRISM file ----\n",
    "long_candidates = [\n",
    "    Path(\"PRISM_AUC_PDAC_long.csv\"),\n",
    "    HOME/\"Desktop/PRISM_AUC_PDAC_long.csv\",\n",
    "    HOME/\"Downloads/PRISM_AUC_PDAC_long.csv\",\n",
    "]\n",
    "if not any(p.exists() for p in long_candidates):\n",
    "    found = glob(str(HOME / \"**/PRISM_AUC_PDAC_long.csv\"), recursive=True)\n",
    "    if found: long_candidates.insert(0, Path(found[0]))\n",
    "PRISM_LONG = next((p for p in long_candidates if p.exists()), None)\n",
    "assert PRISM_LONG is not None, \"Could not find PRISM_AUC_PDAC_long.csv.\"\n",
    "\n",
    "print(f\"[prism long path] {PRISM_LONG}\")\n",
    "\n",
    "# ---- Read long file ----\n",
    "long = pd.read_csv(PRISM_LONG)\n",
    "print(\"[long] shape:\", long.shape)\n",
    "print(\"[long] columns:\", long.columns.tolist()[:12])\n",
    "\n",
    "# Identify column names (robust to variants)\n",
    "cols = {c.lower(): c for c in long.columns}\n",
    "\n",
    "ccle_col = cols.get(\"ccle_name\") or cols.get(\"cclename\") or cols.get(\"ccle\") or cols.get(\"cell_line\")\n",
    "assert ccle_col, f\"Need CCLE name column; available: {long.columns.tolist()}\"\n",
    "\n",
    "# Drug identifier: prefer 'compound'/'name'/'drug'/'broad_id'\n",
    "drug_col = (cols.get(\"compound\") or cols.get(\"drug\") or cols.get(\"name\") or \n",
    "            cols.get(\"pert_iname\") or cols.get(\"broad_id\") or cols.get(\"brd_id\"))\n",
    "assert drug_col, f\"Need a drug/compound column; available: {long.columns.tolist()}\"\n",
    "\n",
    "# AUC value column (try common names)\n",
    "auc_col = (cols.get(\"auc\") or cols.get(\"area_under_curve\") or cols.get(\"auc_mean\") or \n",
    "           cols.get(\"auc_value\") or cols.get(\"auc_avg\"))\n",
    "assert auc_col, f\"Need an AUC column; available: {long.columns.tolist()}\"\n",
    "\n",
    "# Keep only what's needed\n",
    "keep = long[[ccle_col, drug_col, auc_col]].copy()\n",
    "keep = keep.dropna(subset=[ccle_col, drug_col, auc_col])\n",
    "print(\"[long] non-null rows:\", keep.shape[0])\n",
    "\n",
    "# Pivot to matrix (cell lines x drugs), averaging duplicates\n",
    "prism = (\n",
    "    keep.groupby([ccle_col, drug_col], as_index=False)[auc_col]\n",
    "        .mean()\n",
    "        .pivot(index=ccle_col, columns=drug_col, values=auc_col)\n",
    ")\n",
    "print(\"[prism matrix] shape:\", prism.shape)\n",
    "print(\"index head:\", prism.index[:5].tolist())\n",
    "print(\"cols head:\", prism.columns[:5].tolist())\n",
    "\n",
    "# ---- Load DepMap model info for CCLE -> ACH mapping ----\n",
    "model_candidates = [\n",
    "    Path(\"Model.csv\"), Path(\"sample_info.csv\"),\n",
    "    HOME/\"Desktop/Model.csv\", HOME/\"Desktop/sample_info.csv\",\n",
    "    HOME/\"Downloads/Model.csv\", HOME/\"Downloads/sample_info.csv\",\n",
    "]\n",
    "if not any(p.exists() for p in model_candidates):\n",
    "    found = glob(str(HOME / \"**/Model.csv\"), recursive=True) + glob(str(HOME / \"**/sample_info.csv\"), recursive=True)\n",
    "    if found: model_candidates.insert(0, Path(found[0]))\n",
    "MODEL = next((p for p in model_candidates if p.exists()), None)\n",
    "assert MODEL is not None, \"Could not find Model.csv or sample_info.csv.\"\n",
    "\n",
    "info = pd.read_csv(MODEL)\n",
    "icol = {c.lower(): c for c in info.columns}\n",
    "ach_col = icol.get(\"ach_id\") or icol.get(\"modelid\") or icol.get(\"model_id\")\n",
    "ccle_info_col = icol.get(\"ccle_name\") or icol.get(\"cclename\")\n",
    "assert ach_col and ccle_info_col, f\"Model file must include CCLE_Name and ACH_ID/ModelID; found: {info.columns.tolist()}\"\n",
    "\n",
    "map_ccle_to_ach = dict(zip(info[ccle_info_col], info[ach_col]))\n",
    "\n",
    "# Some CCLEs may have tissue suffix (e.g., ASPC1_PANCREAS)\n",
    "def strip_suffix(name):\n",
    "    return name.rsplit(\"_\", 1)[0] if isinstance(name, str) and \"_\" in name else name\n",
    "\n",
    "# Try direct mapping, else try stripped suffix\n",
    "prism1 = prism.rename(index=map_ccle_to_ach)\n",
    "shared1 = expr.columns.intersection(prism1.index)\n",
    "\n",
    "if len(shared1) < 10:\n",
    "    prism2 = prism.copy()\n",
    "    prism2.index = prism2.index.map(strip_suffix)\n",
    "    prism2 = prism2.rename(index=map_ccle_to_ach)\n",
    "    shared2 = expr.columns.intersection(prism2.index)\n",
    "    if len(shared2) >= len(shared1):\n",
    "        prism_mapped, shared = prism2, shared2\n",
    "        used = \"stripped CCLE suffix\"\n",
    "    else:\n",
    "        prism_mapped, shared = prism1, shared1\n",
    "        used = \"direct CCLE\"\n",
    "else:\n",
    "    prism_mapped, shared = prism1, shared1\n",
    "    used = \"direct CCLE\"\n",
    "\n",
    "print(f\"[map] method: {used}\")\n",
    "print(f\"[align] shared ACH with expr: {len(shared)}\")\n",
    "print(\"shared head:\", shared[:10].tolist())\n",
    "\n",
    "# ---- Align and save ----\n",
    "expr_aln  = expr.loc[:, shared].copy()\n",
    "prism_aln = prism_mapped.loc[shared, :].copy()\n",
    "\n",
    "print(\"[expr_aln]\", expr_aln.shape, \"| [prism_aln]\", prism_aln.shape)\n",
    "\n",
    "OUTDIR = Path(\"out_prism_align\"); OUTDIR.mkdir(exist_ok=True)\n",
    "expr_aln.to_csv(OUTDIR / \"expr_genesXACH_shared.csv\")\n",
    "prism_aln.to_csv(OUTDIR / \"prism_ACHXdrugs_shared.csv\")\n",
    "\n",
    "audit = pd.DataFrame({\n",
    "    \"prism_rows_total\":[prism.shape[0]],\n",
    "    \"shared_ACH\":[len(shared)],\n",
    "    \"expr_genes\":[expr.shape[0]],\n",
    "    \"expr_samples\":[expr.shape[1]],\n",
    "    \"prism_drugs\":[prism_aln.shape[1]],\n",
    "    \"mapping_method\":[used],\n",
    "})\n",
    "audit.to_csv(OUTDIR / \"alignment_audit.csv\", index=False)\n",
    "audit\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bca53406",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd, numpy as np, re\n",
    "from pathlib import Path\n",
    "from collections.abc import Iterable\n",
    "\n",
    "# expr already in memory (rows=genes, cols=ACH)\n",
    "print(\"[expr]\", expr.shape)\n",
    "\n",
    "# ==== Paste your gene lists below ====\n",
    "# You can use EITHER strings (one per line/commas ok) OR Python lists like ['GATA6','KRT17',...]\n",
    "SAT_UP = [\n",
    "    \"ABHD8\",\"AC004870.4\",\"AC005920.1\",\"AC009041.1\",\"AC009309.1\",\"AC011498.1\",\"AC012447.1\",\"AC018521.5\",\n",
    "    \"AC018754.1\",\"AC027237.2\",\"AC068338.2\",\"AC072061.1\",\"AC079305.3\",\"AC079807.1\",\"AC087623.2\",\"AC090403.1\",\n",
    "    \"AC091271.1\",\"AC092287.1\",\"AC092910.3\",\"AC093323.1\",\"AC099778.1\",\"AC107959.2\",\"AC125611.3\",\"AC144652.1\",\n",
    "    \"AC239799.2\",\"AC253572.2\",\"ACBD7\",\"AFMID\",\"AHCY\",\"AL021155.5\",\"AL022069.1\",\"AL031963.3\",\"AL049869.2\",\n",
    "    \"AL121574.1\",\"AL133523.1\",\"AL139106.1\",\"AL139246.5\",\"AL355075.4\",\"AL360012.1\",\"AL365436.2\",\"AL592295.5\",\n",
    "    \"AL662844.4\",\"AP001160.1\",\"AP002381.2\",\"AP002813.1\",\"ARL4D\",\"ATP2B1-AS1\",\"ATRIP\",\"BAMBI\",\"BHLHE40-AS1\",\n",
    "    \"BOLA1\",\"BUD23\",\"C12orf65\",\"C19orf48\",\"C2CD4B\",\"C6orf120\",\"CABYR\",\"CCDC9\",\"CCNE2\",\"CDKN2AIP\",\"CHCHD7\",\n",
    "    \"CITED2\",\"CROCC\",\"CSKMT\",\"CTH\",\"DALRD3\",\"DRAIC\",\"DUSP28\",\"EAF2\",\"EIF4A3\",\"FOXA3\",\"FOXL1\",\"GADD45B\",\"GLA\",\n",
    "    \"GOT1\",\"GRPEL1\",\"GTF2A1\",\"GTF2B\",\"HEXIM1\",\"HIST1H2AG\",\"HIST1H2AH\",\"HIST1H2AL\",\"HIST1H2BJ\",\"HIST1H2BN\",\n",
    "    \"HIST1H3A\",\"HIST1H3J\",\"HIST1H4A\",\"HIST1H4C\",\"HIST1H4E\",\"HIST2H2AC\",\"HIST2H3PS2\",\"HIST3H2A\",\"HIST4H4\",\"HMBS\",\n",
    "    \"HSPA2\",\"ID2\",\"IDI1\",\"ING1\",\"KCTD5\",\"KIF9\",\"KLHL11\",\"LAP3\",\"LIFR-AS1\",\"LINC01970\",\"LINC02029\",\"LINC02363\",\n",
    "    \"LRG1\",\"LRTOMT\",\"MAFB\",\"MED29\",\"MEPCE\",\"MIR17HG\",\"MORF4L2-AS1\",\"MTHFD2\",\"MYCL\",\"MYOSLID\",\"NANOS1\",\"NPW\",\n",
    "    \"NRARP\",\"OAT\",\"OSER1-DT\",\"OSGIN1\",\"PHYH\",\"PICART1\",\"PIEZO1\",\"PIK3R3\",\"PLIN5\",\"PLK2\",\"PMAIP1\",\"PMEL\",\"PNKD\",\n",
    "    \"POU3F1\",\"PPP1R3C\",\"PRMT5-AS1\",\"PRR3\",\"PTCH2\",\"PTPN6\",\"RAB26\",\"RALY-AS1\",\"RASL11A\",\"RND1\",\"RNF223\",\"RUVBL2\",\n",
    "    \"SAE1\",\"SENP8\",\"SIAH2-AS1\",\"SIRT2\",\"SLC7A5\",\"SNHG12\",\"SNHG5\",\"SNHG8\",\"SREBF2-AS1\",\"SRSF7\",\"STARD5\",\"TBPL1\",\n",
    "    \"TCTA\",\"THAP9\",\"TLCD1\",\"TM7SF2\",\"TMEM107\",\"TMEM171\",\"TMEM69\",\"TNFRSF10D\",\"TNK1\",\"TRAM2-AS1\",\"TTC33\",\"UAP1\",\n",
    "    \"UBAC2-AS1\",\"UBE2D3-AS1\",\"UBE2S\",\"UGDH\",\"WDR74\",\"Z93241.1\",\"Z99127.4\",\"ZC3H10\",\"ZCWPW1\",\"ZFAS1\",\"ZFX-AS1\",\n",
    "    \"ZNF574\",\"ZNF584\",\"ZNF622\",\"ZNF687-AS1\",\"ZNF844\",\"ZNF92\",\"ZSWIM3\"\n",
    "]\n",
    "SAT_DOWN = [\n",
    "    \"PAX5\",\"AC117386.2\",\"PRSS55\",\"RPS16\",\"GDF7\",\"PAK4\",\"AC022144.1\",\"AC092745.5\",\"AL670729.3\",\n",
    "    \"DLEU2L\",\"ELP3\",\"KCNC2\",\"MAP4K1\",\"AL161729.4\",\"SV2C\",\"RGS11\",\"AC005498.1\",\"WFDC5\",\"PSENEN\",\n",
    "    \"LINC01956\",\"AC115485.1\",\"CYSLTR2\",\"ASMTL-AS1\",\"AP002001.3\",\"FAM153B\"\n",
    "]\n",
    "IGE_UP = [\n",
    "    \"PFN2\",\"SET\",\"LGALS1\",\"PDLIM4\",\"EIF5A\",\"F8A1\",\"BANF1\",\"CTDNEP1\",\"TRAPPC1\",\"AMZ2\",\"PTGES3\",\"ST13\",\n",
    "    \"FTH1\",\"PCBP1\",\"NAA10\",\"ARPC5L\",\"ETFB\",\"CCDC124\",\"SSR2\",\"PGLS\",\"SELENOH\",\"GSTP1\",\"NDUFB7\",\"AURKAIP1\",\n",
    "    \"GCHFR\",\"MYL6\",\"AP2S1\",\"S100A13\",\"C9ORF16\",\"KRT8\",\"PRKCSH\",\"CST3\",\"PET100\",\"DNAJA2\",\"VPS35\",\"VDAC1\",\n",
    "    \"MGST3\",\"PRR13\",\"OCIAD2\",\"FUOM\",\"MIA\",\"RPN1\",\"FUCA2\",\"TMED4\",\"ERGIC3\",\"DDOST\",\"NAXE\",\"SNRPD1\",\"SKP1\",\n",
    "    \"CNBP\",\"ATP5MC3\",\"SLC25A5\",\"LSM4\",\"NDUFAB1\",\"PCBD1\",\"HINT1\",\"ADI1\",\"NENF\",\"MRPL43\",\"VKORC1\",\"EMC4\",\n",
    "    \"COA3\",\"NEDD8\",\"CHCHD2\",\"PRDX5\",\"WDR83OS\",\"NDUFA4\",\"GABARAP\",\"PHPT1\",\"UFC1\",\"MDH1\",\"ATP5F1E\",\"MRPL41\",\n",
    "    \"UBL5\",\"COX5B\",\"ELOB\",\"ATP5ME\",\"UQCRB\",\"SEM1\",\"NDUFB1\",\"COX6C\",\"ATP6V1F\",\"HNRNPA1\",\"HIGD2A\",\"POLR2I\",\n",
    "    \"METTL26\",\"NDUFB4\",\"OST4\",\"C19ORF53\",\"RPL36AL\",\"PPIA\",\"COPS9\",\"COX8A\",\"COX5A\",\"RPL36\",\"RPS15\",\"RPS27\",\n",
    "    \"RPS11\",\"FTL\",\"SNHG29\",\"NACA\",\"RPS17\",\"RPL23\",\"RPL39\",\"RPS21\",\"RPL9\",\"RPL15\",\"RPL34\",\"RPL27A\",\"RPL36A\",\n",
    "    \"RPL38\",\"RPS26\",\"RPS14\",\"RPL35\",\"RPL37A\",\"RPL37\",\"RPL12\",\"RPS29\"\n",
    "]\n",
    "IGE_DOWN = [\n",
    "    \"STT3A\",\"SGPP1\",\"LINGO1\",\"ASS1\",\"CETN2\",\"HNRNPH1\",\"STN1\",\"NRG4\",\"IQSEC2\",\"IYD\",\"CHD9\",\"APBB1IP\",\n",
    "    \"TMEM238\",\"REX1BD\",\"IFI27\",\"CYBA\",\"METRNL\",\"AKR7A2\",\"SULT1A1\",\"ARHGEF35\",\"AC008397.1\",\"KLK11\",\n",
    "    \"DELE1\",\"MISP\",\"FAM234A\",\"CMBL\"\n",
    "]\n",
    "IL2_UP = [\n",
    "    \"ABHD15-AS1\",\"AC007780.1\",\"AC008105.3\",\"AC008964.1\",\"AC016831.1\",\"AC016831.5\",\"AC090772.1\",\"AC108863.2\",\n",
    "    \"ADARB1\",\"ALOX5AP\",\"ANKH\",\"ANKRD44\",\"APOBEC3G\",\"ARHGDIB\",\"ARL6IP5\",\"ARSG\",\"ATP10D\",\"BCL11B\",\"BORCS5\",\n",
    "    \"CAMK1D\",\"CD4\",\"CD84\",\"CD96\",\"CDC42EP3\",\"CELF2\",\"CERS4\",\"CLEC2D\",\"CNOT6L\",\"CRYBG1\",\"CTSW\",\"DSE\",\"FGD3\",\n",
    "    \"FMNL1\",\"FOXN3\",\"FOXO1\",\"FYB1\",\"GFI1\",\"GNAO1\",\"GPRIN3\",\"HOPX\",\"IGF1\",\"IKZF3\",\"IL18R1\",\"INKA2\",\"INSYN2B\",\n",
    "    \"IQSEC1\",\"ITPRIPL1\",\"JAK3\",\"KLRC2\",\"KLRC3\",\"KLRF1\",\"KLRG1\",\"LAPTM5\",\"LCP1\",\"LEPROTL1\",\"LINC00513\",\n",
    "    \"LINC01237\",\"MAN1A1\",\"MAPRE2\",\"MPHOSPH9\",\"MPP7\",\"MVB12B\",\"MYO5A\",\"NIN\",\"PARP11\",\"PARP15\",\"PCED1B-AS1\",\n",
    "    \"PDE3B\",\"PIP4K2A\",\"PLCL1\",\"PLEKHA2\",\"PPP3CC\",\"PRKCH\",\"PRKCQ\",\"PRKD3\",\"PRKX\",\"PTPN22\",\"RAC2\",\"RASGRF2\",\n",
    "    \"RFX3\",\"RIPOR2\",\"RNF166\",\"S1PR4\",\"SAMD3\",\"SENP7\",\"SH2B3\",\"SH2D2A\",\"SMARCA2\",\"SNHG26\",\"SPOCK2\",\"SRGN\",\n",
    "    \"ST8SIA1\",\"STAT5A\",\"STAT5B\",\"STIM1\",\"STK17A\",\"TMEM200A\",\"TMX4\",\"TRBC2\",\"TRDC\",\"TRIM22\",\"TTN\",\"VAV3\",\n",
    "    \"WNT5A-AS1\",\"ZNF101\",\"ZNF471\"\n",
    "]\n",
    "IL2_DOWN = [\n",
    "    \"RBP7\",\"OVCA2\",\"PLAC4\",\"AC026785.3\",\"LINC02212\",\"LINC00605\",\"AC246817.2\",\"FOXCUT\",\"VGLL2\",\"ZIC4\",\"FOLR3\",\n",
    "    \"ECEL1\",\"AC024337.1\",\"C5orf58\",\"AC060814.3\",\"B4GALNT1\",\"UCHL1\",\"VAX1\",\"AL451042.1\",\"COMMD8\",\"IFI30\",\n",
    "    \"AL096794.1\",\"RGS10\"\n",
    "]\n",
    "MPC_UP = [\n",
    "    \"KIAA1211L\",\"CASC4\",\"AHR\",\"YY1AP1\",\"COPA\",\"RELL1\",\"FBXW2\",\"CARMIL1\",\"NUBPL\",\"ZC3H18\",\"AGK\",\"HLCS\",\n",
    "    \"TMEM241\",\"URGCP\",\"CADPS2\",\"COBL\",\"ARHGAP42\",\"AC138305.1\",\"FAM135A\",\"SLC41A2\",\"TACC2\",\"MCU\",\"FMN1\",\n",
    "    \"LGR4\",\"BAIAP2L1\",\"SGPP2\",\"RGS12\",\"PTPN3\",\"IBTK\",\"SPRY4-AS1\",\"UGT8\",\"PNN\",\"SP140L\",\"PIK3CA\",\"CNOT2\",\n",
    "    \"ZFC3H1\",\"UBE2K\",\"STRN3\",\"STAG2\",\"KDM5A\",\"RC3H2\",\"TP53BP1\",\"SLC9A8\",\"ATF7IP\",\"MLLT10\",\"SCAPER\",\"CPSF6\",\n",
    "    \"KLC1\",\"HUWE1\",\"TAOK3\",\"ROCK1\",\"MAN2A1\",\"ZNF44\",\"ARGLU1\",\"EHMT1\",\"HTT\",\"SIN3A\",\"RSBN1L\",\"MLLT3\",\"RABGAP1\",\n",
    "    \"SCFD1\",\"NEMF\",\"DMXL1\",\"RCOR3\",\"NAA35\",\"WWP1\",\"VPS41\",\"PRRC2B\",\"STX16\",\"ANKRD11\",\"ARHGEF7\",\"SOS2\",\"SLAIN2\",\n",
    "    \"LUC7L2\",\"SRPK2\",\"TYW1\",\"HMBOX1\",\"LMBR1\",\"TCF12\",\"MBD5\",\"MON2\",\"COG5\",\"LONP2\",\"RAB3GAP2\",\"LARP4B\",\"NUMB\",\n",
    "    \"NF1\",\"NCOA2\",\"ZNF710\",\"CSNK1G1\",\"WDR37\",\"NUTM2B-AS1\",\"ITFG1\",\"UBE3C\",\"MFSD14C\",\"SPG11\",\"PTK2\",\"LPP\",\n",
    "    \"ZBTB20\",\"FCHO2\",\"PTPN12\",\"DCUN1D4\",\"KDM7A\",\"SLMAP\",\"KIF13B\",\"MIB1\",\"DIP2C\",\"LRCH1\",\"TNIK\",\"TNKS\",\"SMC5\",\n",
    "    \"ANKIB1\",\"RBM33\",\"TNPO3\",\"OSBPL3\",\"RAPGEF2\",\"MED13L\",\"FBXL20\",\"KIAA0232\",\"ITCH\",\"MARCH6\",\"ARID4B\",\"PLEKHA6\",\n",
    "    \"FNBP1L\",\"KIAA1217\",\"FARP2\",\"MAGI3\",\"DIAPH2\",\"VPS13A\",\"DGKH\",\"GNAQ\",\"ARHGEF12\",\"MYO1D\",\"CDC42BPA\",\"TTC7A\",\n",
    "    \"TRIM44\",\"NSD3\",\"NCOA3\",\"ADNP\",\"RUFY3\",\"RUNX1\",\"TRRAP\",\"PTBP2\",\"ZNF609\",\"CHD7\",\"PARP8\",\"ARIH1\",\"ZHX2\",\n",
    "    \"ETV6\",\"CUL1\",\"CDK13\",\"BRAF\",\"MBTD1\",\"AUH\",\"STX17\",\"POLR2J3\",\"KLHDC10\",\"TAF1\",\"TOGARAM1\",\"WRN\",\"ADK\",\n",
    "    \"TASOR2\",\"NUDCD3\",\"TBL1X\",\"MOSMO\",\"USP42\",\"CRCP\",\"GALNT11\",\"DDI2\",\"TTC14\",\"UPF2\",\"PDXDC1\",\"ETFDH\",\"SEL1L3\",\n",
    "    \"HEATR5A\",\"PSMD5\",\"TBC1D2B\",\"NUP214\",\"GAPVD1\",\"RNF19A\",\"SMURF2\",\"NRIP1\",\"WDFY2\",\"TBK1\",\"LCORL\",\"USP25\",\n",
    "    \"RABGEF1\",\"CASD1\",\"RBPJ\",\"AEBP2\",\"MALAT1\",\"MAML2\",\"RBMS1\",\"CRIM1\",\"SNX29\",\"PPFIBP1\",\"SVIL\",\"DDX24\",\"G2E3\",\n",
    "    \"RASA1\",\"FAM160A1\",\"RNF24\",\"ESYT2\",\"EPS8\",\"SESTD1\",\"ATP2B4\",\"PELI1\",\"RNF145\",\"B4GALT5\",\"PPP2R2A\",\"NOS1AP\",\n",
    "    \"EGFR\",\"CPNE8\",\"ARHGAP21\",\"SMAD3\",\"DAPK1\",\"IGF1R\",\"AFAP1\",\"KLF7\",\"DOCK5\",\"MINDY2\",\"ZXDC\",\"NEDD4\",\"METTL15\",\n",
    "    \"FNIP2\",\"NEAT1\",\"CELF1\",\"DANT2\",\"SYT17\",\"TMEM245\",\"ERICH1\",\"ADPGK\",\"LMBRD1\",\"MFSD11\",\"GOLGA2\",\"SCNN1A\",\n",
    "    \"XDH\",\"PLEKHA1\",\"PPP2CB\",\"GTF2E2\",\"KCNK1\",\"SPATS2L\",\"RTF1\",\"UACA\",\"VAV2\",\"MDFIC\",\"STAM\",\"CLIP4\",\"KYAT1\",\n",
    "    \"MECP2\",\"NUP160\",\"THOC1\",\"LINC-PINT\",\"MCPH1\",\"DISC1\",\"UBA6-AS1\",\"AAK1\",\"NRF1\",\"PHF20\",\"RNF216\",\"PCM1\",\"SAFB2\",\n",
    "    \"FAM133B\",\"NR6A1\",\"ATL2\",\"C1orf21\",\"MTUS1\",\"PARD3B\",\"EXT1\",\"ST5\",\"ABI2\",\"INTS6L\",\"TRIM56\",\"PTER\",\"PRR12\",\n",
    "    \"RSPH3\",\"TMC5\",\"MECOM\",\"ARHGEF10L\",\"HNF4G\",\"PPM1H\",\"AP005230.1\",\"AC119674.1\",\"ZSCAN18\",\"NOL4L\",\"PDPK1\",\n",
    "    \"RSU1\",\"TTC39C\",\"COL27A1\",\"SEC16B\",\"AC005162.3\",\"RASAL1\",\"IL17RA\",\"SPART-AS1\",\"CDC37\",\"MUCL3\",\"TMEM178B\",\n",
    "    \"LINC02614\",\"EREG\",\"ELK3\",\"TMTC1\",\"PALM2-AKAP2\",\"RAB31\",\"EMP3\"\n",
    "]\n",
    "MPC_DOWN = [\n",
    "    \"MRPS15\",\"TALDO1\",\"MDH2\",\"PSMB5\",\"PIK3CD-AS2\",\"DUSP9\",\"POPDC3\",\"AKR1C3\",\"MRPS18A\",\"EIF3H\",\"UQCRC2\",\n",
    "    \"IFT22\",\"RAB11B\",\"MBOAT7\"\n",
    "]\n",
    "# =====================================\n",
    "\n",
    "def parse_genes(obj):\n",
    "    \"\"\"Accept str/list/tuple/set/Series; return a clean list of symbols.\"\"\"\n",
    "    if obj is None:\n",
    "        return []\n",
    "    # pandas Series/Index\n",
    "    if hasattr(obj, \"tolist\"):\n",
    "        obj = obj.tolist()\n",
    "    # list-like (but not str/bytes)\n",
    "    if isinstance(obj, Iterable) and not isinstance(obj, (str, bytes)):\n",
    "        flat = []\n",
    "        for x in obj:\n",
    "            if x is None: continue\n",
    "            if hasattr(x, \"tolist\"):\n",
    "                flat.extend(x.tolist())\n",
    "            elif isinstance(x, (str, bytes)):\n",
    "                flat.extend(re.split(r\"[,\\s]+\", x.strip()))\n",
    "            else:\n",
    "                flat.append(str(x))\n",
    "        genes = [g for g in flat if g]\n",
    "        return genes\n",
    "    # string path: split on commas/whitespace/newlines\n",
    "    s = obj.strip()\n",
    "    if not s:\n",
    "        return []\n",
    "    s = re.sub(r\"[,\\s]+\", \"\\n\", s)\n",
    "    return [g for g in s.splitlines() if g]\n",
    "\n",
    "# Build modules (normalize keys to lower-case)\n",
    "MODULES = {\n",
    "    \"SAT\": {\"up\": parse_genes(SAT_UP), \"down\": parse_genes(SAT_DOWN)},\n",
    "    \"IGE\": {\"up\": parse_genes(IGE_UP), \"down\": parse_genes(IGE_DOWN)},\n",
    "    \"IL2\": {\"up\": parse_genes(IL2_UP), \"down\": parse_genes(IL2_DOWN)},\n",
    "    \"MPC\": {\"up\": parse_genes(MPC_UP), \"down\": parse_genes(MPC_DOWN)},\n",
    "}\n",
    "\n",
    "def score_signed_module(expr_df, up_genes, down_genes, method=\"count_weighted\", min_genes=3):\n",
    "    up = pd.Index([g.upper() for g in up_genes])\n",
    "    dn = pd.Index([g.upper() for g in down_genes])\n",
    "\n",
    "    expr_uc = expr_df.copy()\n",
    "    expr_uc.index = expr_uc.index.astype(str).str.upper()\n",
    "    expr_uc = expr_uc[~expr_uc.index.duplicated(keep=\"first\")]\n",
    "\n",
    "    up_in = up.intersection(expr_uc.index)\n",
    "    dn_in = dn.intersection(expr_uc.index)\n",
    "    n_up, n_dn = len(up_in), len(dn_in)\n",
    "    print(f\"[COVERAGE] UP {n_up}/{len(up)} | DOWN {n_dn}/{len(dn)}\")\n",
    "\n",
    "    if n_up + n_dn == 0:\n",
    "        raise ValueError(\"No module genes found in expression. Check symbols.\")\n",
    "\n",
    "    if method == \"count_weighted\":\n",
    "        # (sum(up) - sum(down)) / (n_up + n_dn)  → side with more genes has more influence\n",
    "        up_sum = expr_uc.loc[up_in].sum(axis=0) if n_up else 0.0\n",
    "        dn_sum = expr_uc.loc[dn_in].sum(axis=0) if n_dn else 0.0\n",
    "        signed = (up_sum - dn_sum) / float(n_up + n_dn)\n",
    "    elif method == \"equal_sides\":\n",
    "        up_mean = expr_uc.loc[up_in].mean(axis=0) if n_up else 0.0\n",
    "        dn_mean = expr_uc.loc[dn_in].mean(axis=0) if n_dn else 0.0\n",
    "        signed = up_mean - dn_mean\n",
    "    else:\n",
    "        raise ValueError(\"method must be 'count_weighted' or 'equal_sides'\")\n",
    "\n",
    "    signed = pd.Series(signed, index=expr_uc.columns).astype(float)\n",
    "    z = (signed - signed.mean()) / signed.std(ddof=0)\n",
    "    return signed, z, {\"n_up\": n_up, \"n_dn\": n_dn}\n",
    "\n",
    "OUT = Path(\"out_modules\"); OUT.mkdir(exist_ok=True)\n",
    "coverage = []\n",
    "for label, gd in MODULES.items():\n",
    "    print(f\"\\n=== {label} (count_weighted) ===\")\n",
    "    raw, z, cov = score_signed_module(expr, gd[\"up\"], gd[\"down\"], method=\"count_weighted\", min_genes=3)\n",
    "    raw.rename(f\"{label}_signed_score\").to_csv(OUT / f\"{label}_signed_score.csv\")\n",
    "    z.rename(f\"{label}_signed_score_Z\").to_csv(OUT / f\"{label}_signed_score_Z.csv\")\n",
    "    coverage.append({\"module\": label, **cov})\n",
    "    print(f\"[saved] {OUT / f'{label}_signed_score.csv'}\")\n",
    "    print(f\"[saved] {OUT / f'{label}_signed_score_Z.csv'}\")\n",
    "\n",
    "pd.DataFrame(coverage).to_csv(OUT / \"coverage_report.csv\", index=False)\n",
    "print(\"\\n[done] Wrote Z-scores to:\", OUT)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98a62383",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd, numpy as np\n",
    "from scipy.stats import spearmanr\n",
    "from statsmodels.stats.multitest import multipletests\n",
    "from pathlib import Path\n",
    "\n",
    "OUTDIR = Path(\"out_prism_corr\"); OUTDIR.mkdir(exist_ok=True)\n",
    "\n",
    "# --- load aligned data ---\n",
    "expr_aln  = pd.read_csv(\"out_prism_align/expr_genesXACH_shared.csv\", index_col=0)\n",
    "prism_aln = pd.read_csv(\"out_prism_align/prism_ACHXdrugs_shared.csv\", index_col=0)\n",
    "\n",
    "# --- load module Z-scores ---\n",
    "mods = {}\n",
    "for m in [\"SAT\",\"IGE\",\"IL2\",\"MPC\"]:\n",
    "    z = pd.read_csv(f\"out_modules/{m}_signed_score_Z.csv\", index_col=0).squeeze(\"columns\")\n",
    "    z.name = m\n",
    "    mods[m] = z\n",
    "\n",
    "shared = prism_aln.index.intersection(expr_aln.columns)\n",
    "print(f\"Shared ACH lines: {len(shared)}\")\n",
    "\n",
    "prism_sub = prism_aln.loc[shared, :]\n",
    "\n",
    "# --- correlations ---\n",
    "records = []\n",
    "for mod, scores in mods.items():\n",
    "    s = scores.loc[shared]\n",
    "    for drug in prism_sub.columns:\n",
    "        y = prism_sub[drug]\n",
    "        if y.isna().sum() >= len(y)-3:\n",
    "            continue\n",
    "        rho, p = spearmanr(s, y, nan_policy=\"omit\")\n",
    "        records.append((mod, drug, rho, p))\n",
    "\n",
    "df = pd.DataFrame(records, columns=[\"module\",\"drug\",\"rho\",\"pval\"])\n",
    "df[\"FDR\"] = np.nan\n",
    "for m in df[\"module\"].unique():\n",
    "    mask = df[\"module\"]==m\n",
    "    df.loc[mask,\"FDR\"] = multipletests(df.loc[mask,\"pval\"], method=\"fdr_bh\")[1]\n",
    "\n",
    "# --- save results ---\n",
    "df.to_csv(OUTDIR / \"module_vs_PRISM_spearman.csv\", index=False)\n",
    "\n",
    "tops = (\n",
    "    df.sort_values([\"module\",\"FDR\"])\n",
    "      .groupby(\"module\")\n",
    "      .head(15)\n",
    "      .reset_index(drop=True)\n",
    ")\n",
    "tops.to_csv(OUTDIR / \"module_vs_PRISM_top15.csv\", index=False)\n",
    "print(tops.head(15))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20c49bdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "matplotlib.use(\"Agg\")  # safe, non-GUI backend to avoid local display/ttf issues\n",
    "\n",
    "import pandas as pd, numpy as np, re\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from scipy.stats import spearmanr\n",
    "\n",
    "# ---------------- IO ----------------\n",
    "BASE = Path(\".\")\n",
    "CORR_PATH   = BASE/\"out_prism_corr/module_vs_PRISM_spearman.csv\"\n",
    "PRISM_PATH  = BASE/\"out_prism_align/prism_ACHXdrugs_shared.csv\"\n",
    "MOD_DIR     = BASE/\"out_modules\"\n",
    "FIG_DIR     = BASE/\"out_figs\"; FIG_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "MODULES = [\"SAT\",\"IGE\",\"IL2\",\"MPC\"]\n",
    "TOP_N_VOLC_ANNOT = 8\n",
    "TOP_N_HEATMAP    = 10\n",
    "SAVE_FORMATS = [\"png\"]  # was [\"png\",\"svg\"] # <-- no pdf\n",
    "\n",
    "# ---------------- Load data ----------------\n",
    "df = pd.read_csv(CORR_PATH)\n",
    "prism = pd.read_csv(PRISM_PATH, index_col=0)\n",
    "\n",
    "modZ = {}\n",
    "for m in MODULES:\n",
    "    s = pd.read_csv(MOD_DIR/f\"{m}_signed_score_Z.csv\", index_col=0).squeeze(\"columns\")\n",
    "    s.name = m\n",
    "    modZ[m] = s\n",
    "\n",
    "# shared ACH lines across everything\n",
    "shared = prism.index\n",
    "for m in MODULES:\n",
    "    shared = shared.intersection(modZ[m].index)\n",
    "if len(shared) == 0:\n",
    "    raise RuntimeError(\"No shared ACH lines between PRISM and module Z-scores.\")\n",
    "prism = prism.loc[shared, :]\n",
    "for m in MODULES:\n",
    "    modZ[m] = modZ[m].loc[shared]\n",
    "\n",
    "def neglog10(x):\n",
    "    x = np.asarray(x, dtype=float)\n",
    "    nz = x[x>0]\n",
    "    eps = (nz.min()/2.0) if len(nz)>0 else 1e-300\n",
    "    x = np.where(x>0, x, eps)\n",
    "    return -np.log10(x)\n",
    "\n",
    "def safe_name(s):\n",
    "    return re.sub(r\"[^A-Za-z0-9._-]+\", \"_\", str(s))\n",
    "\n",
    "# ---------------- Volcano plots ----------------\n",
    "for m in MODULES:\n",
    "    sub = df[df[\"module\"]==m].copy()\n",
    "    sub[\"neglog10FDR\"] = neglog10(sub[\"FDR\"])\n",
    "    lab = sub.sort_values([\"FDR\",\"rho\"], ascending=[True, True]).head(TOP_N_VOLC_ANNOT)\n",
    "\n",
    "    plt.figure(figsize=(5,4))\n",
    "    plt.scatter(sub[\"rho\"], sub[\"neglog10FDR\"], s=10)\n",
    "    for _, r in lab.iterrows():\n",
    "        plt.annotate(r[\"drug\"], (r[\"rho\"], r[\"neglog10FDR\"]),\n",
    "                     xytext=(3,3), textcoords=\"offset points\", fontsize=7)\n",
    "    plt.axvline(0, linestyle=\"--\", linewidth=1)\n",
    "    plt.xlabel(\"Spearman ρ (module Z  vs  PRISM AUC)\")\n",
    "    plt.ylabel(\"-log10(FDR)\")\n",
    "    plt.title(f\"{m}: Drug-response associations (PRISM)\")\n",
    "    for ext in SAVE_FORMATS:\n",
    "        plt.savefig(FIG_DIR/f\"{m}_volcano.{ext}\", bbox_inches=\"tight\", dpi=300)\n",
    "    plt.close()\n",
    "\n",
    "# ---------------- Heatmap ----------------\n",
    "drug_set = []\n",
    "for m in MODULES:\n",
    "    sub = df[df[\"module\"]==m].copy().sort_values(\"FDR\", ascending=True).head(TOP_N_HEATMAP)\n",
    "    drug_set.extend(sub[\"drug\"].tolist())\n",
    "drug_list = sorted(set(drug_set))\n",
    "\n",
    "heat = pd.DataFrame(index=MODULES, columns=drug_list, dtype=float)\n",
    "for m in MODULES:\n",
    "    sub = df[df[\"module\"]==m][[\"drug\",\"rho\"]].drop_duplicates().set_index(\"drug\")[\"rho\"]\n",
    "    heat.loc[m, :] = sub.reindex(drug_list).values\n",
    "\n",
    "H = heat.fillna(0.0).values\n",
    "plt.figure(figsize=(max(8, len(drug_list)*0.22), 2.2+0.35*len(MODULES)))\n",
    "im = plt.imshow(H, aspect=\"auto\")\n",
    "plt.colorbar(im, fraction=0.025, pad=0.02)\n",
    "plt.xticks(range(len(drug_list)), drug_list, rotation=80, ha=\"right\", fontsize=7)\n",
    "plt.yticks(range(len(MODULES)), MODULES)\n",
    "plt.title(\"Module × Drug correlation (ρ) — top hits union\")\n",
    "plt.tight_layout()\n",
    "for ext in SAVE_FORMATS:\n",
    "    plt.savefig(FIG_DIR/f\"modules_drug_corr_heatmap.{ext}\", bbox_inches=\"tight\", dpi=300)\n",
    "plt.close()\n",
    "\n",
    "# ---------------- Exemplar scatterplots ----------------\n",
    "def best_drugs_for_module(m):\n",
    "    sub = df[df[\"module\"]==m].copy()\n",
    "    neg = sub.sort_values(\"rho\", ascending=True).iloc[0]\n",
    "    pos = sub.sort_values(\"rho\", ascending=False).iloc[0]\n",
    "    return neg, pos\n",
    "\n",
    "for m in MODULES:\n",
    "    s = modZ[m]\n",
    "    neg, pos = best_drugs_for_module(m)\n",
    "\n",
    "    for tag, row in [(\"sensitive_neg_rho\", neg), (\"resistant_pos_rho\", pos)]:\n",
    "        drug = row[\"drug\"]\n",
    "        y = prism[drug]\n",
    "        valid = s.index.intersection(y.dropna().index)\n",
    "        rho, p = spearmanr(s.loc[valid], y.loc[valid], nan_policy=\"omit\")\n",
    "\n",
    "        plt.figure(figsize=(4.2,3.6))\n",
    "        plt.scatter(s.loc[valid], y.loc[valid], s=14)\n",
    "        plt.xlabel(f\"{m} module Z-score\")\n",
    "        plt.ylabel(f\"{drug} PRISM AUC\")\n",
    "        plt.title(f\"{m} vs {drug}\\nρ={rho:.2f}, p={p:.2g}\")\n",
    "        for ext in SAVE_FORMATS:\n",
    "            plt.savefig(FIG_DIR/f\"{m}_{tag}_{safe_name(drug)}.{ext}\", bbox_inches=\"tight\", dpi=300)\n",
    "        plt.close()\n",
    "\n",
    "print(\"Saved figures to:\", FIG_DIR.resolve())\n",
    "for p in sorted(FIG_DIR.glob(\"*\")):\n",
    "    print(\" -\", p.name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd2b3add",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== Focus on vulnerabilities only: rho < 0 (module-high => more sensitive) =====\n",
    "# Outputs:\n",
    "#  - out_prism_corr/module_negatives_top.csv  (annotated table)\n",
    "#  - out_figs/{MODULE}_neg_lollipop.png       (top sensitive drugs per module)\n",
    "#  - out_figs/{MODULE}_neg_mech_meanrho.png   (mean rho by mechanism)\n",
    "# ================================================================================\n",
    "\n",
    "import matplotlib\n",
    "matplotlib.use(\"Agg\")  # safe, non-GUI backend\n",
    "\n",
    "import pandas as pd, numpy as np, re\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "\n",
    "# ---------------- Paths / settings ----------------\n",
    "BASE = Path(\".\")\n",
    "CORR_PATH = BASE / \"out_prism_corr/module_vs_PRISM_spearman.csv\"\n",
    "OUTDIR    = BASE / \"out_prism_corr\"; OUTDIR.mkdir(exist_ok=True)\n",
    "FIG_DIR   = BASE / \"out_figs\"; FIG_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "MODULES = [\"SAT\",\"IGE\",\"IL2\",\"MPC\"]\n",
    "TOP_N_PER_MODULE = 15       # top negatives to label per module\n",
    "MIN_MECH_COUNT   = 2        # group sparse mechanisms into \"Other (misc.)\" for cleaner plots\n",
    "\n",
    "# ---------------- Load ----------------\n",
    "df = pd.read_csv(CORR_PATH)\n",
    "assert {\"module\",\"drug\",\"rho\",\"FDR\"}.issubset(df.columns)\n",
    "\n",
    "# Keep only requested modules and NEGATIVE rho (sensitivities)\n",
    "df = df[df[\"module\"].isin(MODULES)].copy()\n",
    "neg = df[df[\"rho\"] < 0].copy()\n",
    "\n",
    "# ---------------- Mechanism map (edit/extend freely; case-insensitive) ----------------\n",
    "MECH_MAP_RAW = {\n",
    "    # DNA repair / replication stress\n",
    "    \"talazoparib\": \"PARP inhibitor / DNA repair\",\n",
    "    \"3-amino-benzamide\": \"PARP inhibitor (early gen)\",\n",
    "    \"10-hydroxycamptothecin\": \"Topoisomerase I inhibitor\",\n",
    "    \"5-fluorouracil\": \"Antimetabolite (TS inhibitor)\",\n",
    "    \"cyclophosphamide\": \"Alkylating agent (DNA cross-linker)\",\n",
    "\n",
    "    # Splicing / RNA processing\n",
    "    \"indisulam\": \"Spliceosome / RNA-processing inhibitor\",\n",
    "\n",
    "    # Oxidative / ROS / redox & checkpoint stress\n",
    "    \"bis(maltolato)oxovanadium(iv)\": \"Oxidative-stress inducer (vanadium)\",\n",
    "    \"2,3-dcpe\": \"DNA damage / S-phase checkpoint inducer\",\n",
    "    \"2-methoxyestradiol\": \"Microtubule disruptor / HIF-1 inhibitor\",\n",
    "\n",
    "    # RTK axis (usually appears as POS rho; included for completeness if any NEG show)\n",
    "    \"alpelisib\": \"PI3Kα inhibitor\",\n",
    "    \"dacomitinib\": \"ERBB/EGFR inhibitor (pan-ERBB)\",\n",
    "    \"bms-690514\": \"Multi-RTK inhibitor (ErbB/FGF/VEGFR)\",\n",
    "    \"xl-647\": \"EGFR/VEGFR/ERBB inhibitor\",\n",
    "    \"golvatinib\": \"MET/VEGFR/RTK inhibitor\",\n",
    "\n",
    "    # GPCR/hormonal/other (some may show NEG via off-targets)\n",
    "    \"bephenium-hydroxynaphthoate\": \"Anthelmintic (nicotinic agonist)\",\n",
    "    \"lacitol\": \"Osmotic laxative / carbohydrate analog\",\n",
    "}\n",
    "\n",
    "def norm_name(s: str) -> str:\n",
    "    s = str(s).lower().strip()\n",
    "    s = s.replace(\"’\", \"'\").replace(\"“\",\"\\\"\").replace(\"”\",\"\\\"\")\n",
    "    s = s.replace(\"–\",\"-\").replace(\"—\",\"-\")\n",
    "    s = re.sub(r\"\\s+\", \" \", s)\n",
    "    return s\n",
    "\n",
    "MECH_MAP = {k.strip().lower(): v for k, v in MECH_MAP_RAW.items() if isinstance(k, str)}\n",
    "neg[\"drug_norm\"] = neg[\"drug\"].map(norm_name)\n",
    "neg[\"mechanism\"] = neg[\"drug_norm\"].map(MECH_MAP).fillna(\"Unknown/Other\")\n",
    "\n",
    "# ---------------- Select top (FDR, then most negative rho) per module ----------------\n",
    "tops = []\n",
    "for m in MODULES:\n",
    "    sub = neg[neg[\"module\"]==m].copy()\n",
    "    sub = sub.sort_values([\"FDR\", \"rho\"], ascending=[True, True])  # rho ascending → most negative first\n",
    "    tops.append(sub.head(TOP_N_PER_MODULE))\n",
    "top_neg = pd.concat(tops, ignore_index=True)\n",
    "\n",
    "# Save annotated table\n",
    "out_csv = OUTDIR / \"module_negatives_top.csv\"\n",
    "top_neg[[\"module\",\"drug\",\"mechanism\",\"rho\",\"FDR\"]].to_csv(out_csv, index=False)\n",
    "print(f\"[saved] {out_csv}\")\n",
    "\n",
    "# ---------------- Optionally collapse sparse mechanisms for plotting ----------------\n",
    "mech_counts = top_neg[\"mechanism\"].value_counts()\n",
    "sparse = set(mech_counts[mech_counts < MIN_MECH_COUNT].index)\n",
    "def mech_for_plot(x): return \"Other (misc.)\" if x in sparse else x\n",
    "top_neg[\"mechanism_plot\"] = top_neg[\"mechanism\"].map(mech_for_plot)\n",
    "\n",
    "# ---------------- Per-module lollipop of top sensitive drugs ----------------\n",
    "for m in MODULES:\n",
    "    sub = top_neg[top_neg[\"module\"]==m].copy()\n",
    "    if sub.empty:\n",
    "        print(f\"[warn] No negative-rho hits for {m}.\")\n",
    "        continue\n",
    "\n",
    "    # sort by rho (most negative at bottom for prettier up-left stems)\n",
    "    sub = sub.sort_values(\"rho\", ascending=True)\n",
    "    ylabels = sub[\"drug\"].tolist()\n",
    "    y = np.arange(len(sub))\n",
    "\n",
    "    plt.figure(figsize=(8, max(4, 0.35*len(sub)+1)))\n",
    "    # stems\n",
    "    for i, rho in enumerate(sub[\"rho\"]):\n",
    "        plt.plot([rho, 0], [i, i], linewidth=1)\n",
    "    # markers at rho\n",
    "    plt.scatter(sub[\"rho\"], y, s=20)\n",
    "    plt.axvline(0, linestyle=\"--\", linewidth=1)\n",
    "    plt.yticks(y, ylabels)\n",
    "    plt.xlabel(\"Spearman ρ (module Z vs PRISM AUC)  —  ρ < 0 ⇒ sensitivity\")\n",
    "    plt.title(f\"{m} — Top sensitive drugs (negative ρ)\")\n",
    "    plt.tight_layout()\n",
    "    outp = FIG_DIR / f\"{m}_neg_lollipop.png\"\n",
    "    plt.savefig(outp, dpi=300)\n",
    "    plt.close()\n",
    "    print(f\"[saved] {outp}\")\n",
    "\n",
    "# ---------------- Per-module mechanism summary (mean rho among negatives) ----------------\n",
    "for m in MODULES:\n",
    "    sub = top_neg[top_neg[\"module\"]==m]\n",
    "    if sub.empty:\n",
    "        continue\n",
    "    g = sub.groupby(\"mechanism_plot\")[\"rho\"].mean().sort_values()  # more negative on top\n",
    "    plt.figure(figsize=(8, max(4, 0.4*len(g)+1)))\n",
    "    y = np.arange(len(g))\n",
    "    plt.barh(y, g.values)\n",
    "    plt.axvline(0, linestyle=\"--\", linewidth=1)\n",
    "    plt.yticks(y, g.index.tolist())\n",
    "    plt.xlabel(\"Mean Spearman ρ (more negative ⇒ stronger sensitivity)\")\n",
    "    plt.title(f\"{m} — Mechanism classes among top sensitive hits\")\n",
    "    plt.tight_layout()\n",
    "    outp = FIG_DIR / f\"{m}_neg_mech_meanrho.png\"\n",
    "    plt.savefig(outp, dpi=300)\n",
    "    plt.close()\n",
    "    print(f\"[saved] {outp}\")\n",
    "\n",
    "print(\"\\nINTERPRETATION NOTES:\")\n",
    "print(\" - We’re showing drugs with ρ < 0 only: module-high lines are more sensitive (lower AUC).\")\n",
    "print(\" - Lollipop: each stem ends at the drug’s ρ (more negative = stronger sensitivity).\")\n",
    "print(\" - Mechanism plot: average ρ per mechanism among top hits (more negative = stronger class-level vulnerability).\")\n",
    "print(\" - Refine MECH_MAP_RAW above to replace 'Unknown/Other' with precise classes (PARP, JAK/STAT, ERBB, Complex I, etc.).\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f37d49d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== Focus on vulnerabilities only: rho < 0 (module-high => more sensitive) =====\n",
    "# Outputs:\n",
    "#  - out_prism_corr/module_negatives_top.csv  (annotated table)\n",
    "#  - out_figs/{MODULE}_neg_lollipop.png       (top sensitive drugs per module)\n",
    "#  - out_figs/{MODULE}_neg_mech_meanrho.png   (mean rho by mechanism)\n",
    "# ================================================================================\n",
    "\n",
    "import matplotlib\n",
    "matplotlib.use(\"Agg\")  # safe, non-GUI backend\n",
    "\n",
    "import pandas as pd, numpy as np, re\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "\n",
    "# ---------------- Paths / settings ----------------\n",
    "BASE = Path(\".\")\n",
    "CORR_PATH = BASE / \"out_prism_corr/module_vs_PRISM_spearman.csv\"\n",
    "OUTDIR    = BASE / \"out_prism_corr\"; OUTDIR.mkdir(exist_ok=True)\n",
    "FIG_DIR   = BASE / \"out_figs\"; FIG_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "MODULES = [\"SAT\",\"IGE\",\"IL2\",\"MPC\"]\n",
    "TOP_N_PER_MODULE = 15       # top negatives to label per module\n",
    "MIN_MECH_COUNT   = 2        # group sparse mechanisms into \"Other (misc.)\" for cleaner plots\n",
    "\n",
    "# ---------------- Load ----------------\n",
    "df = pd.read_csv(CORR_PATH)\n",
    "assert {\"module\",\"drug\",\"rho\",\"FDR\"}.issubset(df.columns)\n",
    "\n",
    "# Keep only requested modules and NEGATIVE rho (sensitivities)\n",
    "df = df[df[\"module\"].isin(MODULES)].copy()\n",
    "neg = df[df[\"rho\"] < 0].copy()\n",
    "\n",
    "# ---------------- Mechanism map (edit/extend freely; case-insensitive) ----------------\n",
    "MECH_MAP_RAW = {\n",
    "    # DNA repair / replication stress\n",
    "    \"talazoparib\": \"PARP inhibitor / DNA repair\",\n",
    "    \"3-amino-benzamide\": \"PARP inhibitor (early gen)\",\n",
    "    \"10-hydroxycamptothecin\": \"Topoisomerase I inhibitor\",\n",
    "    \"5-fluorouracil\": \"Antimetabolite (TS inhibitor)\",\n",
    "    \"cyclophosphamide\": \"Alkylating agent (DNA cross-linker)\",\n",
    "\n",
    "    # Splicing / RNA processing\n",
    "    \"indisulam\": \"Spliceosome / RNA-processing inhibitor\",\n",
    "\n",
    "    # Oxidative / ROS / redox & checkpoint stress\n",
    "    \"bis(maltolato)oxovanadium(iv)\": \"Oxidative-stress inducer (vanadium)\",\n",
    "    \"2,3-dcpe\": \"DNA damage / S-phase checkpoint inducer\",\n",
    "    \"2-methoxyestradiol\": \"Microtubule disruptor / HIF-1 inhibitor\",\n",
    "\n",
    "    # RTK axis (usually appears as POS rho; included for completeness if any NEG show)\n",
    "    \"alpelisib\": \"PI3Kα inhibitor\",\n",
    "    \"dacomitinib\": \"ERBB/EGFR inhibitor (pan-ERBB)\",\n",
    "    \"bms-690514\": \"Multi-RTK inhibitor (ErbB/FGF/VEGFR)\",\n",
    "    \"xl-647\": \"EGFR/VEGFR/ERBB inhibitor\",\n",
    "    \"golvatinib\": \"MET/VEGFR/RTK inhibitor\",\n",
    "\n",
    "    # GPCR/hormonal/other (some may show NEG via off-targets)\n",
    "    \"bephenium-hydroxynaphthoate\": \"Anthelmintic (nicotinic agonist)\",\n",
    "    \"lacitol\": \"Osmotic laxative / carbohydrate analog\",\n",
    "}\n",
    "\n",
    "def norm_name(s: str) -> str:\n",
    "    s = str(s).lower().strip()\n",
    "    s = s.replace(\"’\", \"'\").replace(\"“\",\"\\\"\").replace(\"”\",\"\\\"\")\n",
    "    s = s.replace(\"–\",\"-\").replace(\"—\",\"-\")\n",
    "    s = re.sub(r\"\\s+\", \" \", s)\n",
    "    return s\n",
    "\n",
    "MECH_MAP = {k.strip().lower(): v for k, v in MECH_MAP_RAW.items() if isinstance(k, str)}\n",
    "neg[\"drug_norm\"] = neg[\"drug\"].map(norm_name)\n",
    "neg[\"mechanism\"] = neg[\"drug_norm\"].map(MECH_MAP).fillna(\"Unknown/Other\")\n",
    "\n",
    "# ---------------- Select top (FDR, then most negative rho) per module ----------------\n",
    "tops = []\n",
    "for m in MODULES:\n",
    "    sub = neg[neg[\"module\"]==m].copy()\n",
    "    sub = sub.sort_values([\"FDR\", \"rho\"], ascending=[True, True])  # rho ascending → most negative first\n",
    "    tops.append(sub.head(TOP_N_PER_MODULE))\n",
    "top_neg = pd.concat(tops, ignore_index=True)\n",
    "\n",
    "# Save annotated table\n",
    "out_csv = OUTDIR / \"module_negatives_top.csv\"\n",
    "top_neg[[\"module\",\"drug\",\"mechanism\",\"rho\",\"FDR\"]].to_csv(out_csv, index=False)\n",
    "print(f\"[saved] {out_csv}\")\n",
    "\n",
    "# ---------------- Optionally collapse sparse mechanisms for plotting ----------------\n",
    "mech_counts = top_neg[\"mechanism\"].value_counts()\n",
    "sparse = set(mech_counts[mech_counts < MIN_MECH_COUNT].index)\n",
    "def mech_for_plot(x): return \"Other (misc.)\" if x in sparse else x\n",
    "top_neg[\"mechanism_plot\"] = top_neg[\"mechanism\"].map(mech_for_plot)\n",
    "\n",
    "# ---------------- Per-module lollipop of top sensitive drugs ----------------\n",
    "for m in MODULES:\n",
    "    sub = top_neg[top_neg[\"module\"]==m].copy()\n",
    "    if sub.empty:\n",
    "        print(f\"[warn] No negative-rho hits for {m}.\")\n",
    "        continue\n",
    "\n",
    "    # sort by rho (most negative at bottom for prettier up-left stems)\n",
    "    sub = sub.sort_values(\"rho\", ascending=True)\n",
    "    ylabels = sub[\"drug\"].tolist()\n",
    "    y = np.arange(len(sub))\n",
    "\n",
    "    plt.figure(figsize=(8, max(4, 0.35*len(sub)+1)))\n",
    "    # stems\n",
    "    for i, rho in enumerate(sub[\"rho\"]):\n",
    "        plt.plot([rho, 0], [i, i], linewidth=1)\n",
    "    # markers at rho\n",
    "    plt.scatter(sub[\"rho\"], y, s=20)\n",
    "    plt.axvline(0, linestyle=\"--\", linewidth=1)\n",
    "    plt.yticks(y, ylabels)\n",
    "    plt.xlabel(\"Spearman ρ (module Z vs PRISM AUC)  —  ρ < 0 ⇒ sensitivity\")\n",
    "    plt.title(f\"{m} — Top sensitive drugs (negative ρ)\")\n",
    "    plt.tight_layout()\n",
    "    outp = FIG_DIR / f\"{m}_neg_lollipop.png\"\n",
    "    plt.savefig(outp, dpi=300)\n",
    "    plt.close()\n",
    "    print(f\"[saved] {outp}\")\n",
    "\n",
    "# ---------------- Per-module mechanism summary (mean rho among negatives) ----------------\n",
    "for m in MODULES:\n",
    "    sub = top_neg[top_neg[\"module\"]==m]\n",
    "    if sub.empty:\n",
    "        continue\n",
    "    g = sub.groupby(\"mechanism_plot\")[\"rho\"].mean().sort_values()  # more negative on top\n",
    "    plt.figure(figsize=(8, max(4, 0.4*len(g)+1)))\n",
    "    y = np.arange(len(g))\n",
    "    plt.barh(y, g.values)\n",
    "    plt.axvline(0, linestyle=\"--\", linewidth=1)\n",
    "    plt.yticks(y, g.index.tolist())\n",
    "    plt.xlabel(\"Mean Spearman ρ (more negative ⇒ stronger sensitivity)\")\n",
    "    plt.title(f\"{m} — Mechanism classes among top sensitive hits\")\n",
    "    plt.tight_layout()\n",
    "    outp = FIG_DIR / f\"{m}_neg_mech_meanrho.png\"\n",
    "    plt.savefig(outp, dpi=300)\n",
    "    plt.close()\n",
    "    print(f\"[saved] {outp}\")\n",
    "\n",
    "print(\"\\nINTERPRETATION NOTES:\")\n",
    "print(\" - We’re showing drugs with ρ < 0 only: module-high lines are more sensitive (lower AUC).\")\n",
    "print(\" - Lollipop: each stem ends at the drug’s ρ (more negative = stronger sensitivity).\")\n",
    "print(\" - Mechanism plot: average ρ per mechanism among top hits (more negative = stronger class-level vulnerability).\")\n",
    "print(\" - Refine MECH_MAP_RAW above to replace 'Unknown/Other' with precise classes (PARP, JAK/STAT, ERBB, Complex I, etc.).\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "364cbc34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================= DepMap Chronos (rows=samples, cols=genes) → genes×ACH; correlate vs module Z =================\n",
    "import pandas as pd, numpy as np, re\n",
    "from pathlib import Path\n",
    "from glob import glob\n",
    "from scipy.stats import spearmanr\n",
    "from statsmodels.stats.multitest import multipletests\n",
    "\n",
    "# ----- your PDAC name map -----\n",
    "mapping_dict = {\n",
    "    \"ACH-000022\": \"PATU8988S\", \"ACH-000023\": \"PATU8988T\", \"ACH-000094\": \"HPAFII\",\n",
    "    \"ACH-000108\": \"KP3\", \"ACH-000114\": \"SU8686\", \"ACH-000118\": \"HUPT3\",\n",
    "    \"ACH-000138\": \"CFPAC1\", \"ACH-000178\": \"HS766T\", \"ACH-000205\": \"PK59\",\n",
    "    \"ACH-000213\": \"HUPT4\", \"ACH-000222\": \"ASPC1\", \"ACH-000265\": \"KP4\",\n",
    "    \"ACH-000307\": \"PK1\", \"ACH-000332\": \"YAPC\", \"ACH-000354\": \"CAPAN1\",\n",
    "    \"ACH-000502\": \"TCCPAN2\", \"ACH-000517\": \"SNU410\", \"ACH-000652\": \"SUIT2\",\n",
    "    \"ACH-000685\": \"L33\", \"ACH-001376\": \"PACADD135\", \"ACH-001379\": \"PACADD161\",\n",
    "    \"ACH-001380\": \"PACADD165\", \"ACH-001382\": \"PACADD188\", \"ACH-002039\": \"PK8\",\n",
    "    \"ACH-003161\": \"ABMT9430\", \"ACH-003433\": \"CCLFPANC0019T\"\n",
    "}\n",
    "ach_to_name = {k.upper(): v for k, v in mapping_dict.items()}\n",
    "\n",
    "# ----- paths -----\n",
    "BASE       = Path(\".\")\n",
    "ALIGN_DIR  = BASE/\"out_prism_align\"\n",
    "MODULE_DIR = BASE/\"out_modules\"\n",
    "OUTDIR     = BASE/\"out_depmap_corr\"; OUTDIR.mkdir(exist_ok=True)\n",
    "\n",
    "# ----- shared ACH from PRISM align -----\n",
    "prism_aln = pd.read_csv(ALIGN_DIR/\"prism_ACHXdrugs_shared.csv\", index_col=0)\n",
    "shared_ach = prism_aln.index.astype(str).str.upper().tolist()\n",
    "shared_set = set(shared_ach)\n",
    "print(f\"[align] Using {len(shared_ach)} shared ACH lines.\")\n",
    "\n",
    "# ----- find/load Chronos (the 'inverted' wide file: rows=samples, cols=genes) -----\n",
    "def find_first(patterns):\n",
    "    for pat in patterns:\n",
    "        hits = sorted(glob(str(pat)))\n",
    "        if hits: return Path(hits[0])\n",
    "    return None\n",
    "\n",
    "cand = find_first([\n",
    "    BASE/\"CRISPR_*Chronos*subsetted*.csv\", BASE/\"CRISPR_*Chronos*.csv\",\n",
    "    Path.home()/\"Desktop/CRISPR_*Chronos*subsetted*.csv\", Path.home()/\"Desktop/CRISPR_*Chronos*.csv\",\n",
    "    Path.home()/\"Downloads/CRISPR_*Chronos*subsetted*.csv\", Path.home()/\"Downloads/CRISPR_*Chronos*.csv\",\n",
    "])\n",
    "assert cand is not None, \"Chronos CSV not found.\"\n",
    "dep = pd.read_csv(cand)\n",
    "print(\"[dep raw]\", dep.shape)\n",
    "\n",
    "# Heuristic: if MANY column names look like gene symbols (A1BG, A1CF, ...),\n",
    "# assume this is SAMPLES × GENES and the first column is a sample identifier.\n",
    "cols_lower = [c.lower() for c in dep.columns]\n",
    "# pick an ID column if present, else use first column\n",
    "id_col = next((c for c in dep.columns if c.lower() in {\"depmap_id\",\"modelid\",\"model_id\",\"ach_id\",\"sample\",\"cell_line\"}), dep.columns[0])\n",
    "dep = dep.set_index(id_col)\n",
    "print(\"[dep samples×genes]\", dep.shape)\n",
    "\n",
    "# ----- extract ACH IDs from the ROW index -----\n",
    "def extract_ach(s):\n",
    "    s = str(s)\n",
    "    m = re.search(r\"ACH-\\d{6}\", s, flags=re.IGNORECASE)\n",
    "    return m.group(0).upper() if m else None\n",
    "\n",
    "row_ach = pd.Index([extract_ach(x) for x in dep.index], name=\"ACH\")\n",
    "mask = [a in shared_set for a in row_ach]\n",
    "if sum(mask) == 0:\n",
    "    # sometimes the raw index IS the ACH already\n",
    "    row_ach = pd.Index([x.upper() if isinstance(x,str) and x.upper().startswith(\"ACH-\") else None for x in dep.index], name=\"ACH\")\n",
    "    mask = [a in shared_set for a in row_ach]\n",
    "\n",
    "assert sum(mask) > 0, \"Could not extract any ACH-###### from row index; show a few row names to adjust parser.\"\n",
    "\n",
    "# keep only shared ACH rows & set ACH as index\n",
    "dep_rows = dep.loc[mask].copy()\n",
    "dep_rows.index = row_ach[mask]\n",
    "dep_rows = dep_rows.loc[dep_rows.index.intersection(shared_ach)]\n",
    "print(\"[dep filtered rows (ACH×genes)]\", dep_rows.shape)\n",
    "\n",
    "# ----- transpose to GENES × ACH (what the correlator expects) -----\n",
    "wide_ach = dep_rows.T  # genes × ACH\n",
    "# reorder ACH columns to shared order\n",
    "wide_ach = wide_ach.reindex(columns=shared_ach)\n",
    "print(\"[dep genes×ACH]\", wide_ach.shape)\n",
    "\n",
    "# ----- dependency strength = −Chronos (Chronos more negative = more essential) -----\n",
    "dep_strength = -wide_ach\n",
    "\n",
    "# ----- load module Z and align -----\n",
    "mods = {}\n",
    "for m in [\"SAT\",\"IGE\",\"IL2\",\"MPC\"]:\n",
    "    s = pd.read_csv(MODULE_DIR/f\"{m}_signed_score_Z.csv\", index_col=0).squeeze(\"columns\")\n",
    "    s = s.reindex(shared_ach).astype(float)\n",
    "    s.name = m\n",
    "    mods[m] = s\n",
    "\n",
    "# ----- correlate (Spearman) per gene -----\n",
    "records = []\n",
    "for m, s in mods.items():\n",
    "    D = dep_strength.loc[:, s.index]  # genes × ACH\n",
    "    for gene, row in D.iterrows():\n",
    "        if row.isna().sum() >= len(row) - 3:\n",
    "            continue\n",
    "        rho, p = spearmanr(s, row, nan_policy=\"omit\")\n",
    "        records.append((m, gene, rho, p))\n",
    "\n",
    "res = pd.DataFrame(records, columns=[\"module\",\"gene\",\"rho\",\"pval\"])\n",
    "# FDR per module\n",
    "res[\"FDR\"] = np.nan\n",
    "for m in res[\"module\"].unique():\n",
    "    idx = res[\"module\"]==m\n",
    "    res.loc[idx,\"FDR\"] = multipletests(res.loc[idx,\"pval\"], method=\"fdr_bh\")[1]\n",
    "\n",
    "# ----- save -----\n",
    "OUTDIR.mkdir(exist_ok=True)\n",
    "full_path = OUTDIR/\"module_vs_dependency_strength_spearman.csv\"\n",
    "res.to_csv(full_path, index=False)\n",
    "print(f\"[saved] {full_path} (rows={len(res)})\")\n",
    "\n",
    "topk = (res.sort_values([\"module\",\"FDR\",\"rho\"], ascending=[True, True, False])\n",
    "          .groupby(\"module\").head(50).reset_index(drop=True))\n",
    "top_path = OUTDIR/\"module_vs_dependency_strength_TOP50_per_module.csv\"\n",
    "topk.to_csv(top_path, index=False)\n",
    "print(f\"[saved] {top_path}\")\n",
    "\n",
    "# ----- small key (ACH ↔ PDAC name) for readability -----\n",
    "pd.Series({ach: ach_to_name.get(ach, ach) for ach in shared_ach}, name=\"PDAC_line_name\")\\\n",
    "  .to_csv(OUTDIR/\"ACH_to_name_key.csv\")\n",
    "print(f\"[saved] {OUTDIR/'ACH_to_name_key.csv'}\")\n",
    "\n",
    "# ----- quick previews -----\n",
    "def preview(mod, n=12):\n",
    "    sub = topk[topk[\"module\"]==mod].head(n)\n",
    "    if sub.empty:\n",
    "        print(f\"{mod}: (no rows)\")\n",
    "    else:\n",
    "        print(f\"\\n[{mod}] top {len(sub)} (ρ>0 ⇒ module-high lines more dependent):\")\n",
    "        print(sub[[\"gene\",\"rho\",\"FDR\"]].to_string(index=False))\n",
    "\n",
    "for m in [\"SAT\",\"IGE\",\"IL2\",\"MPC\"]:\n",
    "    preview(m, 12)\n",
    "\n",
    "print(\"\\nNOTE: We detected SAMPLES×GENES input, extracted ACH IDs from the **row index**,\")\n",
    "print(\"      kept the 30 shared ACH, transposed to GENES×ACH, and used −Chronos so ρ>0 = vulnerability.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d8cd446",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== Two-sided pathway analysis on dependency correlations (robust FDR handling) =====\n",
    "import pandas as pd, numpy as np\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import gseapy as gp\n",
    "from statsmodels.stats.multitest import multipletests\n",
    "\n",
    "BASE    = Path(\".\")\n",
    "INFILE  = BASE/\"out_depmap_corr/module_vs_dependency_strength_spearman.csv\"\n",
    "OUTDIR  = BASE/\"out_depmap_gsea\"; OUTDIR.mkdir(exist_ok=True)\n",
    "\n",
    "TOP_PLOT = 15\n",
    "TOP_LE   = 10\n",
    "TOPK_ORA = 300\n",
    "\n",
    "# --- Discover available libraries and pick defaults ---\n",
    "avail = set(gp.get_library_name())\n",
    "def pick_lib(preferred, fallback_any=None):\n",
    "    for kw in preferred:\n",
    "        for lib in avail:\n",
    "            if kw.lower() in lib.lower():\n",
    "                return lib\n",
    "    if fallback_any:\n",
    "        for lib in avail:\n",
    "            if fallback_any.lower() in lib.lower():\n",
    "                return lib\n",
    "    for lib in [\"Reactome_2023\",\"Reactome_2022\",\"GO_Biological_Process_2023\",\"KEGG_2021_Human\"]:\n",
    "        if lib in avail: return lib\n",
    "    return next(iter(avail)) if avail else None\n",
    "\n",
    "PRERANK_LIB = pick_lib([\"MSigDB_Hallmark\",\"Hallmark\"])\n",
    "ORA_LIB     = pick_lib([\"Reactome_2023\",\"Reactome_2022\"], fallback_any=\"Reactome\")\n",
    "if PRERANK_LIB is None:\n",
    "    raise RuntimeError(\"No gene-set libraries detected by gseapy.\")\n",
    "print(f\"[libs] Using PRERANK_LIB={PRERANK_LIB}  |  ORA_LIB={ORA_LIB}\")\n",
    "\n",
    "# --- Load correlations ---\n",
    "df = pd.read_csv(INFILE)\n",
    "assert {\"module\",\"gene\",\"rho\"}.issubset(df.columns), \"Input missing module/gene/rho.\"\n",
    "modules = df[\"module\"].dropna().unique().tolist()\n",
    "\n",
    "def make_ranks(df_mod: pd.DataFrame) -> pd.Series:\n",
    "    r = (df_mod.groupby(\"gene\", as_index=True)[\"rho\"].mean()).sort_values(ascending=False)\n",
    "    # tiny deterministic tie-break to avoid duplicated-ranks warning\n",
    "    tb = pd.Series(np.linspace(0, 1e-9, num=len(r), endpoint=False), index=r.index)\n",
    "    return r + tb\n",
    "\n",
    "def normalize_cols(res_df: pd.DataFrame) -> pd.DataFrame:\n",
    "    # unify column names to snake_case lowercase\n",
    "    res = res_df.copy()\n",
    "    res.columns = [c.strip().lower().replace(\" \", \"_\").replace(\"-\", \"_\") for c in res.columns]\n",
    "    return res\n",
    "\n",
    "def ensure_fdr(res: pd.DataFrame) -> pd.DataFrame:\n",
    "    # map common variants or compute from pval\n",
    "    colmap = {\n",
    "        \"fdr_q_val\": \"fdr\", \"fdr_qval\": \"fdr\", \"fdr_q\": \"fdr\",\n",
    "        \"fdr_q_value\": \"fdr\", \"fdr_q_value_adj\": \"fdr\",\n",
    "        \"fdr_q_value_(bh)\": \"fdr\", \"adj_p_value\": \"fdr\", \"adjusted_p_value\": \"fdr\",\n",
    "    }\n",
    "    res = res.copy()\n",
    "    for src, dst in colmap.items():\n",
    "        if src in res.columns and \"fdr\" not in res.columns:\n",
    "            res[\"fdr\"] = res[src]\n",
    "            break\n",
    "    if \"fdr\" not in res.columns:\n",
    "        if \"pval\" in res.columns:\n",
    "            res[\"fdr\"] = multipletests(res[\"pval\"].astype(float), method=\"fdr_bh\")[1]\n",
    "        elif \"p_value\" in res.columns:\n",
    "            res[\"fdr\"] = multipletests(res[\"p_value\"].astype(float), method=\"fdr_bh\")[1]\n",
    "        else:\n",
    "            # last resort: make a neutral column so downstream code runs\n",
    "            res[\"fdr\"] = np.nan\n",
    "    return res\n",
    "\n",
    "def extract_leading_edge(res_slice: pd.DataFrame) -> pd.DataFrame:\n",
    "    out = []\n",
    "    for term, row in res_slice.iterrows():\n",
    "        for col in [\"lead_genes\",\"ledge_genes\",\"le_genes\",\"leading_edge\"]:\n",
    "            val = row.get(col, None)\n",
    "            if isinstance(val, str) and val:\n",
    "                genes = [g for g in val.split(\",\") if g]\n",
    "                out.append({\"term\": term, \"genes\": \";\".join(genes)})\n",
    "                break\n",
    "    return pd.DataFrame(out)\n",
    "\n",
    "def preranked_module(module: str):\n",
    "    sub = df[df[\"module\"]==module].dropna(subset=[\"gene\",\"rho\"]).copy()\n",
    "    ranks = make_ranks(sub)\n",
    "    rnk_df = ranks.reset_index()\n",
    "    rnk_df.columns = [\"gene\", \"score\"]\n",
    "\n",
    "    pre = gp.prerank(\n",
    "        rnk=rnk_df,\n",
    "        gene_sets=PRERANK_LIB,\n",
    "        threads=4,\n",
    "        permutation_num=1000,\n",
    "        min_size=10, max_size=500,\n",
    "        outdir=None, seed=42, verbose=False,\n",
    "    )\n",
    "    res = normalize_cols(pre.res2d)\n",
    "    res = ensure_fdr(res)\n",
    "\n",
    "    # some gseapy versions keep gene set name as index, others as a column like 'term' or 'name'\n",
    "    if \"term\" in res.columns and res.index.name is None:\n",
    "        res = res.set_index(\"term\")\n",
    "    # Sort by FDR safely\n",
    "    res = res.sort_values(\"fdr\", ascending=True)\n",
    "\n",
    "    out_csv = OUTDIR/f\"{module}_GSEA_{PRERANK_LIB}.csv\"\n",
    "    res.to_csv(out_csv)\n",
    "    print(f\"[saved] {out_csv}\")\n",
    "\n",
    "    pos = res[res[\"nes\"]>0].head(TOP_PLOT)\n",
    "    neg = res[res[\"nes\"]<0].head(TOP_PLOT)\n",
    "\n",
    "    if not pos.empty:\n",
    "        plt.figure(figsize=(7,5))\n",
    "        plt.barh(pos.index[::-1], pos[\"nes\"][::-1])\n",
    "        plt.axvline(0, ls=\"--\", lw=1)\n",
    "        plt.title(f\"{module} — GSEA ({PRERANK_LIB}) top positive NES\")\n",
    "        plt.xlabel(\"Normalized Enrichment Score (NES)\")\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(OUTDIR/f\"{module}_GSEA_{PRERANK_LIB}_topPOS.png\", dpi=300)\n",
    "        plt.close()\n",
    "\n",
    "    if not neg.empty:\n",
    "        plt.figure(figsize=(7,5))\n",
    "        plt.barh(neg.index[::-1], neg[\"nes\"][::-1])\n",
    "        plt.axvline(0, ls=\"--\", lw=1)\n",
    "        plt.title(f\"{module} — GSEA ({PRERANK_LIB}) top negative NES\")\n",
    "        plt.xlabel(\"Normalized Enrichment Score (NES)\")\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(OUTDIR/f\"{module}_GSEA_{PRERANK_LIB}_topNEG.png\", dpi=300)\n",
    "        plt.close()\n",
    "\n",
    "    if not pos.empty:\n",
    "        le_pos = extract_leading_edge(res.loc[pos.index].head(TOP_LE))\n",
    "        if not le_pos.empty:\n",
    "            le_pos.to_csv(OUTDIR/f\"{module}_GSEA_{PRERANK_LIB}_leading_edge_POS.csv\", index=False)\n",
    "            print(f\"[saved] {OUTDIR/f'{module}_GSEA_{PRERANK_LIB}_leading_edge_POS.csv'}\")\n",
    "    if not neg.empty:\n",
    "        le_neg = extract_leading_edge(res.loc[neg.index].head(TOP_LE))\n",
    "        if not le_neg.empty:\n",
    "            le_neg.to_csv(OUTDIR/f\"{module}_GSEA_{PRERANK_LIB}_leading_edge_NEG.csv\", index=False)\n",
    "            print(f\"[saved] {OUTDIR/f'{module}_GSEA_{PRERANK_LIB}_leading_edge_NEG.csv'}\")\n",
    "\n",
    "    return ranks, res\n",
    "\n",
    "def ora_on_tails(module: str, ranks: pd.Series):\n",
    "    pos_genes = ranks.head(TOPK_ORA).index.tolist()\n",
    "    neg_genes = ranks.tail(TOPK_ORA).index.tolist()\n",
    "\n",
    "    enr_pos = gp.enrichr(gene_list=pos_genes, gene_sets=ORA_LIB, outdir=None, cutoff=1.0)\n",
    "    res_pos = normalize_cols(enr_pos.results)\n",
    "    if \"adjusted_p_value\" in res_pos.columns and \"adjusted_p_value\" != \"adj_p_value\":\n",
    "        res_pos = res_pos.rename(columns={\"adjusted_p_value\":\"adj_p_value\"})\n",
    "    res_pos.to_csv(OUTDIR/f\"{module}_ORApos_{ORA_LIB}.csv\", index=False)\n",
    "    print(f\"[saved] {OUTDIR/f'{module}_ORApos_{ORA_LIB}.csv'}\")\n",
    "\n",
    "    enr_neg = gp.enrichr(gene_list=neg_genes, gene_sets=ORA_LIB, outdir=None, cutoff=1.0)\n",
    "    res_neg = normalize_cols(enr_neg.results)\n",
    "    if \"adjusted_p_value\" in res_neg.columns and \"adjusted_p_value\" != \"adj_p_value\":\n",
    "        res_neg = res_neg.rename(columns={\"adjusted_p_value\":\"adj_p_value\"})\n",
    "    res_neg.to_csv(OUTDIR/f\"{module}_ORAneg_{ORA_LIB}.csv\", index=False)\n",
    "    print(f\"[saved] {OUTDIR/f'{module}_ORAneg_{ORA_LIB}.csv'}\")\n",
    "\n",
    "for m in modules:\n",
    "    print(f\"\\n== {m} ==\")\n",
    "    ranks, _res = preranked_module(m)\n",
    "    ora_on_tails(m, ranks)\n",
    "\n",
    "print(\"\\nDone. See:\", OUTDIR.resolve())\n",
    "print(\"Interpretation:\")\n",
    "print(\"  • Positive NES: pathways enriched among genes more essential in module-high lines (vulnerability biology).\")\n",
    "print(\"  • Negative NES: pathways enriched among genes less essential in module-high lines (buffering/escape).\")\n",
    "print(\"  • ORA on tails complements GSEA by focusing on strict top ρ>0 and ρ<0 gene sets.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "119d3dfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== Compare Hallmark vs Reactome vs BioPlanet for one module (default: IGE) =====\n",
    "import pandas as pd, numpy as np\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import gseapy as gp\n",
    "from statsmodels.stats.multitest import multipletests\n",
    "\n",
    "# ---------- CONFIG ----------\n",
    "MODULE      = \"IGE\"          # <-- change to \"SAT\", \"IL2\", \"MPC\" as needed\n",
    "INFILE      = Path(\"out_depmap_corr/module_vs_dependency_strength_spearman.csv\")\n",
    "OUTROOT     = Path(\"out_depmap_gsea_compare\") / MODULE\n",
    "OUTROOT.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "TOP_PLOT    = 15\n",
    "MIN_SIZE    = 10\n",
    "MAX_SIZE    = 500\n",
    "N_PERM      = 1000\n",
    "THREADS     = 4\n",
    "SEED        = 42\n",
    "\n",
    "# ---------- Helpers ----------\n",
    "def make_ranks(df_mod: pd.DataFrame) -> pd.DataFrame:\n",
    "    # collapse duplicates, sort desc by rho, add tiny deterministic tie-break\n",
    "    r = (df_mod.groupby(\"gene\", as_index=True)[\"rho\"].mean()).sort_values(ascending=False)\n",
    "    tb = pd.Series(np.linspace(0, 1e-9, num=len(r), endpoint=False), index=r.index)\n",
    "    r = r + tb\n",
    "    rnk_df = r.reset_index()\n",
    "    rnk_df.columns = [\"gene\", \"score\"]\n",
    "    return rnk_df\n",
    "\n",
    "def normalize_cols(res_df: pd.DataFrame) -> pd.DataFrame:\n",
    "    res = res_df.copy()\n",
    "    res.columns = [c.strip().lower().replace(\" \", \"_\").replace(\"-\", \"_\") for c in res.columns]\n",
    "    # set index to term if present\n",
    "    if \"term\" in res.columns and res.index.name is None:\n",
    "        res = res.set_index(\"term\")\n",
    "    return res\n",
    "\n",
    "def ensure_fdr(res: pd.DataFrame) -> pd.DataFrame:\n",
    "    res = res.copy()\n",
    "    # map common variants to 'fdr'\n",
    "    colmap = {\n",
    "        \"fdr_q_val\":\"fdr\",\"fdr_qval\":\"fdr\",\"fdr_q\":\"fdr\",\"fdr_q_value\":\"fdr\",\n",
    "        \"adj_p_value\":\"fdr\",\"adjusted_p_value\":\"fdr\"\n",
    "    }\n",
    "    for src,dst in colmap.items():\n",
    "        if src in res.columns:\n",
    "            res[\"fdr\"] = res[src]\n",
    "            break\n",
    "    if \"fdr\" not in res.columns:\n",
    "        pcol = \"pval\" if \"pval\" in res.columns else (\"p_value\" if \"p_value\" in res.columns else None)\n",
    "        if pcol:\n",
    "            res[\"fdr\"] = multipletests(res[pcol].astype(float), method=\"fdr_bh\")[1]\n",
    "        else:\n",
    "            res[\"fdr\"] = np.nan\n",
    "    return res\n",
    "\n",
    "def run_prerank(rnk_df: pd.DataFrame, gene_set_name: str, outdir: Path):\n",
    "    pre = gp.prerank(\n",
    "        rnk=rnk_df, gene_sets=gene_set_name, threads=THREADS,\n",
    "        permutation_num=N_PERM, min_size=MIN_SIZE, max_size=MAX_SIZE,\n",
    "        outdir=None, seed=SEED, verbose=False\n",
    "    )\n",
    "    res = ensure_fdr(normalize_cols(pre.res2d))\n",
    "    res = res.sort_values(\"fdr\", ascending=True)\n",
    "    # save full result\n",
    "    csv_path = outdir / f\"GSEA_{gene_set_name}.csv\"\n",
    "    res.to_csv(csv_path)\n",
    "    # plots\n",
    "    pos = res[res[\"nes\"]>0].head(TOP_PLOT)\n",
    "    neg = res[res[\"nes\"]<0].head(TOP_PLOT)\n",
    "    if not pos.empty:\n",
    "        plt.figure(figsize=(7,5))\n",
    "        plt.barh(pos.index[::-1], pos[\"nes\"][::-1])\n",
    "        plt.axvline(0, ls=\"--\", lw=1)\n",
    "        plt.title(f\"{MODULE} — {gene_set_name} top positive NES\")\n",
    "        plt.xlabel(\"Normalized Enrichment Score (NES)\")\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(outdir / f\"{gene_set_name}_topPOS.png\", dpi=300)\n",
    "        plt.close()\n",
    "    if not neg.empty:\n",
    "        plt.figure(figsize=(7,5))\n",
    "        plt.barh(neg.index[::-1], neg[\"nes\"][::-1])\n",
    "        plt.axvline(0, ls=\"--\", lw=1)\n",
    "        plt.title(f\"{MODULE} — {gene_set_name} top negative NES\")\n",
    "        plt.xlabel(\"Normalized Enrichment Score (NES)\")\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(outdir / f\"{gene_set_name}_topNEG.png\", dpi=300)\n",
    "        plt.close()\n",
    "    return res\n",
    "\n",
    "# ---------- Pick valid library names on your install ----------\n",
    "avail = set(gp.get_library_name())  # requires internet for first call; then cached\n",
    "def pick_like(*candidates):\n",
    "    for cand in candidates:\n",
    "        for lib in avail:\n",
    "            if cand.lower() in lib.lower():\n",
    "                return lib\n",
    "    return None\n",
    "\n",
    "LIB_HALLMARK = pick_like(\"MSigDB_Hallmark\", \"Hallmark\")\n",
    "LIB_REACTOME = pick_like(\"Reactome_2023\", \"Reactome_2022\", \"Reactome\")\n",
    "LIB_BIOPLANT = pick_like(\"BioPlanet_2019\", \"BioPlanet\")\n",
    "\n",
    "libs = []\n",
    "if LIB_HALLMARK: libs.append(LIB_HALLMARK)\n",
    "if LIB_REACTOME: libs.append(LIB_REACTOME)\n",
    "if LIB_BIOPLANT: libs.append(LIB_BIOPLANT)\n",
    "if not libs:\n",
    "    raise RuntimeError(\"No Hallmark/Reactome/BioPlanet libraries found by gseapy.get_library_name().\")\n",
    "\n",
    "print(\"[libs]\", libs)\n",
    "\n",
    "# ---------- Load correlations and build ranks for the chosen module ----------\n",
    "corr = pd.read_csv(INFILE)\n",
    "assert {\"module\",\"gene\",\"rho\"}.issubset(corr.columns), \"Expected columns: module, gene, rho\"\n",
    "sub = corr[corr[\"module\"]==MODULE].dropna(subset=[\"gene\",\"rho\"]).copy()\n",
    "rnk_df = make_ranks(sub)\n",
    "\n",
    "# ---------- Run GSEA for each library and collect a compact summary ----------\n",
    "summary_rows = []\n",
    "for lib in libs:\n",
    "    outdir = OUTROOT / lib\n",
    "    outdir.mkdir(parents=True, exist_ok=True)\n",
    "    res = run_prerank(rnk_df, lib, outdir)\n",
    "    # capture top positives (NES>0) and top negatives (NES<0)\n",
    "    top_pos = res[res[\"nes\"]>0].head(10).assign(direction=\"POS\", library=lib)\n",
    "    top_neg = res[res[\"nes\"]<0].head(10).assign(direction=\"NEG\", library=lib)\n",
    "    summary_rows.append(top_pos[[\"library\",\"nes\",\"fdr\"]].rename_axis(\"term\"))\n",
    "    summary_rows.append(top_neg[[\"library\",\"nes\",\"fdr\"]].rename_axis(\"term\"))\n",
    "\n",
    "summary = pd.concat(summary_rows, axis=0)\n",
    "summary_path = OUTROOT / f\"{MODULE}_GSEA_summary_across_libraries.csv\"\n",
    "summary.to_csv(summary_path)\n",
    "print(f\"[saved] {summary_path}\")\n",
    "\n",
    "print(\"\\nDone. Outputs per library in:\", OUTROOT.resolve())\n",
    "print(\"Interpretation:\")\n",
    "print(\"  • Positive NES ⇒ pathways enriched among genes more essential in module-high lines (putative vulnerabilities).\")\n",
    "print(\"  • Negative NES ⇒ pathways enriched among genes less essential in module-high lines (buffering/escape).\")\n",
    "print(\"  • Hallmark gives clean overview; Reactome and BioPlanet add targetable, mechanistic detail.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4b39dd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== Compare Hallmark vs Reactome vs BioPlanet for one module (default: SAT) =====\n",
    "import pandas as pd, numpy as np\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import gseapy as gp\n",
    "from statsmodels.stats.multitest import multipletests\n",
    "\n",
    "# ---------- CONFIG ----------\n",
    "MODULE      = \"SAT\"          # <-- change to \"SAT\", \"IL2\", \"MPC\" as needed\n",
    "INFILE      = Path(\"out_depmap_corr/module_vs_dependency_strength_spearman.csv\")\n",
    "OUTROOT     = Path(\"out_depmap_gsea_compare\") / MODULE\n",
    "OUTROOT.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "TOP_PLOT    = 15\n",
    "MIN_SIZE    = 10\n",
    "MAX_SIZE    = 500\n",
    "N_PERM      = 1000\n",
    "THREADS     = 4\n",
    "SEED        = 42\n",
    "\n",
    "# ---------- Helpers ----------\n",
    "def make_ranks(df_mod: pd.DataFrame) -> pd.DataFrame:\n",
    "    # collapse duplicates, sort desc by rho, add tiny deterministic tie-break\n",
    "    r = (df_mod.groupby(\"gene\", as_index=True)[\"rho\"].mean()).sort_values(ascending=False)\n",
    "    tb = pd.Series(np.linspace(0, 1e-9, num=len(r), endpoint=False), index=r.index)\n",
    "    r = r + tb\n",
    "    rnk_df = r.reset_index()\n",
    "    rnk_df.columns = [\"gene\", \"score\"]\n",
    "    return rnk_df\n",
    "\n",
    "def normalize_cols(res_df: pd.DataFrame) -> pd.DataFrame:\n",
    "    res = res_df.copy()\n",
    "    res.columns = [c.strip().lower().replace(\" \", \"_\").replace(\"-\", \"_\") for c in res.columns]\n",
    "    # set index to term if present\n",
    "    if \"term\" in res.columns and res.index.name is None:\n",
    "        res = res.set_index(\"term\")\n",
    "    return res\n",
    "\n",
    "def ensure_fdr(res: pd.DataFrame) -> pd.DataFrame:\n",
    "    res = res.copy()\n",
    "    # map common variants to 'fdr'\n",
    "    colmap = {\n",
    "        \"fdr_q_val\":\"fdr\",\"fdr_qval\":\"fdr\",\"fdr_q\":\"fdr\",\"fdr_q_value\":\"fdr\",\n",
    "        \"adj_p_value\":\"fdr\",\"adjusted_p_value\":\"fdr\"\n",
    "    }\n",
    "    for src,dst in colmap.items():\n",
    "        if src in res.columns:\n",
    "            res[\"fdr\"] = res[src]\n",
    "            break\n",
    "    if \"fdr\" not in res.columns:\n",
    "        pcol = \"pval\" if \"pval\" in res.columns else (\"p_value\" if \"p_value\" in res.columns else None)\n",
    "        if pcol:\n",
    "            res[\"fdr\"] = multipletests(res[pcol].astype(float), method=\"fdr_bh\")[1]\n",
    "        else:\n",
    "            res[\"fdr\"] = np.nan\n",
    "    return res\n",
    "\n",
    "def run_prerank(rnk_df: pd.DataFrame, gene_set_name: str, outdir: Path):\n",
    "    pre = gp.prerank(\n",
    "        rnk=rnk_df, gene_sets=gene_set_name, threads=THREADS,\n",
    "        permutation_num=N_PERM, min_size=MIN_SIZE, max_size=MAX_SIZE,\n",
    "        outdir=None, seed=SEED, verbose=False\n",
    "    )\n",
    "    res = ensure_fdr(normalize_cols(pre.res2d))\n",
    "    res = res.sort_values(\"fdr\", ascending=True)\n",
    "    # save full result\n",
    "    csv_path = outdir / f\"GSEA_{gene_set_name}.csv\"\n",
    "    res.to_csv(csv_path)\n",
    "    # plots\n",
    "    pos = res[res[\"nes\"]>0].head(TOP_PLOT)\n",
    "    neg = res[res[\"nes\"]<0].head(TOP_PLOT)\n",
    "    if not pos.empty:\n",
    "        plt.figure(figsize=(7,5))\n",
    "        plt.barh(pos.index[::-1], pos[\"nes\"][::-1])\n",
    "        plt.axvline(0, ls=\"--\", lw=1)\n",
    "        plt.title(f\"{MODULE} — {gene_set_name} top positive NES\")\n",
    "        plt.xlabel(\"Normalized Enrichment Score (NES)\")\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(outdir / f\"{gene_set_name}_topPOS.png\", dpi=300)\n",
    "        plt.close()\n",
    "    if not neg.empty:\n",
    "        plt.figure(figsize=(7,5))\n",
    "        plt.barh(neg.index[::-1], neg[\"nes\"][::-1])\n",
    "        plt.axvline(0, ls=\"--\", lw=1)\n",
    "        plt.title(f\"{MODULE} — {gene_set_name} top negative NES\")\n",
    "        plt.xlabel(\"Normalized Enrichment Score (NES)\")\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(outdir / f\"{gene_set_name}_topNEG.png\", dpi=300)\n",
    "        plt.close()\n",
    "    return res\n",
    "\n",
    "# ---------- Pick valid library names on your install ----------\n",
    "avail = set(gp.get_library_name())  # requires internet for first call; then cached\n",
    "def pick_like(*candidates):\n",
    "    for cand in candidates:\n",
    "        for lib in avail:\n",
    "            if cand.lower() in lib.lower():\n",
    "                return lib\n",
    "    return None\n",
    "\n",
    "LIB_HALLMARK = pick_like(\"MSigDB_Hallmark\", \"Hallmark\")\n",
    "LIB_REACTOME = pick_like(\"Reactome_2023\", \"Reactome_2022\", \"Reactome\")\n",
    "LIB_BIOPLANT = pick_like(\"BioPlanet_2019\", \"BioPlanet\")\n",
    "\n",
    "libs = []\n",
    "if LIB_HALLMARK: libs.append(LIB_HALLMARK)\n",
    "if LIB_REACTOME: libs.append(LIB_REACTOME)\n",
    "if LIB_BIOPLANT: libs.append(LIB_BIOPLANT)\n",
    "if not libs:\n",
    "    raise RuntimeError(\"No Hallmark/Reactome/BioPlanet libraries found by gseapy.get_library_name().\")\n",
    "\n",
    "print(\"[libs]\", libs)\n",
    "\n",
    "# ---------- Load correlations and build ranks for the chosen module ----------\n",
    "corr = pd.read_csv(INFILE)\n",
    "assert {\"module\",\"gene\",\"rho\"}.issubset(corr.columns), \"Expected columns: module, gene, rho\"\n",
    "sub = corr[corr[\"module\"]==MODULE].dropna(subset=[\"gene\",\"rho\"]).copy()\n",
    "rnk_df = make_ranks(sub)\n",
    "\n",
    "# ---------- Run GSEA for each library and collect a compact summary ----------\n",
    "summary_rows = []\n",
    "for lib in libs:\n",
    "    outdir = OUTROOT / lib\n",
    "    outdir.mkdir(parents=True, exist_ok=True)\n",
    "    res = run_prerank(rnk_df, lib, outdir)\n",
    "    # capture top positives (NES>0) and top negatives (NES<0)\n",
    "    top_pos = res[res[\"nes\"]>0].head(10).assign(direction=\"POS\", library=lib)\n",
    "    top_neg = res[res[\"nes\"]<0].head(10).assign(direction=\"NEG\", library=lib)\n",
    "    summary_rows.append(top_pos[[\"library\",\"nes\",\"fdr\"]].rename_axis(\"term\"))\n",
    "    summary_rows.append(top_neg[[\"library\",\"nes\",\"fdr\"]].rename_axis(\"term\"))\n",
    "\n",
    "summary = pd.concat(summary_rows, axis=0)\n",
    "summary_path = OUTROOT / f\"{MODULE}_GSEA_summary_across_libraries.csv\"\n",
    "summary.to_csv(summary_path)\n",
    "print(f\"[saved] {summary_path}\")\n",
    "\n",
    "print(\"\\nDone. Outputs per library in:\", OUTROOT.resolve())\n",
    "print(\"Interpretation:\")\n",
    "print(\"  • Positive NES ⇒ pathways enriched among genes more essential in module-high lines (putative vulnerabilities).\")\n",
    "print(\"  • Negative NES ⇒ pathways enriched among genes less essential in module-high lines (buffering/escape).\")\n",
    "print(\"  • Hallmark gives clean overview; Reactome and BioPlanet add targetable, mechanistic detail.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "985c8e1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== Compare Hallmark vs Reactome vs BioPlanet for one module (default: IL2) =====\n",
    "import pandas as pd, numpy as np\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import gseapy as gp\n",
    "from statsmodels.stats.multitest import multipletests\n",
    "\n",
    "# ---------- CONFIG ----------\n",
    "MODULE      = \"IL2\"          # <-- change to \"IL2\", \"IL2\", \"MPC\" as needed\n",
    "INFILE      = Path(\"out_depmap_corr/module_vs_dependency_strength_spearman.csv\")\n",
    "OUTROOT     = Path(\"out_depmap_gsea_compare\") / MODULE\n",
    "OUTROOT.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "TOP_PLOT    = 15\n",
    "MIN_SIZE    = 10\n",
    "MAX_SIZE    = 500\n",
    "N_PERM      = 1000\n",
    "THREADS     = 4\n",
    "SEED        = 42\n",
    "\n",
    "# ---------- Helpers ----------\n",
    "def make_ranks(df_mod: pd.DataFrame) -> pd.DataFrame:\n",
    "    # collapse duplicates, sort desc by rho, add tiny deterministic tie-break\n",
    "    r = (df_mod.groupby(\"gene\", as_index=True)[\"rho\"].mean()).sort_values(ascending=False)\n",
    "    tb = pd.Series(np.linspace(0, 1e-9, num=len(r), endpoint=False), index=r.index)\n",
    "    r = r + tb\n",
    "    rnk_df = r.reset_index()\n",
    "    rnk_df.columns = [\"gene\", \"score\"]\n",
    "    return rnk_df\n",
    "\n",
    "def normalize_cols(res_df: pd.DataFrame) -> pd.DataFrame:\n",
    "    res = res_df.copy()\n",
    "    res.columns = [c.strip().lower().replace(\" \", \"_\").replace(\"-\", \"_\") for c in res.columns]\n",
    "    # set index to term if present\n",
    "    if \"term\" in res.columns and res.index.name is None:\n",
    "        res = res.set_index(\"term\")\n",
    "    return res\n",
    "\n",
    "def ensure_fdr(res: pd.DataFrame) -> pd.DataFrame:\n",
    "    res = res.copy()\n",
    "    # map common variants to 'fdr'\n",
    "    colmap = {\n",
    "        \"fdr_q_val\":\"fdr\",\"fdr_qval\":\"fdr\",\"fdr_q\":\"fdr\",\"fdr_q_value\":\"fdr\",\n",
    "        \"adj_p_value\":\"fdr\",\"adjusted_p_value\":\"fdr\"\n",
    "    }\n",
    "    for src,dst in colmap.items():\n",
    "        if src in res.columns:\n",
    "            res[\"fdr\"] = res[src]\n",
    "            break\n",
    "    if \"fdr\" not in res.columns:\n",
    "        pcol = \"pval\" if \"pval\" in res.columns else (\"p_value\" if \"p_value\" in res.columns else None)\n",
    "        if pcol:\n",
    "            res[\"fdr\"] = multipletests(res[pcol].astype(float), method=\"fdr_bh\")[1]\n",
    "        else:\n",
    "            res[\"fdr\"] = np.nan\n",
    "    return res\n",
    "\n",
    "def run_prerank(rnk_df: pd.DataFrame, gene_set_name: str, outdir: Path):\n",
    "    pre = gp.prerank(\n",
    "        rnk=rnk_df, gene_sets=gene_set_name, threads=THREADS,\n",
    "        permutation_num=N_PERM, min_size=MIN_SIZE, max_size=MAX_SIZE,\n",
    "        outdir=None, seed=SEED, verbose=False\n",
    "    )\n",
    "    res = ensure_fdr(normalize_cols(pre.res2d))\n",
    "    res = res.sort_values(\"fdr\", ascending=True)\n",
    "    # save full result\n",
    "    csv_path = outdir / f\"GSEA_{gene_set_name}.csv\"\n",
    "    res.to_csv(csv_path)\n",
    "    # plots\n",
    "    pos = res[res[\"nes\"]>0].head(TOP_PLOT)\n",
    "    neg = res[res[\"nes\"]<0].head(TOP_PLOT)\n",
    "    if not pos.empty:\n",
    "        plt.figure(figsize=(7,5))\n",
    "        plt.barh(pos.index[::-1], pos[\"nes\"][::-1])\n",
    "        plt.axvline(0, ls=\"--\", lw=1)\n",
    "        plt.title(f\"{MODULE} — {gene_set_name} top positive NES\")\n",
    "        plt.xlabel(\"Normalized Enrichment Score (NES)\")\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(outdir / f\"{gene_set_name}_topPOS.png\", dpi=300)\n",
    "        plt.close()\n",
    "    if not neg.empty:\n",
    "        plt.figure(figsize=(7,5))\n",
    "        plt.barh(neg.index[::-1], neg[\"nes\"][::-1])\n",
    "        plt.axvline(0, ls=\"--\", lw=1)\n",
    "        plt.title(f\"{MODULE} — {gene_set_name} top negative NES\")\n",
    "        plt.xlabel(\"Normalized Enrichment Score (NES)\")\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(outdir / f\"{gene_set_name}_topNEG.png\", dpi=300)\n",
    "        plt.close()\n",
    "    return res\n",
    "\n",
    "# ---------- Pick valid library names on your install ----------\n",
    "avail = set(gp.get_library_name())  # requires internet for first call; then cached\n",
    "def pick_like(*candidates):\n",
    "    for cand in candidates:\n",
    "        for lib in avail:\n",
    "            if cand.lower() in lib.lower():\n",
    "                return lib\n",
    "    return None\n",
    "\n",
    "LIB_HALLMARK = pick_like(\"MSigDB_Hallmark\", \"Hallmark\")\n",
    "LIB_REACTOME = pick_like(\"Reactome_2023\", \"Reactome_2022\", \"Reactome\")\n",
    "LIB_BIOPLANT = pick_like(\"BioPlanet_2019\", \"BioPlanet\")\n",
    "\n",
    "libs = []\n",
    "if LIB_HALLMARK: libs.append(LIB_HALLMARK)\n",
    "if LIB_REACTOME: libs.append(LIB_REACTOME)\n",
    "if LIB_BIOPLANT: libs.append(LIB_BIOPLANT)\n",
    "if not libs:\n",
    "    raise RuntimeError(\"No Hallmark/Reactome/BioPlanet libraries found by gseapy.get_library_name().\")\n",
    "\n",
    "print(\"[libs]\", libs)\n",
    "\n",
    "# ---------- Load correlations and build ranks for the chosen module ----------\n",
    "corr = pd.read_csv(INFILE)\n",
    "assert {\"module\",\"gene\",\"rho\"}.issubset(corr.columns), \"Expected columns: module, gene, rho\"\n",
    "sub = corr[corr[\"module\"]==MODULE].dropna(subset=[\"gene\",\"rho\"]).copy()\n",
    "rnk_df = make_ranks(sub)\n",
    "\n",
    "# ---------- Run GSEA for each library and collect a compact summary ----------\n",
    "summary_rows = []\n",
    "for lib in libs:\n",
    "    outdir = OUTROOT / lib\n",
    "    outdir.mkdir(parents=True, exist_ok=True)\n",
    "    res = run_prerank(rnk_df, lib, outdir)\n",
    "    # capture top positives (NES>0) and top negatives (NES<0)\n",
    "    top_pos = res[res[\"nes\"]>0].head(10).assign(direction=\"POS\", library=lib)\n",
    "    top_neg = res[res[\"nes\"]<0].head(10).assign(direction=\"NEG\", library=lib)\n",
    "    summary_rows.append(top_pos[[\"library\",\"nes\",\"fdr\"]].rename_axis(\"term\"))\n",
    "    summary_rows.append(top_neg[[\"library\",\"nes\",\"fdr\"]].rename_axis(\"term\"))\n",
    "\n",
    "summary = pd.concat(summary_rows, axis=0)\n",
    "summary_path = OUTROOT / f\"{MODULE}_GSEA_summary_across_libraries.csv\"\n",
    "summary.to_csv(summary_path)\n",
    "print(f\"[saved] {summary_path}\")\n",
    "\n",
    "print(\"\\nDone. Outputs per library in:\", OUTROOT.resolve())\n",
    "print(\"Interpretation:\")\n",
    "print(\"  • Positive NES ⇒ pathways enriched among genes more essential in module-high lines (putative vulnerabilities).\")\n",
    "print(\"  • Negative NES ⇒ pathways enriched among genes less essential in module-high lines (buffering/escape).\")\n",
    "print(\"  • Hallmark gives clean overview; Reactome and BioPlanet add targetable, mechanistic detail.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "134ffc7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== Compare Hallmark vs Reactome vs BioPlanet for one module (default: MPC) =====\n",
    "import pandas as pd, numpy as np\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import gseapy as gp\n",
    "from statsmodels.stats.multitest import multipletests\n",
    "\n",
    "# ---------- CONFIG ----------\n",
    "MODULE      = \"MPC\"          # <-- change to \"MPC\", \"IL2\", \"MPC\" as needed\n",
    "INFILE      = Path(\"out_depmap_corr/module_vs_dependency_strength_spearman.csv\")\n",
    "OUTROOT     = Path(\"out_depmap_gsea_compare\") / MODULE\n",
    "OUTROOT.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "TOP_PLOT    = 15\n",
    "MIN_SIZE    = 10\n",
    "MAX_SIZE    = 500\n",
    "N_PERM      = 1000\n",
    "THREADS     = 4\n",
    "SEED        = 42\n",
    "\n",
    "# ---------- Helpers ----------\n",
    "def make_ranks(df_mod: pd.DataFrame) -> pd.DataFrame:\n",
    "    # collapse duplicates, sort desc by rho, add tiny deterministic tie-break\n",
    "    r = (df_mod.groupby(\"gene\", as_index=True)[\"rho\"].mean()).sort_values(ascending=False)\n",
    "    tb = pd.Series(np.linspace(0, 1e-9, num=len(r), endpoint=False), index=r.index)\n",
    "    r = r + tb\n",
    "    rnk_df = r.reset_index()\n",
    "    rnk_df.columns = [\"gene\", \"score\"]\n",
    "    return rnk_df\n",
    "\n",
    "def normalize_cols(res_df: pd.DataFrame) -> pd.DataFrame:\n",
    "    res = res_df.copy()\n",
    "    res.columns = [c.strip().lower().replace(\" \", \"_\").replace(\"-\", \"_\") for c in res.columns]\n",
    "    # set index to term if present\n",
    "    if \"term\" in res.columns and res.index.name is None:\n",
    "        res = res.set_index(\"term\")\n",
    "    return res\n",
    "\n",
    "def ensure_fdr(res: pd.DataFrame) -> pd.DataFrame:\n",
    "    res = res.copy()\n",
    "    # map common variants to 'fdr'\n",
    "    colmap = {\n",
    "        \"fdr_q_val\":\"fdr\",\"fdr_qval\":\"fdr\",\"fdr_q\":\"fdr\",\"fdr_q_value\":\"fdr\",\n",
    "        \"adj_p_value\":\"fdr\",\"adjusted_p_value\":\"fdr\"\n",
    "    }\n",
    "    for src,dst in colmap.items():\n",
    "        if src in res.columns:\n",
    "            res[\"fdr\"] = res[src]\n",
    "            break\n",
    "    if \"fdr\" not in res.columns:\n",
    "        pcol = \"pval\" if \"pval\" in res.columns else (\"p_value\" if \"p_value\" in res.columns else None)\n",
    "        if pcol:\n",
    "            res[\"fdr\"] = multipletests(res[pcol].astype(float), method=\"fdr_bh\")[1]\n",
    "        else:\n",
    "            res[\"fdr\"] = np.nan\n",
    "    return res\n",
    "\n",
    "def run_prerank(rnk_df: pd.DataFrame, gene_set_name: str, outdir: Path):\n",
    "    pre = gp.prerank(\n",
    "        rnk=rnk_df, gene_sets=gene_set_name, threads=THREADS,\n",
    "        permutation_num=N_PERM, min_size=MIN_SIZE, max_size=MAX_SIZE,\n",
    "        outdir=None, seed=SEED, verbose=False\n",
    "    )\n",
    "    res = ensure_fdr(normalize_cols(pre.res2d))\n",
    "    res = res.sort_values(\"fdr\", ascending=True)\n",
    "    # save full result\n",
    "    csv_path = outdir / f\"GSEA_{gene_set_name}.csv\"\n",
    "    res.to_csv(csv_path)\n",
    "    # plots\n",
    "    pos = res[res[\"nes\"]>0].head(TOP_PLOT)\n",
    "    neg = res[res[\"nes\"]<0].head(TOP_PLOT)\n",
    "    if not pos.empty:\n",
    "        plt.figure(figsize=(7,5))\n",
    "        plt.barh(pos.index[::-1], pos[\"nes\"][::-1])\n",
    "        plt.axvline(0, ls=\"--\", lw=1)\n",
    "        plt.title(f\"{MODULE} — {gene_set_name} top positive NES\")\n",
    "        plt.xlabel(\"Normalized Enrichment Score (NES)\")\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(outdir / f\"{gene_set_name}_topPOS.png\", dpi=300)\n",
    "        plt.close()\n",
    "    if not neg.empty:\n",
    "        plt.figure(figsize=(7,5))\n",
    "        plt.barh(neg.index[::-1], neg[\"nes\"][::-1])\n",
    "        plt.axvline(0, ls=\"--\", lw=1)\n",
    "        plt.title(f\"{MODULE} — {gene_set_name} top negative NES\")\n",
    "        plt.xlabel(\"Normalized Enrichment Score (NES)\")\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(outdir / f\"{gene_set_name}_topNEG.png\", dpi=300)\n",
    "        plt.close()\n",
    "    return res\n",
    "\n",
    "# ---------- Pick valid library names on your install ----------\n",
    "avail = set(gp.get_library_name())  # requires internet for first call; then cached\n",
    "def pick_like(*candidates):\n",
    "    for cand in candidates:\n",
    "        for lib in avail:\n",
    "            if cand.lower() in lib.lower():\n",
    "                return lib\n",
    "    return None\n",
    "\n",
    "LIB_HALLMARK = pick_like(\"MSigDB_Hallmark\", \"Hallmark\")\n",
    "LIB_REACTOME = pick_like(\"Reactome_2023\", \"Reactome_2022\", \"Reactome\")\n",
    "LIB_BIOPLANT = pick_like(\"BioPlanet_2019\", \"BioPlanet\")\n",
    "\n",
    "libs = []\n",
    "if LIB_HALLMARK: libs.append(LIB_HALLMARK)\n",
    "if LIB_REACTOME: libs.append(LIB_REACTOME)\n",
    "if LIB_BIOPLANT: libs.append(LIB_BIOPLANT)\n",
    "if not libs:\n",
    "    raise RuntimeError(\"No Hallmark/Reactome/BioPlanet libraries found by gseapy.get_library_name().\")\n",
    "\n",
    "print(\"[libs]\", libs)\n",
    "\n",
    "# ---------- Load correlations and build ranks for the chosen module ----------\n",
    "corr = pd.read_csv(INFILE)\n",
    "assert {\"module\",\"gene\",\"rho\"}.issubset(corr.columns), \"Expected columns: module, gene, rho\"\n",
    "sub = corr[corr[\"module\"]==MODULE].dropna(subset=[\"gene\",\"rho\"]).copy()\n",
    "rnk_df = make_ranks(sub)\n",
    "\n",
    "# ---------- Run GSEA for each library and collect a compact summary ----------\n",
    "summary_rows = []\n",
    "for lib in libs:\n",
    "    outdir = OUTROOT / lib\n",
    "    outdir.mkdir(parents=True, exist_ok=True)\n",
    "    res = run_prerank(rnk_df, lib, outdir)\n",
    "    # capture top positives (NES>0) and top negatives (NES<0)\n",
    "    top_pos = res[res[\"nes\"]>0].head(10).assign(direction=\"POS\", library=lib)\n",
    "    top_neg = res[res[\"nes\"]<0].head(10).assign(direction=\"NEG\", library=lib)\n",
    "    summary_rows.append(top_pos[[\"library\",\"nes\",\"fdr\"]].rename_axis(\"term\"))\n",
    "    summary_rows.append(top_neg[[\"library\",\"nes\",\"fdr\"]].rename_axis(\"term\"))\n",
    "\n",
    "summary = pd.concat(summary_rows, axis=0)\n",
    "summary_path = OUTROOT / f\"{MODULE}_GSEA_summary_across_libraries.csv\"\n",
    "summary.to_csv(summary_path)\n",
    "print(f\"[saved] {summary_path}\")\n",
    "\n",
    "print(\"\\nDone. Outputs per library in:\", OUTROOT.resolve())\n",
    "print(\"Interpretation:\")\n",
    "print(\"  • Positive NES ⇒ pathways enriched among genes more essential in module-high lines (putative vulnerabilities).\")\n",
    "print(\"  • Negative NES ⇒ pathways enriched among genes less essential in module-high lines (buffering/escape).\")\n",
    "print(\"  • Hallmark gives clean overview; Reactome and BioPlanet add targetable, mechanistic detail.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "0babf6f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pairwise overlaps:\n",
      "       pair  overlap_n  size_IGE  size_SAT   jaccard  size_IL2  size_MPC\n",
      "4  SAT∩MPC         74       NaN     458.0  0.081140       NaN     528.0\n",
      "3  SAT∩IL2         66       NaN     458.0  0.084942     385.0       NaN\n",
      "5  IL2∩MPC         48       NaN       NaN  0.055491     385.0     528.0\n",
      "0  IGE∩SAT          8     622.0     458.0  0.007463       NaN       NaN\n",
      "1  IGE∩IL2          3     622.0       NaN  0.002988     385.0       NaN\n",
      "2  IGE∩MPC          0     622.0       NaN  0.000000       NaN     528.0 \n",
      "\n",
      "Triple overlaps:\n",
      "         triple  overlap_n\n",
      "3  SAT∩IL2∩MPC         10\n",
      "0  IGE∩SAT∩IL2          1\n",
      "1  IGE∩SAT∩MPC          0\n",
      "2  IGE∩IL2∩MPC          0 \n",
      "\n",
      "Top genes present in >=2 modules:\n",
      " module    IGE  SAT  IL2  MPC  n_modules\n",
      "gene                                   \n",
      "TBC1D7    1.0  1.0  1.0  0.0        3.0\n",
      "ACO2      0.0  1.0  1.0  1.0        3.0\n",
      "ARFGAP1   0.0  1.0  1.0  1.0        3.0\n",
      "ASB11     0.0  1.0  1.0  1.0        3.0\n",
      "ASPM      0.0  1.0  1.0  1.0        3.0\n",
      "C11orf16  0.0  1.0  1.0  1.0        3.0\n",
      "C17orf99  0.0  1.0  1.0  1.0        3.0\n",
      "PLAG1     0.0  1.0  1.0  1.0        3.0\n",
      "PRRT2     0.0  1.0  1.0  1.0        3.0\n",
      "PTPN14    0.0  1.0  1.0  1.0        3.0\n",
      "TMEM31    0.0  1.0  1.0  1.0        3.0\n",
      "APH1A     1.0  1.0  0.0  0.0        2.0\n",
      "HAUS6     1.0  1.0  0.0  0.0        2.0\n",
      "PGLYRP3   1.0  1.0  0.0  0.0        2.0\n",
      "RIOK3     1.0  1.0  0.0  0.0        2.0\n",
      "SEC14L3   1.0  1.0  0.0  0.0        2.0\n",
      "SYNPO     1.0  1.0  0.0  0.0        2.0\n",
      "ZNF706    1.0  1.0  0.0  0.0        2.0\n",
      "DYNC1I2   1.0  0.0  1.0  0.0        2.0\n",
      "NXF1      1.0  0.0  1.0  0.0        2.0\n",
      "ANKH      0.0  1.0  1.0  0.0        2.0\n",
      "ANKRD10   0.0  1.0  1.0  0.0        2.0\n",
      "ANKRD26   0.0  1.0  1.0  0.0        2.0\n",
      "ARK2N     0.0  1.0  1.0  0.0        2.0\n",
      "ATP10D    0.0  1.0  1.0  0.0        2.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from itertools import combinations\n",
    "\n",
    "os.chdir(\"/Users/scottpowers/Desktop\")\n",
    "\n",
    "# --- load & clean ---\n",
    "df = pd.read_csv(\"module_correlations.csv\", skipinitialspace=True)  # comma-separated\n",
    "df.columns = df.columns.str.strip().str.lower()\n",
    "\n",
    "# keep only rows that satisfy your dependency criterion\n",
    "crit = (df['rho'] < 0) & (df['pval'] < 0.05)\n",
    "neg = df.loc[crit, ['module','gene']].drop_duplicates()\n",
    "\n",
    "# set of genes per module\n",
    "mods = ['IGE','SAT','IL2','MPC']\n",
    "S = {m: set(neg.loc[neg.module==m, 'gene']) for m in mods}\n",
    "\n",
    "# --- pairwise overlaps & Jaccard ---\n",
    "pair_rows = []\n",
    "for a,b in combinations(mods, 2):\n",
    "    inter = S[a] & S[b]\n",
    "    union = S[a] | S[b]\n",
    "    pair_rows.append({\n",
    "        'pair': f'{a}∩{b}',\n",
    "        'overlap_n': len(inter),\n",
    "        'size_'+a: len(S[a]),\n",
    "        'size_'+b: len(S[b]),\n",
    "        'jaccard': (len(inter)/len(union)) if union else 0.0\n",
    "    })\n",
    "pair_df = pd.DataFrame(pair_rows).sort_values('overlap_n', ascending=False)\n",
    "\n",
    "# --- triple overlaps ---\n",
    "tri_rows = []\n",
    "for a,b,c in combinations(mods, 3):\n",
    "    inter = S[a] & S[b] & S[c]\n",
    "    tri_rows.append({'triple': f'{a}∩{b}∩{c}', 'overlap_n': len(inter)})\n",
    "tri_df = pd.DataFrame(tri_rows).sort_values('overlap_n', ascending=False)\n",
    "\n",
    "# --- genes shared by >= 2 modules ---\n",
    "counts = (neg.assign(val=1)\n",
    "            .pivot_table(index='gene', columns='module', values='val', fill_value=0)\n",
    "            .reindex(columns=mods, fill_value=0))\n",
    "counts['n_modules'] = counts.sum(1)\n",
    "multi = counts[counts['n_modules']>=2].sort_values(['n_modules']+mods, ascending=False)\n",
    "\n",
    "# save detailed outputs\n",
    "counts.to_csv(\"dependency_flags_by_gene.csv\")  # 1/0 flags per module + n_modules\n",
    "pair_df.to_csv(\"pairwise_dependency_overlap.csv\", index=False)\n",
    "tri_df.to_csv(\"triple_dependency_overlap.csv\", index=False)\n",
    "multi.to_csv(\"genes_shared_in_2plus_modules.csv\")\n",
    "\n",
    "# quick text previews\n",
    "print(\"Pairwise overlaps:\\n\", pair_df.head(10), \"\\n\")\n",
    "print(\"Triple overlaps:\\n\", tri_df, \"\\n\")\n",
    "print(\"Top genes present in >=2 modules:\\n\", multi.head(25))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "c07d9766",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Fig 6A built\n",
      "  - Fig6A_UpSet.png (+ PDF if available)\n",
      "  - dependency_hits.csv + per-module *_hits.txt\n",
      "  - Fig6A_UpSet_intersections_all.tsv + _top15.tsv\n",
      "Hit method: fdr | Q_MAX: 0.1 ABS_R: 0.2 TOP_N: 100\n"
     ]
    }
   ],
   "source": [
    "# ==== Fig 6A — Overlap of dependency genes from shared_dependencies.csv (LONG format) ====\n",
    "# CONFIG\n",
    "PATH = \"shared_dependencies.csv\"          # long table with columns: module,gene,rho,pval,FDR\n",
    "MODULES = [\"SAT\",\"IGE\",\"IL2\",\"MPC\"]       # order will be preserved in the plot\n",
    "\n",
    "HIT_METHOD = \"fdr\"    # \"fdr\" or \"topn\"\n",
    "Q_MAX   = 0.10        # used if HIT_METHOD == \"fdr\"\n",
    "ABS_R   = 0.20        # used if HIT_METHOD == \"fdr\"\n",
    "TOP_N   = 100         # used if HIT_METHOD == \"topn\" or as fallback when no FDR hits\n",
    "\n",
    "OUT = \"Fig6A_UpSet\"\n",
    "TOP_INTERSECTIONS = 15\n",
    "\n",
    "# ---------------------------------------------------\n",
    "import pandas as pd, numpy as np, itertools, re\n",
    "\n",
    "# Use a headless backend to avoid GUI/freetype issues\n",
    "import matplotlib\n",
    "matplotlib.use(\"Agg\")\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "\n",
    "def _clean_symbol(s):\n",
    "    s = str(s)\n",
    "    s = s.replace(\"\\u00A0\",\" \").replace(\"\\u2009\",\" \").strip()\n",
    "    s = re.sub(r\"\\s+\", \"\", s)  # drop internal spaces: e.g., \"SOS 1\" -> \"SOS1\"\n",
    "    return s.upper()\n",
    "\n",
    "# ---- load & standardize ----\n",
    "df = pd.read_csv(PATH)\n",
    "need = [\"module\",\"gene\",\"rho\",\"pval\",\"FDR\"]\n",
    "missing = [c for c in need if c not in df.columns]\n",
    "if missing:\n",
    "    raise ValueError(f\"Missing expected columns {missing}; found {list(df.columns)}\")\n",
    "\n",
    "df[\"module\"] = df[\"module\"].astype(str).str.upper().str.strip()\n",
    "df[\"gene\"]   = df[\"gene\"].map(_clean_symbol)\n",
    "for c in [\"rho\",\"pval\",\"FDR\"]:\n",
    "    df[c] = pd.to_numeric(df[c], errors=\"coerce\")\n",
    "\n",
    "df = df[df[\"module\"].isin([m.upper() for m in MODULES])].dropna(subset=[\"gene\",\"rho\"])\n",
    "\n",
    "# ---- call hits per module ----\n",
    "hits = {}\n",
    "for mod in MODULES:\n",
    "    sub = df[df[\"module\"] == mod].dropna(subset=[\"rho\"])\n",
    "    if HIT_METHOD.lower() == \"fdr\":\n",
    "        kept = sub[(sub[\"FDR\"] <= Q_MAX) & (sub[\"rho\"].abs() >= ABS_R)]\n",
    "        if kept.empty:\n",
    "            kept = sub.sort_values(\"rho\", key=lambda s: s.abs(), ascending=False).head(TOP_N)\n",
    "    elif HIT_METHOD.lower() == \"topn\":\n",
    "        kept = sub.sort_values(\"rho\", key=lambda s: s.abs(), ascending=False).head(TOP_N)\n",
    "    else:\n",
    "        raise ValueError(\"HIT_METHOD must be 'fdr' or 'topn'\")\n",
    "    genes = sorted(set(kept[\"gene\"]))\n",
    "    hits[mod] = set(genes)\n",
    "    pd.Series(genes).to_csv(f\"{mod}_hits.txt\", index=False, header=False)\n",
    "\n",
    "# ---- wide 0/1 table ----\n",
    "all_genes = sorted(set().union(*hits.values())) if hits else []\n",
    "wide = pd.DataFrame({\"gene\": all_genes})\n",
    "for mod in MODULES:\n",
    "    wide[mod] = wide[\"gene\"].isin(hits.get(mod, set())).astype(int)\n",
    "wide.to_csv(\"dependency_hits.csv\", index=False)\n",
    "\n",
    "# ---- membership + exclusive intersections (UpSet-style) ----\n",
    "mdf = wide.set_index(\"gene\")[MODULES].astype(bool)\n",
    "\n",
    "def exclusive_intersections(mdf_bool):\n",
    "    cols = list(mdf_bool.columns)\n",
    "    rows = []\n",
    "    for r in range(1, len(cols)+1):\n",
    "        for comb in itertools.combinations(cols, r):\n",
    "            mask = mdf_bool[list(comb)].all(axis=1)\n",
    "            others = [c for c in cols if c not in comb]\n",
    "            if others:\n",
    "                mask &= ~mdf_bool[others].any(axis=1)\n",
    "            rows.append({\"intersection\":\"+\".join(comb), \"k\":r, \"count\":int(mask.sum())})\n",
    "    return pd.DataFrame(rows).sort_values([\"count\",\"k\",\"intersection\"], ascending=[False,True,True])\n",
    "\n",
    "inter_df = exclusive_intersections(mdf)\n",
    "inter_df.to_csv(f\"{OUT}_intersections_all.tsv\", sep=\"\\t\", index=False)\n",
    "inter_top = inter_df.head(TOP_INTERSECTIONS)\n",
    "inter_top.to_csv(f\"{OUT}_intersections_top{TOP_INTERSECTIONS}.tsv\", sep=\"\\t\", index=False)\n",
    "\n",
    "# ---- plot (bars + dot matrix + per-set sizes) ----\n",
    "set_sizes = mdf.sum(axis=0).astype(int).sort_values(ascending=False)\n",
    "\n",
    "fig = plt.figure(figsize=(8,6), constrained_layout=False)\n",
    "gs = fig.add_gridspec(nrows=4, ncols=5,\n",
    "                      height_ratios=[5,0.4,1.8,0.2],\n",
    "                      width_ratios=[5,0.6,0.6,0.6,2.0])\n",
    "\n",
    "ax_bar  = fig.add_subplot(gs[0, 0:4])\n",
    "ax_dots = fig.add_subplot(gs[2, 0:4])\n",
    "ax_set  = fig.add_subplot(gs[0:3, 4])\n",
    "\n",
    "# Bars\n",
    "x = np.arange(len(inter_top))\n",
    "ax_bar.bar(x, inter_top[\"count\"].values)\n",
    "ax_bar.set_ylabel(\"Genes in intersection\")\n",
    "ax_bar.set_xticks([])\n",
    "ax_bar.yaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "ax_bar.set_title(\"Dependency Gene Overlap — PDAC Modules\", pad=10)\n",
    "ymax = inter_top[\"count\"].max() if len(inter_top) else 0\n",
    "for xi, val in zip(x, inter_top[\"count\"].values):\n",
    "    ax_bar.text(xi, val + max(1, 0.02*max(1, ymax)), str(val),\n",
    "                ha=\"center\", va=\"bottom\", fontsize=9)\n",
    "\n",
    "# Dot matrix\n",
    "sets = MODULES[:]  # preserve order\n",
    "k = len(sets)\n",
    "mat = np.zeros((k, len(inter_top)), dtype=int)\n",
    "for col_i, inter_name in enumerate(inter_top[\"intersection\"].tolist()):\n",
    "    active = inter_name.split(\"+\")\n",
    "    for row_i, s in enumerate(sets):\n",
    "        mat[row_i, col_i] = 1 if s in active else 0\n",
    "for row_i in range(k):\n",
    "    where = mat[row_i]==1\n",
    "    ax_dots.scatter(x[where], np.full(where.sum(), k-1-row_i), s=60)\n",
    "    for col_i in range(len(x)):\n",
    "        if mat[row_i, col_i]==1:\n",
    "            active_rows = [ri for ri in range(k) if mat[ri, col_i]==1]\n",
    "            if active_rows:\n",
    "                ax_dots.plot([col_i,col_i], [k-1-active_rows[0], k-1-active_rows[-1]], linewidth=1)\n",
    "ax_dots.set_yticks(range(k)); ax_dots.set_yticklabels(list(reversed(sets)))\n",
    "ax_dots.set_xlabel(\"Intersections (top by size)\")\n",
    "ax_dots.set_xlim(-0.5, len(x)-0.5)\n",
    "ax_dots.set_xticks(range(len(x)))\n",
    "ax_dots.set_xticklabels(inter_top[\"intersection\"].tolist(), rotation=45, ha=\"right\", fontsize=8)\n",
    "ax_dots.set_ylim(-0.5, k-0.5)\n",
    "\n",
    "# Per-set sizes\n",
    "sizes_sorted = set_sizes\n",
    "y = np.arange(len(sizes_sorted))\n",
    "ax_set.barh(y, sizes_sorted.values)\n",
    "ax_set.set_yticks(y); ax_set.set_yticklabels(sizes_sorted.index.tolist())\n",
    "ax_set.invert_yaxis()\n",
    "ax_set.set_xlabel(\"Genes per module\")\n",
    "ax_set.xaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "\n",
    "plt.tight_layout()\n",
    "# Always save PNG; try PDF but don't crash if PDF backend is broken\n",
    "fig.savefig(f\"{OUT}.png\", dpi=300, bbox_inches=\"tight\")\n",
    "try:\n",
    "    fig.savefig(f\"{OUT}.pdf\", dpi=300, bbox_inches=\"tight\")\n",
    "except Exception as e:\n",
    "    print(f\"⚠️ PDF save failed; PNG written. Reason: {e}\")\n",
    "plt.close(fig)\n",
    "\n",
    "print(\"✅ Fig 6A built\")\n",
    "print(f\"  - {OUT}.png (+ PDF if available)\")\n",
    "print(\"  - dependency_hits.csv + per-module *_hits.txt\")\n",
    "print(f\"  - {OUT}_intersections_all.tsv + _top{TOP_INTERSECTIONS}.tsv\")\n",
    "print(\"Hit method:\", HIT_METHOD, \"| Q_MAX:\", Q_MAX, \"ABS_R:\", ABS_R, \"TOP_N:\", TOP_N)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "56a3cd83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Fig 6B saved as Fig6B_Overlap.png (+ PDF if available)\n"
     ]
    }
   ],
   "source": [
    "# ==== Fig 6B — Pairwise overlap (Jaccard + Fisher exact), diagonal grayed & excluded from scales ====\n",
    "IN   = \"dependency_hits.csv\"\n",
    "OUT  = \"Fig6B_Overlap\"\n",
    "MODULES = [\"SAT\",\"IGE\",\"IL2\",\"MPC\"]  # keep same order as Fig 6A\n",
    "\n",
    "import pandas as pd, numpy as np\n",
    "# Headless backend\n",
    "import matplotlib\n",
    "matplotlib.use(\"Agg\")\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ---------- load ----------\n",
    "wide = pd.read_csv(IN)\n",
    "wide[\"gene\"] = wide[\"gene\"].astype(str)\n",
    "for m in MODULES:\n",
    "    if m not in wide.columns:\n",
    "        wide[m] = 0\n",
    "wide = wide[[\"gene\"] + MODULES].copy()\n",
    "wide[MODULES] = wide[MODULES].astype(int)\n",
    "\n",
    "# ---------- helpers ----------\n",
    "def jaccard(a, b):\n",
    "    inter = int(((a==1)&(b==1)).sum())\n",
    "    union = int(((a==1)|(b==1)).sum())\n",
    "    return (inter / union) if union > 0 else 0.0, inter\n",
    "\n",
    "def fishers_exact(a, b):\n",
    "    a1 = int((a==1).sum()); b1 = int((b==1).sum())\n",
    "    a0 = len(a) - a1;       b0 = len(b) - b1\n",
    "    a1b1 = int(((a==1)&(b==1)).sum())\n",
    "    a1b0 = a1 - a1b1\n",
    "    a0b1 = b1 - a1b1\n",
    "    a0b0 = len(a) - (a1b1 + a1b0 + a0b1)\n",
    "    try:\n",
    "        from scipy.stats import fisher_exact\n",
    "        _, p = fisher_exact([[a1b1, a1b0],[a0b1, a0b0]], alternative=\"two-sided\")\n",
    "    except Exception:\n",
    "        # hypergeometric tail fallback\n",
    "        N = len(a)\n",
    "        from math import comb\n",
    "        def logC(n,k): return np.log(comb(n,k))\n",
    "        def pmf(x):\n",
    "            return np.exp(logC(b1,x)+logC(N-b1,a1-x)-logC(N,a1))\n",
    "        x_obs = a1b1\n",
    "        support = range(max(0, a1+b1-N), min(a1,b1)+1)\n",
    "        p_obs = pmf(x_obs)\n",
    "        p = sum(pmf(x) for x in support if pmf(x) <= p_obs)\n",
    "        p = min(1.0, float(p))\n",
    "    return p, a1b1\n",
    "\n",
    "# ---------- compute matrices ----------\n",
    "cols = MODULES\n",
    "k = len(cols)\n",
    "J    = np.zeros((k,k), dtype=float)   # Jaccard\n",
    "Nint = np.zeros((k,k), dtype=int)     # |A∩B|\n",
    "Q    = np.ones((k,k), dtype=float)    # BH-FDR q\n",
    "\n",
    "# raw p for BH\n",
    "pairs = []\n",
    "for i, mi in enumerate(cols):\n",
    "    ai = wide[mi].values\n",
    "    for j, mj in enumerate(cols):\n",
    "        aj = wide[mj].values\n",
    "        jv, inter = jaccard(ai, aj)\n",
    "        J[i,j] = jv\n",
    "        Nint[i,j] = inter\n",
    "        if i < j:\n",
    "            p, _ = fishers_exact(ai, aj)\n",
    "            pairs.append(((i,j), p))\n",
    "\n",
    "# BH-FDR on upper triangle\n",
    "if pairs:\n",
    "    idx, pvals = zip(*pairs)\n",
    "    pvals = np.array(pvals, float)\n",
    "    order = np.argsort(pvals)\n",
    "    m = len(pvals)\n",
    "    ranks = np.arange(1, m+1)[np.argsort(order)]\n",
    "    q_sorted = np.minimum.accumulate((pvals[order] * m / np.arange(1, m+1))[::-1])[::-1]\n",
    "    q = np.empty_like(pvals); q[order] = q_sorted\n",
    "    for (i,j), qv in zip(idx, q):\n",
    "        Q[i,j] = Q[j,i] = qv\n",
    "np.fill_diagonal(Q, np.nan)  # diagonal ignored\n",
    "\n",
    "# ---------- plotting ----------\n",
    "fig, axes = plt.subplots(1, 2, figsize=(8,4.8))\n",
    "(ax1, ax2) = axes\n",
    "\n",
    "# Panel 1: Jaccard (diagonal gray & excluded from vmin/vmax)\n",
    "J_plot = J.copy().astype(float)\n",
    "np.fill_diagonal(J_plot, np.nan)\n",
    "offdiag_J = J_plot[~np.isnan(J_plot)]\n",
    "vmin1, vmax1 = 0.0, (offdiag_J.max() if offdiag_J.size else 1.0)\n",
    "\n",
    "cmap1 = plt.cm.viridis.copy()\n",
    "cmap1.set_bad(color=\"lightgray\")  # diagonal\n",
    "im1 = ax1.imshow(J_plot, vmin=vmin1, vmax=vmax1, cmap=cmap1)\n",
    "ax1.set_xticks(range(k)); ax1.set_yticks(range(k))\n",
    "ax1.set_xticklabels(cols); ax1.set_yticklabels(cols)\n",
    "ax1.set_title(\"Jaccard overlap\")\n",
    "# annotate with |∩| counts except diagonal\n",
    "for i in range(k):\n",
    "    for j in range(k):\n",
    "        if i != j:\n",
    "            ax1.text(j, i, f\"{Nint[i,j]}\", ha=\"center\", va=\"center\", fontsize=9)\n",
    "\n",
    "cbar1 = fig.colorbar(im1, ax=ax1, fraction=0.046, pad=0.04)\n",
    "cbar1.set_label(\"Jaccard index\")\n",
    "\n",
    "# Panel 2: Fisher −log10(q) (diagonal gray & excluded from scale)\n",
    "neglogQ = -np.log10(np.clip(Q, 1e-300, 1.0))\n",
    "np.fill_diagonal(neglogQ, np.nan)\n",
    "offdiag_neglog = neglogQ[~np.isnan(neglogQ)]\n",
    "vmin2, vmax2 = 0.0, (offdiag_neglog.max() if offdiag_neglog.size else 1.0)\n",
    "\n",
    "cmap2 = plt.cm.magma.copy()\n",
    "cmap2.set_bad(color=\"lightgray\")  # diagonal\n",
    "im2 = ax2.imshow(neglogQ, vmin=vmin2, vmax=vmax2, cmap=cmap2)\n",
    "ax2.set_xticks(range(k)); ax2.set_yticks(range(k))\n",
    "ax2.set_xticklabels(cols); ax2.set_yticklabels(cols)\n",
    "ax2.set_title(\"Fisher overlap (−log10 q)\")\n",
    "\n",
    "# significance stars (skip diagonal)\n",
    "def stars(q):\n",
    "    if np.isnan(q): return \"\"\n",
    "    if q < 0.001: return \"***\"\n",
    "    if q < 0.01:  return \"**\"\n",
    "    if q < 0.05:  return \"*\"\n",
    "    return \"\"\n",
    "\n",
    "for i in range(k):\n",
    "    for j in range(k):\n",
    "        s = stars(Q[i,j])\n",
    "        if s:\n",
    "            ax2.text(j, i, s, ha=\"center\", va=\"center\", fontsize=12, fontweight=\"bold\")\n",
    "\n",
    "cbar2 = fig.colorbar(im2, ax=ax2, fraction=0.046, pad=0.04)\n",
    "cbar2.set_label(\"−log10(q)\")\n",
    "\n",
    "plt.suptitle(\"Dependency Gene Overlap: Pairwise Metrics\", y=0.98)\n",
    "plt.tight_layout(rect=[0,0,1,0.95])\n",
    "\n",
    "fig.savefig(f\"{OUT}.png\", dpi=300, bbox_inches=\"tight\")\n",
    "try:\n",
    "    fig.savefig(f\"{OUT}.pdf\", dpi=300, bbox_inches=\"tight\")\n",
    "except Exception as e:\n",
    "    print(f\"⚠️ PDF save failed; PNG written. Reason: {e}\")\n",
    "plt.close(fig)\n",
    "\n",
    "print(\"✅ Fig 6B saved as\", f\"{OUT}.png (+ PDF if available)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "f205d4ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/mh/r2nrb73509z0t_wjbx9r5fg00000gn/T/ipykernel_92012/4217200611.py:37: MatplotlibDeprecationWarning: The get_cmap function was deprecated in Matplotlib 3.7 and will be removed in 3.11. Use ``matplotlib.colormaps[name]`` or ``matplotlib.colormaps.get_cmap()`` or ``pyplot.get_cmap()`` instead.\n",
      "  cmap = plt.cm.get_cmap(\"coolwarm\").copy()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved Fig6B_DependencyCorr_CLUSTERED.png (+ PDF if available) [matplotlib fallback]\n",
      "(Seaborn path failed with: module 'matplotlib.cm' has no attribute 'register_cmap')\n"
     ]
    }
   ],
   "source": [
    "# ==== Fig 6B (Clustered) — robust dendrograms (seaborn first, matplotlib fallback) ====\n",
    "# Input: shared_dependencies.csv with columns: module,gene,rho,pval,FDR\n",
    "# Output: Fig6B_DependencyCorr_CLUSTERED.png (+ PDF if possible)\n",
    "\n",
    "PATH = \"shared_dependencies.csv\"\n",
    "OUT  = \"Fig6B_DependencyCorr_CLUSTERED\"\n",
    "MODULES = [\"SAT\",\"IGE\",\"IL2\",\"MPC\"]\n",
    "\n",
    "import pandas as pd, numpy as np\n",
    "import matplotlib\n",
    "matplotlib.use(\"Agg\")\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ---- Font: Arial (fallback to DejaVu) ----\n",
    "try:\n",
    "    from matplotlib import font_manager\n",
    "    if any(\"arial\" in f.name.lower() for f in font_manager.fontManager.ttflist):\n",
    "        plt.rcParams[\"font.family\"] = \"Arial\"\n",
    "    else:\n",
    "        plt.rcParams[\"font.family\"] = \"DejaVu Sans\"\n",
    "except Exception:\n",
    "    plt.rcParams[\"font.family\"] = \"DejaVu Sans\"\n",
    "\n",
    "# ---- Load & build module×module Spearman corr across genes ----\n",
    "df = pd.read_csv(PATH)\n",
    "df[\"module\"] = df[\"module\"].astype(str).str.upper().str.strip()\n",
    "df = df[df[\"module\"].isin(MODULES)]\n",
    "mat = (df.pivot_table(index=\"gene\", columns=\"module\", values=\"rho\")\n",
    "         .reindex(columns=MODULES))\n",
    "corr = mat.corr(method=\"spearman\").astype(float)\n",
    "labels = corr.index.tolist()\n",
    "\n",
    "# Gray out diagonal for plotting\n",
    "C = corr.copy()\n",
    "np.fill_diagonal(C.values, np.nan)\n",
    "vmin, vmax = -1.0, 1.0\n",
    "cmap = plt.cm.get_cmap(\"coolwarm\").copy()\n",
    "cmap.set_bad(color=\"lightgray\")  # diagonal\n",
    "\n",
    "# Try seaborn.clustermap first (most reliable dendrograms)\n",
    "try:\n",
    "    import seaborn as sns\n",
    "    from scipy.spatial.distance import squareform\n",
    "    from scipy.cluster.hierarchy import linkage\n",
    "\n",
    "    # Precompute average-linkage on 1 - corr (condensed)\n",
    "    D_condensed = squareform((1.0 - corr).clip(0, 2).values, checks=False)\n",
    "    Z = linkage(D_condensed, method=\"average\")\n",
    "\n",
    "    # Build clustermap. Use our precomputed linkages for both rows/cols.\n",
    "    # Place a wider colorbar (x, y, width, height) in figure coords.\n",
    "    cg = sns.clustermap(\n",
    "        C, row_linkage=Z, col_linkage=Z, cmap=cmap, vmin=vmin, vmax=vmax,\n",
    "        figsize=(8.2, 8.2), xticklabels=True, yticklabels=True,\n",
    "        dendrogram_ratio=(0.22, 0.22), cbar_pos=(0.86, 0.25, 0.04, 0.5)\n",
    "    )\n",
    "\n",
    "    # Remove cbar outline\n",
    "    try: cg.cax.outline.set_visible(False)\n",
    "    except Exception: pass\n",
    "\n",
    "    # Title\n",
    "    cg.ax_heatmap.set_title(\"Pairwise Dependency Correlations (Spearman, clustered)\")\n",
    "\n",
    "    # Black numeric annotations for off-diagonals in the reordered matrix\n",
    "    data2d = cg.data2d  # reordered DataFrame\n",
    "    for i, row in enumerate(data2d.index):\n",
    "        for j, col in enumerate(data2d.columns):\n",
    "            val = data2d.iat[i, j]\n",
    "            if not np.isnan(val):\n",
    "                cg.ax_heatmap.text(j, i, f\"{val:.2f}\", ha=\"center\", va=\"center\",\n",
    "                                   color=\"black\", fontsize=9)\n",
    "\n",
    "    # Save\n",
    "    cg.fig.savefig(f\"{OUT}.png\", dpi=300, bbox_inches=\"tight\")\n",
    "    try:\n",
    "        cg.fig.savefig(f\"{OUT}.pdf\", dpi=300, bbox_inches=\"tight\")\n",
    "    except Exception as e:\n",
    "        print(f\"⚠️ PDF save failed; PNG written. Reason: {e}\")\n",
    "    plt.close(cg.fig)\n",
    "    print(f\"✅ Saved {OUT}.png (+ PDF if available) [seaborn.clustermap]\")\n",
    "except Exception as seaborn_err:\n",
    "    # ---- Matplotlib/SciPy fallback with explicit dendrogram axes ----\n",
    "    from matplotlib.gridspec import GridSpec\n",
    "    try:\n",
    "        from scipy.spatial.distance import squareform\n",
    "        from scipy.cluster.hierarchy import linkage, dendrogram\n",
    "        D_condensed = squareform((1.0 - corr).clip(0, 2).values, checks=False)\n",
    "        Z = linkage(D_condensed, method=\"average\")\n",
    "    except Exception:\n",
    "        Z = None\n",
    "\n",
    "    fig = plt.figure(figsize=(8.0, 8.0))\n",
    "    gs = GridSpec(nrows=2, ncols=2, height_ratios=[0.30, 1.0], width_ratios=[0.30, 1.0], figure=fig)\n",
    "    ax_dtop  = fig.add_subplot(gs[0, 1])\n",
    "    ax_dleft = fig.add_subplot(gs[1, 0])\n",
    "    ax_hm    = fig.add_subplot(gs[1, 1])\n",
    "\n",
    "    # Order from Z (or eigen fallback)\n",
    "    if Z is not None:\n",
    "        leaves = dendrogram(Z, no_plot=True)[\"leaves\"]\n",
    "    else:\n",
    "        w, v = np.linalg.eig(corr.values)\n",
    "        leaves = list(np.argsort(np.real(v[:, np.argmax(np.real(w))])))\n",
    "\n",
    "    labels_ord = [labels[i] for i in leaves]\n",
    "    C_ord = C.values[np.ix_(leaves, leaves)]\n",
    "\n",
    "    # Draw dendrograms with safe defaults (and then force line color/width)\n",
    "    if Z is not None:\n",
    "        dtop = dendrogram(Z, ax=ax_dtop, no_labels=True, color_threshold=None)\n",
    "        ax_dtop.set_xticks([]); ax_dtop.set_yticks([])\n",
    "        for spine in ax_dtop.spines.values(): spine.set_visible(False)\n",
    "        for line in ax_dtop.get_lines():\n",
    "            line.set_color(\"black\"); line.set_linewidth(1.6)\n",
    "\n",
    "        dleft = dendrogram(Z, ax=ax_dleft, orientation=\"right\", no_labels=True, color_threshold=None)\n",
    "        ax_dleft.set_xticks([]); ax_dleft.set_yticks([])\n",
    "        for spine in ax_dleft.spines.values(): spine.set_visible(False)\n",
    "        for line in ax_dleft.get_lines():\n",
    "            line.set_color(\"black\"); line.set_linewidth(1.6)\n",
    "    else:\n",
    "        ax_dtop.axis(\"off\")\n",
    "        ax_dleft.axis(\"off\")\n",
    "\n",
    "    # Heatmap\n",
    "    im = ax_hm.imshow(C_ord, vmin=vmin, vmax=vmax, cmap=cmap)\n",
    "    ax_hm.set_xticks(range(len(labels_ord))); ax_hm.set_yticks(range(len(labels_ord)))\n",
    "    ax_hm.set_xticklabels(labels_ord); ax_hm.set_yticklabels(labels_ord)\n",
    "    ax_hm.set_title(\"Pairwise Dependency Correlations (Spearman, clustered)\")\n",
    "\n",
    "    # Black numeric annotations (skip diagonal NaNs)\n",
    "    for i in range(len(labels_ord)):\n",
    "        for j in range(len(labels_ord)):\n",
    "            if not np.isnan(C_ord[i, j]):\n",
    "                ax_hm.text(j, i, f\"{C_ord[i,j]:.2f}\", ha=\"center\", va=\"center\",\n",
    "                           color=\"black\", fontsize=10)\n",
    "\n",
    "    # Wider colorbar, no outline\n",
    "    cbar = fig.colorbar(im, ax=ax_hm, fraction=0.06, pad=0.02)\n",
    "    try: cbar.outline.set_visible(False)\n",
    "    except Exception: pass\n",
    "    cbar.set_label(\"Spearman correlation\", rotation=90)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    fig.savefig(f\"{OUT}.png\", dpi=300, bbox_inches=\"tight\")\n",
    "    try:\n",
    "        fig.savefig(f\"{OUT}.pdf\", dpi=300, bbox_inches=\"tight\")\n",
    "    except Exception as e:\n",
    "        print(f\"⚠️ PDF save failed; PNG written. Reason: {e}\")\n",
    "    plt.close(fig)\n",
    "    print(f\"✅ Saved {OUT}.png (+ PDF if available) [matplotlib fallback]\")\n",
    "    if 'seaborn_err' in locals():\n",
    "        print(f\"(Seaborn path failed with: {seaborn_err})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "218369d3",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'matplotlib.cm' has no attribute 'register_cmap'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[72], line 8\u001b[0m\n\u001b[1;32m      6\u001b[0m matplotlib\u001b[38;5;241m.\u001b[39muse(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAgg\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mseaborn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01msns\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mspatial\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistance\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m squareform\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcluster\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mhierarchy\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m linkage\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/seaborn/__init__.py:9\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcategorical\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m  \u001b[38;5;66;03m# noqa: F401,F403\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistributions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m  \u001b[38;5;66;03m# noqa: F401,F403\u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmatrix\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m  \u001b[38;5;66;03m# noqa: F401,F403\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmiscplot\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m  \u001b[38;5;66;03m# noqa: F401,F403\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01maxisgrid\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m  \u001b[38;5;66;03m# noqa: F401,F403\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/seaborn/matrix.py:12\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcluster\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m hierarchy\n\u001b[0;32m---> 12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m cm\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01maxisgrid\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Grid\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     15\u001b[0m     despine,\n\u001b[1;32m     16\u001b[0m     axis_ticklabels_overlap,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     19\u001b[0m     _draw_figure,\n\u001b[1;32m     20\u001b[0m )\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/seaborn/cm.py:1582\u001b[0m\n\u001b[1;32m   1579\u001b[0m     _cmap_r \u001b[38;5;241m=\u001b[39m colors\u001b[38;5;241m.\u001b[39mListedColormap(_lut[::\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m], _name \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_r\u001b[39m\u001b[38;5;124m\"\u001b[39m)  \n\u001b[1;32m   1580\u001b[0m     \u001b[38;5;28mlocals\u001b[39m()[_name \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_r\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m _cmap_r\n\u001b[0;32m-> 1582\u001b[0m     \u001b[43mmpl_cm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mregister_cmap\u001b[49m(_name, _cmap)\n\u001b[1;32m   1583\u001b[0m     mpl_cm\u001b[38;5;241m.\u001b[39mregister_cmap(_name \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_r\u001b[39m\u001b[38;5;124m\"\u001b[39m, _cmap_r)\n\u001b[1;32m   1585\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m colors, mpl_cm\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'matplotlib.cm' has no attribute 'register_cmap'"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "# Fig 6B — Pairwise dependency correlations (side dendrogram only, spaced colorbar)\n",
    "\n",
    "import pandas as pd, numpy as np\n",
    "import matplotlib\n",
    "matplotlib.use(\"Agg\")\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.spatial.distance import squareform\n",
    "from scipy.cluster.hierarchy import linkage\n",
    "\n",
    "plt.rcParams.update({\n",
    "    \"font.size\": 10, \"axes.titlesize\": 12, \"xtick.labelsize\": 11, \"ytick.labelsize\": 11,\n",
    "    \"figure.dpi\": 300, \"savefig.dpi\": 300, \"figure.facecolor\": \"white\", \"savefig.facecolor\": \"white\",\n",
    "})\n",
    "try:\n",
    "    from matplotlib import font_manager\n",
    "    if any(\"arial\" in f.name.lower() for f in font_manager.fontManager.ttflist):\n",
    "        plt.rcParams[\"font.family\"] = \"Arial\"\n",
    "    else:\n",
    "        plt.rcParams[\"font.family\"] = \"DejaVu Sans\"\n",
    "except Exception:\n",
    "    plt.rcParams[\"font.family\"] = \"DejaVu Sans\"\n",
    "\n",
    "PATH = \"shared_dependencies.csv\"\n",
    "OUT  = \"Fig6B_DependencyCorr_SIDEonly_final\"\n",
    "MODULES = [\"SAT\",\"IGE\",\"IL2\",\"MPC\"]\n",
    "\n",
    "df = pd.read_csv(PATH)\n",
    "df[\"module\"] = df[\"module\"].astype(str).str.upper().str.strip()\n",
    "df = df[df[\"module\"].isin(MODULES)]\n",
    "mat = df.pivot_table(index=\"gene\", columns=\"module\", values=\"rho\").reindex(columns=MODULES)\n",
    "corr = mat.corr(method=\"spearman\").astype(float)\n",
    "\n",
    "C = corr.copy()\n",
    "np.fill_diagonal(C.values, np.nan)\n",
    "cmap = plt.cm.get_cmap(\"coolwarm\").copy()\n",
    "cmap.set_bad(\"lightgray\")\n",
    "\n",
    "D = squareform((1.0 - corr).clip(0, 2).values, checks=False)\n",
    "Z = linkage(D, method=\"average\")\n",
    "\n",
    "sns.set_context(\"notebook\")\n",
    "cg = sns.clustermap(\n",
    "    C,\n",
    "    row_linkage=Z,\n",
    "    col_linkage=Z,\n",
    "    cmap=cmap, vmin=-1, vmax=1,\n",
    "    figsize=(5.2, 5.2),\n",
    "    xticklabels=True, yticklabels=True,\n",
    "    dendrogram_ratio=(0.18, 0.001),      # only side dendrogram\n",
    "    cbar_pos=(0.95, 0.3, 0.03, 0.5),     # more gap & simple 0.5 height\n",
    ")\n",
    "\n",
    "# Hide top dendrogram\n",
    "cg.ax_col_dendrogram.set_visible(False)\n",
    "\n",
    "# Title and cleanup\n",
    "cg.ax_heatmap.set_title(\"Pairwise Module Dependency Correlations\", pad=10)\n",
    "cg.ax_heatmap.set_xlabel(\"\"); cg.ax_heatmap.set_ylabel(\"\")\n",
    "\n",
    "# Style side dendrogram\n",
    "for line in cg.ax_row_dendrogram.collections:\n",
    "    line.set_color(\"black\"); line.set_linewidth(1.1)\n",
    "cg.ax_row_dendrogram.set_xticks([]); cg.ax_row_dendrogram.set_yticks([])\n",
    "for s in cg.ax_row_dendrogram.spines.values(): s.set_visible(False)\n",
    "\n",
    "# Colorbar with adjusted label\n",
    "cbar = cg.ax_heatmap.collections[0].colorbar\n",
    "cbar.set_label(\"Correlation\", rotation=90)\n",
    "try: cbar.outline.set_visible(False)\n",
    "except Exception: pass\n",
    "\n",
    "cg.fig.tight_layout()\n",
    "cg.fig.savefig(f\"{OUT}.png\", bbox_inches=\"tight\")\n",
    "try: cg.fig.savefig(f\"{OUT}.pdf\", bbox_inches=\"tight\")\n",
    "except Exception as e: print(f\"⚠️ PDF save failed; {e}\")\n",
    "try: cg.fig.savefig(f\"{OUT}.svg\", bbox_inches=\"tight\")\n",
    "except Exception: pass\n",
    "\n",
    "print(f\"✅ Saved {OUT}.png (+ PDF/SVG if available)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "2ef62f13",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'matplotlib.cm' has no attribute 'register_cmap'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[73], line 8\u001b[0m\n\u001b[1;32m      6\u001b[0m matplotlib\u001b[38;5;241m.\u001b[39muse(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAgg\u001b[39m\u001b[38;5;124m\"\u001b[39m)  \u001b[38;5;66;03m# safe in notebooks & headless\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mseaborn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01msns\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpatches\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Patch\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m font_manager \u001b[38;5;28;01mas\u001b[39;00m _fm, text \u001b[38;5;28;01mas\u001b[39;00m _mtext\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/seaborn/__init__.py:9\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcategorical\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m  \u001b[38;5;66;03m# noqa: F401,F403\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistributions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m  \u001b[38;5;66;03m# noqa: F401,F403\u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmatrix\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m  \u001b[38;5;66;03m# noqa: F401,F403\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmiscplot\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m  \u001b[38;5;66;03m# noqa: F401,F403\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01maxisgrid\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m  \u001b[38;5;66;03m# noqa: F401,F403\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/seaborn/matrix.py:12\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcluster\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m hierarchy\n\u001b[0;32m---> 12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m cm\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01maxisgrid\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Grid\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     15\u001b[0m     despine,\n\u001b[1;32m     16\u001b[0m     axis_ticklabels_overlap,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     19\u001b[0m     _draw_figure,\n\u001b[1;32m     20\u001b[0m )\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/seaborn/cm.py:1582\u001b[0m\n\u001b[1;32m   1579\u001b[0m     _cmap_r \u001b[38;5;241m=\u001b[39m colors\u001b[38;5;241m.\u001b[39mListedColormap(_lut[::\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m], _name \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_r\u001b[39m\u001b[38;5;124m\"\u001b[39m)  \n\u001b[1;32m   1580\u001b[0m     \u001b[38;5;28mlocals\u001b[39m()[_name \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_r\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m _cmap_r\n\u001b[0;32m-> 1582\u001b[0m     \u001b[43mmpl_cm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mregister_cmap\u001b[49m(_name, _cmap)\n\u001b[1;32m   1583\u001b[0m     mpl_cm\u001b[38;5;241m.\u001b[39mregister_cmap(_name \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_r\u001b[39m\u001b[38;5;124m\"\u001b[39m, _cmap_r)\n\u001b[1;32m   1585\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m colors, mpl_cm\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'matplotlib.cm' has no attribute 'register_cmap'"
     ]
    }
   ],
   "source": [
    "# === Figure 6A — Module-Specific Dependency Signatures (self-contained) ===\n",
    "# Paste this as a single cell and run. No CLI args required.\n",
    "\n",
    "import os, numpy as np, pandas as pd\n",
    "import matplotlib\n",
    "matplotlib.use(\"Agg\")  # safe in notebooks & headless\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from matplotlib.patches import Patch\n",
    "from matplotlib import font_manager as _fm, text as _mtext\n",
    "\n",
    "# ---------------- USER SETTINGS ----------------\n",
    "PATH_IN = None  # if None, will try \"all_dependencies.csv\" then \"shared_dependencies.csv\"\n",
    "OUT     = \"Fig6A_ModuleDependencyHeatmap\"\n",
    "\n",
    "MODULES = [\"IGE\",\"SAT\",\"IL2\",\"MPC\"]\n",
    "\n",
    "# Curated genes per module (from manuscript text)\n",
    "CURATED = {\n",
    "    \"IGE\": [\"VPS4B\",\"UTP23\",\"HSCB\",\"MRPL13\",\"MRPS18B\",\"NDUFAF3\",\"NDUFS6\",\n",
    "            \"POLR1A\",\"POLR1C\",\"EIF3C\",\"EIF4A1\",\"DHX37\"],\n",
    "    \"SAT\": [\"HSPA5\",\"HSP90B1\",\"DNAJB11\",\"PSMC3\",\"PSMD2\",\"VCP\",\"ATF4\",\"DDIT3\"],\n",
    "    \"IL2\": [\"JAK1\",\"STAT5B\",\"IL6ST\",\"SOCS1\",\"SOCS3\",\"IRF1\",\"IRF7\",\"PSME1\",\"SEC61A1\"],\n",
    "    \"MPC\": [\"RHOA\",\"RAC1\",\"CDC42\",\"PAK4\",\"ARF6\",\"RAB11FIP1\",\"VIM\",\"CTNNB1\",\"PTK2\"],\n",
    "}\n",
    "\n",
    "# Biological category per gene (for row color strip)\n",
    "CATEGORY_MAP = {\n",
    "    # IGE\n",
    "    \"HSCB\":\"Mitochondrial\",\"MRPL13\":\"Ribosomal\",\"MRPS18B\":\"Ribosomal\",\n",
    "    \"NDUFAF3\":\"Mitochondrial\",\"NDUFS6\":\"Mitochondrial\",\n",
    "    \"POLR1A\":\"RNA processing\",\"POLR1C\":\"RNA processing\",\"EIF3C\":\"RNA processing\",\n",
    "    \"EIF4A1\":\"RNA processing\",\"DHX37\":\"RNA processing\",\"UTP23\":\"Ribosomal\",\n",
    "    \"VPS4B\":\"Trafficking/Endocytosis\",\n",
    "    # SAT\n",
    "    \"HSPA5\":\"Proteostasis/UPR\",\"HSP90B1\":\"Proteostasis/UPR\",\"DNAJB11\":\"Proteostasis/UPR\",\n",
    "    \"PSMC3\":\"Proteostasis/UPR\",\"PSMD2\":\"Proteostasis/UPR\",\"VCP\":\"Proteostasis/UPR\",\n",
    "    \"ATF4\":\"Proteostasis/UPR\",\"DDIT3\":\"Proteostasis/UPR\",\n",
    "    # IL2\n",
    "    \"JAK1\":\"Cytokine signaling\",\"STAT5B\":\"Cytokine signaling\",\"IL6ST\":\"Cytokine signaling\",\n",
    "    \"SOCS1\":\"Cytokine signaling\",\"SOCS3\":\"Cytokine signaling\",\n",
    "    \"IRF1\":\"Cytokine signaling\",\"IRF7\":\"Cytokine signaling\",\n",
    "    \"PSME1\":\"Cytokine signaling\",\"SEC61A1\":\"Trafficking/Endocytosis\",\n",
    "    # MPC\n",
    "    \"RHOA\":\"Cytoskeletal/Adhesion\",\"RAC1\":\"Cytoskeletal/Adhesion\",\"CDC42\":\"Cytoskeletal/Adhesion\",\n",
    "    \"PAK4\":\"Cytoskeletal/Adhesion\",\"ARF6\":\"Trafficking/Endocytosis\",\"RAB11FIP1\":\"Trafficking/Endocytosis\",\n",
    "    \"VIM\":\"Cytoskeletal/Adhesion\",\"CTNNB1\":\"Cytoskeletal/Adhesion\",\"PTK2\":\"Cytoskeletal/Adhesion\",\n",
    "}\n",
    "CAT_PALETTE = {\n",
    "    \"Mitochondrial\":\"#2E7D32\",\"Ribosomal\":\"#6A1B9A\",\"RNA processing\":\"#EF6C00\",\n",
    "    \"Proteostasis/UPR\":\"#1565C0\",\"Cytokine signaling\":\"#AD1457\",\n",
    "    \"Trafficking/Endocytosis\":\"#00838F\",\"Cytoskeletal/Adhesion\":\"#5D4037\",\n",
    "    \"Other\":\"#9E9E9E\",\n",
    "}\n",
    "\n",
    "# Data-driven extras (optional): include additional genes per module with strong association\n",
    "FDR_MAX = 0.25\n",
    "ABS_R_MIN = 0.25\n",
    "TOP_N_PER_MODULE = 12\n",
    "\n",
    "# Presentation\n",
    "FIGSIZE = (6.6, 8.2)     # inches\n",
    "VMIN, VMAX = -1.0, 1.0\n",
    "MAX_ROWS = 32            # keep compact; set None to keep all rows that have data\n",
    "FONT_FAMILY = \"Arial\"    # will fall back to DejaVu Sans if Arial unavailable\n",
    "TITLE = \"Module-Specific Dependency Signatures\"\n",
    "\n",
    "# ---------------- LOAD DATA ----------------\n",
    "candidates = [PATH_IN] if PATH_IN else [\"all_dependencies.csv\", \"shared_dependencies.csv\"]\n",
    "PATH_USED = next((p for p in candidates if p and os.path.exists(p)), None)\n",
    "if PATH_USED is None:\n",
    "    raise FileNotFoundError(\"Could not find 'all_dependencies.csv' or 'shared_dependencies.csv'. Set PATH_IN.\")\n",
    "\n",
    "df = pd.read_csv(PATH_USED)\n",
    "for col in [\"module\",\"gene\"]:\n",
    "    df[col] = df[col].astype(str).str.upper().str.strip()\n",
    "df = df.drop_duplicates(subset=[\"module\",\"gene\"])\n",
    "df = df[df[\"module\"].isin(MODULES)].copy()\n",
    "\n",
    "# ---------------- BUILD DISPLAY GENE ORDER ----------------\n",
    "display_genes = []\n",
    "# curated first\n",
    "for m in MODULES:\n",
    "    for g in CURATED[m]:\n",
    "        if g not in display_genes:\n",
    "            display_genes.append(g)\n",
    "\n",
    "# optional extras meeting thresholds\n",
    "extras = set()\n",
    "if {\"rho\",\"FDR\"}.issubset(df.columns):\n",
    "    for m in MODULES:\n",
    "        sub = df[df[\"module\"] == m].copy()\n",
    "        sub = sub[(sub[\"FDR\"] <= FDR_MAX) & (sub[\"rho\"].abs() >= ABS_R_MIN)]\n",
    "        sub = sub.assign(abs_r=sub[\"rho\"].abs()).sort_values(\"abs_r\", ascending=False)\n",
    "        extras |= set(sub[\"gene\"].head(TOP_N_PER_MODULE))\n",
    "for g in sorted(extras):\n",
    "    if g not in display_genes:\n",
    "        display_genes.append(g)\n",
    "\n",
    "# pivot\n",
    "mat = df.pivot_table(index=\"gene\", columns=\"module\", values=\"rho\", aggfunc=\"mean\")\n",
    "# ensure curated rows exist (NaN if absent)\n",
    "for g in display_genes:\n",
    "    if g not in mat.index:\n",
    "        mat.loc[g] = np.nan\n",
    "mat = mat.loc[display_genes, MODULES]\n",
    "# drop rows with no data at all\n",
    "mat = mat.loc[mat.notna().any(axis=1)]\n",
    "\n",
    "# optional cap (curated prioritized)\n",
    "if MAX_ROWS is not None and mat.shape[0] > MAX_ROWS:\n",
    "    curated = [g for m in MODULES for g in CURATED[m] if g in mat.index]\n",
    "    extras_order = [g for g in mat.index if g not in curated]\n",
    "    keep = curated + extras_order\n",
    "    mat = mat.loc[keep[:MAX_ROWS]]\n",
    "\n",
    "# Row color strip by category\n",
    "def _cat(g): return CATEGORY_MAP.get(g, \"Other\")\n",
    "row_colors = [CAT_PALETTE.get(_cat(g), CAT_PALETTE[\"Other\"]) for g in mat.index]\n",
    "\n",
    "# colormap with gray for missing values\n",
    "CMAP = plt.cm.get_cmap(\"coolwarm\").copy()\n",
    "CMAP.set_bad(\"#d9d9d9\")\n",
    "\n",
    "# ---------------- PLOT ----------------\n",
    "# Base rcParams (will still be hard-forced below for clustermap)\n",
    "plt.rcParams.update({\n",
    "    \"figure.dpi\":300, \"savefig.dpi\":300,\n",
    "    \"figure.facecolor\":\"white\", \"savefig.facecolor\":\"white\",\n",
    "    \"font.size\":8, \"axes.titlesize\":8, \"axes.labelsize\":9\n",
    "})\n",
    "\n",
    "sns.set_context(\"notebook\")\n",
    "cg = sns.clustermap(\n",
    "    mat,\n",
    "    row_cluster=False, col_cluster=False,  # no clustering; fixed order\n",
    "    row_colors=row_colors,\n",
    "    cmap=CMAP, vmin=VMIN, vmax=VMAX,\n",
    "    figsize=FIGSIZE,\n",
    "    linewidths=0.4, linecolor=\"white\",\n",
    "    # wider / separated colorbar (left, bottom, width, height as fractions)\n",
    "    cbar_pos=(0.92, 0.22, 0.05, 0.58)\n",
    ")\n",
    "\n",
    "ax = cg.ax_heatmap\n",
    "ax.set_title(TITLE, pad=8)\n",
    "ax.set_xlabel(\"Module\")\n",
    "ax.set_ylabel(\"Gene\")\n",
    "ax.set_xticklabels(ax.get_xticklabels(), rotation=0)\n",
    "ax.set_yticklabels(ax.get_yticklabels(), rotation=0)\n",
    "\n",
    "# Colorbar formatting: ticks every 0.5 from -1 to 1\n",
    "cbar = ax.collections[0].colorbar\n",
    "cbar.set_label(\"Dependency (ρ)\")\n",
    "cbar.set_ticks(np.arange(-1.0, 1.01, 0.5))\n",
    "try: cbar.outline.set_visible(False)\n",
    "except Exception: pass\n",
    "\n",
    "# Category legend\n",
    "handles = [Patch(facecolor=col, edgecolor=\"none\", label=lab)\n",
    "           for lab, col in CAT_PALETTE.items()]\n",
    "leg = ax.legend(handles=handles, title=\"Category\",\n",
    "                loc=\"upper left\", bbox_to_anchor=(1.02, 1.02),\n",
    "                frameon=False, fontsize=9, title_fontsize=10)\n",
    "\n",
    "# ---------------- FORCE FONTS/SIZES (clustermap-safe) ----------------\n",
    "def _has_font(name: str) -> bool:\n",
    "    try:\n",
    "        return any(name.lower() in f.name.lower() for f in _fm.fontManager.ttflist)\n",
    "    except Exception:\n",
    "        return False\n",
    "\n",
    "_family = FONT_FAMILY if _has_font(FONT_FAMILY) else \"DejaVu Sans\"\n",
    "\n",
    "def _force_fonts(cg,\n",
    "                 family=_family,\n",
    "                 title_fs=12, label_fs=11, tick_fs=10, cbar_fs=9, legend_fs=9):\n",
    "    ax = cg.ax_heatmap\n",
    "    # title & labels\n",
    "    ax.set_title(ax.get_title(), fontsize=title_fs, fontfamily=family, pad=8)\n",
    "    ax.set_xlabel(ax.get_xaxis().get_label().get_text(), fontsize=label_fs, fontfamily=family)\n",
    "    ax.set_ylabel(ax.get_yaxis().get_label().get_text(), fontsize=label_fs, fontfamily=family)\n",
    "    # ticks\n",
    "    ax.tick_params(axis=\"x\", labelsize=tick_fs)\n",
    "    ax.tick_params(axis=\"y\", labelsize=tick_fs)\n",
    "    for t in list(ax.get_xticklabels()) + list(ax.get_yticklabels()):\n",
    "        t.set_fontsize(tick_fs); t.set_fontfamily(family)\n",
    "    # colorbar\n",
    "    cbar = ax.collections[0].colorbar\n",
    "    cbar.set_label(cbar.ax.get_ylabel() or \"Dependency (ρ)\", fontsize=label_fs, fontfamily=family)\n",
    "    cbar.ax.tick_params(labelsize=cbar_fs)\n",
    "    for t in cbar.ax.get_yticklabels():\n",
    "        t.set_fontsize(cbar_fs); t.set_fontfamily(family)\n",
    "    # legend\n",
    "    lg = ax.get_legend() or leg\n",
    "    if lg:\n",
    "        if lg.get_title():\n",
    "            lg.set_title(lg.get_title().get_text(), prop={\"size\": legend_fs, \"family\": family})\n",
    "        for txt in lg.get_texts():\n",
    "            txt.set_fontsize(legend_fs); txt.set_fontfamily(family)\n",
    "    # all other text objects → ensure family\n",
    "    for txt in cg.fig.findobj(_mtext.Text):\n",
    "        if txt.get_text():\n",
    "            try: txt.set_fontfamily(family)\n",
    "            except Exception: pass\n",
    "\n",
    "# apply (twice to beat any post-draw adjustments)\n",
    "cg.fig.canvas.draw()\n",
    "_force_fonts(cg)\n",
    "cg.fig.canvas.draw()\n",
    "_force_fonts(cg)\n",
    "\n",
    "# Bold curated labels\n",
    "curated_flat = {g for m in MODULES for g in CURATED[m]}\n",
    "for lbl in ax.get_yticklabels():\n",
    "    if lbl.get_text().upper() in curated_flat:\n",
    "        try: lbl.set_fontweight(\"bold\")\n",
    "        except Exception: pass\n",
    "\n",
    "# Tight layout & SAVE\n",
    "cg.fig.tight_layout()\n",
    "cg.fig.savefig(f\"{OUT}.png\", bbox_inches=\"tight\")\n",
    "for ext in (\"pdf\",\"svg\"):\n",
    "    try:\n",
    "        cg.fig.savefig(f\"{OUT}.{ext}\", bbox_inches=\"tight\")\n",
    "    except Exception as e:\n",
    "        print(f\"⚠️ {ext.upper()} save failed; continuing. Reason: {e}\")\n",
    "\n",
    "# Export list of displayed genes + categories (for methods/caption)\n",
    "(pd.DataFrame({\"gene\": mat.index, \"category\": [CATEGORY_MAP.get(g, 'Other') for g in mat.index]})\n",
    "   .to_csv(f\"{OUT}_genes.tsv\", sep=\"\\t\", index=False))\n",
    "\n",
    "print(f\"✅ Fig 6A saved → {OUT}.png (+PDF/SVG if available)\")\n",
    "print(f\"   Source file: {PATH_USED} | Rows plotted: {mat.shape[0]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "7f54655f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/mh/r2nrb73509z0t_wjbx9r5fg00000gn/T/ipykernel_92012/3692122939.py:172: UserWarning: This figure includes Axes that are not compatible with tight_layout, so results might be incorrect.\n",
      "  fig.tight_layout()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Wrote Fig6A_StrongDependencies.png\n",
      "  filters: dependency-only (ρ ≤ -0.05), FDR ≤ 0.9, top 4/module\n"
     ]
    }
   ],
   "source": [
    "# === Fig 6A: Strong Dependency Signatures by Module (dependencies only) ===\n",
    "# Inputs:  all_dependencies.csv  with columns: module,gene,rho,pval,FDR,kind\n",
    "# Output:  Fig6A_StrongDependencies.png\n",
    "#\n",
    "# Notes:\n",
    "# - We keep only \"kind == dependency\"\n",
    "# - We include ONLY negative correlations (dependency) by default (KEEP_NEG=True)\n",
    "# - We select top N by absolute rho per module, after thresholds.\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import TwoSlopeNorm\n",
    "\n",
    "# ------------------- CONFIG -------------------\n",
    "CSV_IN = \"all_dependencies.csv\"\n",
    "OUT_PNG = \"Fig6A_StrongDependencies.png\"\n",
    "\n",
    "MODULES = [\"IGE\", \"SAT\", \"IL2\", \"MPC\"]   # display order\n",
    "FDR_MAX   = 0.9   # allow slightly higher q-values\n",
    "ABS_R_MIN = 0.05   # accept moderately strong dependencies\n",
    "TOP_N_PER_MODULE = 4\n",
    "\n",
    "KEEP_NEG = True   # True = keep rho <= -ABS_R_MIN (dependencies); False = keep rho >= +ABS_R_MIN (resistance)\n",
    "\n",
    "# Fonts / style\n",
    "matplotlib.rcParams.update({\n",
    "    \"font.family\": \"Arial\",\n",
    "    \"axes.titlesize\": 16,\n",
    "    \"axes.labelsize\": 14,\n",
    "    \"xtick.labelsize\": 12,\n",
    "    \"ytick.labelsize\": 12,\n",
    "})\n",
    "\n",
    "# Left color strip for module groups (choose any you like)\n",
    "MODULE_COLORS = {\n",
    "    \"IGE\": \"#2ca25f\",   # green\n",
    "    \"SAT\": \"#ef8a62\",   # salmon\n",
    "    \"IL2\": \"#67a9cf\",   # blue\n",
    "    \"MPC\": \"#984ea3\",   # purple\n",
    "}\n",
    "\n",
    "# ------------------- LOAD -------------------\n",
    "df = pd.read_csv(CSV_IN)\n",
    "# Exclude spurious or irrelevant genes\n",
    "EXCLUDE_GENES = {\"OR1Q1\",\"LHFPL1\",\"KIF4B\",'ASPM','C16orf89'}       # add more if needed\n",
    "df = df[~df[\"gene\"].isin(EXCLUDE_GENES)]\n",
    "\n",
    "\n",
    "required = {\"module\",\"gene\",\"rho\",\"FDR\"}\n",
    "missing = required - set(df.columns)\n",
    "if missing:\n",
    "    raise ValueError(f\"Missing columns in {CSV_IN}: {sorted(missing)}\")\n",
    "\n",
    "# If a 'kind' column exists, keep only 'dependency'\n",
    "if \"kind\" in df.columns:\n",
    "    df = df[df[\"kind\"].str.lower() == \"dependency\"]\n",
    "\n",
    "# Clean gene names\n",
    "df[\"gene\"] = df[\"gene\"].astype(str).str.strip()\n",
    "df[\"module\"] = df[\"module\"].astype(str).str.strip()\n",
    "\n",
    "# ------------------- FILTER PER MODULE -------------------\n",
    "display_rows = []   # (module, gene)\n",
    "for mod in MODULES:\n",
    "    sub = df[df[\"module\"] == mod].copy()\n",
    "\n",
    "    # Keep only strong correlation in the dependency direction\n",
    "    if KEEP_NEG:\n",
    "        sub = sub[(sub[\"rho\"] <= -ABS_R_MIN) & (sub[\"FDR\"] <= FDR_MAX)]\n",
    "        # sort by most negative first\n",
    "        sub = sub.sort_values(\"rho\")  # more negative on top\n",
    "    else:\n",
    "        sub = sub[(sub[\"rho\"] >= +ABS_R_MIN) & (sub[\"FDR\"] <= FDR_MAX)]\n",
    "        sub = sub.sort_values(\"rho\", ascending=False)\n",
    "\n",
    "    if len(sub) == 0:\n",
    "        # no hits; leave empty block for this module\n",
    "        continue\n",
    "\n",
    "    # top-N for visual balance\n",
    "    sub = sub.head(TOP_N_PER_MODULE)\n",
    "    display_rows.extend(list(zip(sub[\"module\"], sub[\"gene\"])))\n",
    "\n",
    "# If nothing passed, bail gracefully\n",
    "if not display_rows:\n",
    "    raise SystemExit(\"No genes passed the dependency-only filters. Try relaxing FDR_MAX or ABS_R_MIN.\")\n",
    "\n",
    "# Create ordered Gene index grouped by module\n",
    "row_labels = []\n",
    "row_modules = []\n",
    "for mod in MODULES:\n",
    "    genes = [g for (m,g) in display_rows if m == mod]\n",
    "    for g in genes:\n",
    "        row_labels.append(g)\n",
    "        row_modules.append(mod)\n",
    "\n",
    "# Build full matrix (genes x modules) from rho (can include +/- across columns for context)\n",
    "mat = pd.DataFrame(index=row_labels, columns=MODULES, dtype=float)\n",
    "mat[:] = np.nan\n",
    "for _, r in df[df[\"gene\"].isin(row_labels)].iterrows():\n",
    "    if r[\"module\"] in MODULES:\n",
    "        # note: rows are genes; columns are *display* modules; we keep the rho for each module column where available\n",
    "        # If your CSV is one row per (module,gene), this assignment fills the matching column only.\n",
    "        mat.loc[r[\"gene\"], r[\"module\"]] = r[\"rho\"]\n",
    "\n",
    "# Replace remaining NaNs with 0 for display (neutral color)\n",
    "mat = mat.fillna(0.0)\n",
    "\n",
    "# ------------------- PLOT -------------------\n",
    "fig = plt.figure(figsize=(7.0, 10.0), dpi=300)\n",
    "# layout: [left color band | heatmap | colorbar]\n",
    "gs = fig.add_gridspec(nrows=1, ncols=3, width_ratios=[0.18, 0.92, 0.12], wspace=0.28)\n",
    "\n",
    "# Left module color band\n",
    "ax_band = fig.add_subplot(gs[0,0])\n",
    "ax_band.set_xlim(0,1)\n",
    "ax_band.set_ylim(0, len(row_labels))\n",
    "y = 0\n",
    "tick_positions = []\n",
    "tick_labels = []\n",
    "for mod in MODULES:\n",
    "    n = sum(np.array(row_modules) == mod)\n",
    "    if n == 0:\n",
    "        continue\n",
    "    ax_band.add_patch(plt.Rectangle((0, y), 1, n, color=MODULE_COLORS.get(mod, \"#888888\"), lw=0))\n",
    "    tick_positions.append(y + n/2)\n",
    "    tick_labels.append(mod)\n",
    "    y += n\n",
    "\n",
    "ax_band.set_xticks([])\n",
    "ax_band.set_yticks(tick_positions, tick_labels)\n",
    "for spine in ax_band.spines.values():\n",
    "    spine.set_visible(False)\n",
    "ax_band.invert_yaxis()\n",
    "ax_band.set_title(\"\")  # no title on the band\n",
    "\n",
    "# Heatmap\n",
    "ax_hm = fig.add_subplot(gs[0,1])\n",
    "cmap = matplotlib.colormaps.get_cmap(\"coolwarm\")\n",
    "# symmetric around 0\n",
    "norm = TwoSlopeNorm(vmin=-1.0, vcenter=0.0, vmax=1.0)\n",
    "im = ax_hm.imshow(mat.values, aspect=\"auto\", cmap=cmap, norm=norm, interpolation=\"nearest\")\n",
    "\n",
    "ax_hm.set_xticks(np.arange(len(MODULES)))\n",
    "ax_hm.set_xticklabels(MODULES)\n",
    "ax_hm.set_yticks(np.arange(len(row_labels)))\n",
    "ax_hm.set_yticklabels(row_labels)\n",
    "ax_hm.tick_params(axis=\"both\", length=0)\n",
    "\n",
    "# gridlines to separate modules vertically (optional)\n",
    "y0 = 0\n",
    "for mod in MODULES:\n",
    "    n = sum(np.array(row_modules) == mod)\n",
    "    if n == 0:\n",
    "        continue\n",
    "    ax_hm.hlines(y0-0.5, -0.5, len(MODULES)-0.5, colors=\"white\", linewidth=1.2)\n",
    "    y0 += n\n",
    "ax_hm.hlines(y0-0.5, -0.5, len(MODULES)-0.5, colors=\"white\", linewidth=1.2)\n",
    "\n",
    "ax_hm.set_xlabel(\"Module\")\n",
    "ax_hm.set_ylabel(\"Gene\")\n",
    "ax_hm.set_title(\"Strong Dependency Signatures by Module\", pad=10)\n",
    "\n",
    "# Colorbar (with 0.5 tick spacing as you preferred earlier)\n",
    "ax_cb = fig.add_subplot(gs[0,2])\n",
    "cbar = fig.colorbar(im, cax=ax_cb)\n",
    "cbar.set_label(\"Correlation\", rotation=90)\n",
    "cbar.set_ticks([-1.0, -0.5, 0.0, 0.5, 1.0])\n",
    "\n",
    "fig.tight_layout()\n",
    "fig.savefig(OUT_PNG, bbox_inches=\"tight\")\n",
    "print(f\"✅ Wrote {OUT_PNG}\\n  filters: dependency-only (ρ {'≤ -' if KEEP_NEG else '≥ +'}{ABS_R_MIN}), FDR ≤ {FDR_MAX}, top {TOP_N_PER_MODULE}/module\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "f9e98940",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/mh/r2nrb73509z0t_wjbx9r5fg00000gn/T/ipykernel_92012/3785973966.py:56: MatplotlibDeprecationWarning: The get_cmap function was deprecated in Matplotlib 3.7 and will be removed in 3.11. Use ``matplotlib.colormaps[name]`` or ``matplotlib.colormaps.get_cmap()`` or ``pyplot.get_cmap()`` instead.\n",
      "  im = ax.imshow(M, cmap=cm.get_cmap(\"coolwarm\"), vmin=vmin, vmax=vmax,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved: Fig6A_StrongDeps_vertical.png (+ PDF if available)\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "# Figure 6A — Strong Dependency Signatures by Module (no left module labels)\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "\n",
    "# -------------------- CONFIG --------------------\n",
    "CSV_PATH = \"all_dependencies.csv\"   # expects columns: gene,module,rho\n",
    "MODULES  = [\"IGE\", \"SAT\", \"IL2\", \"MPC\"]\n",
    "GENES_BY_MODULE = {\n",
    "    \"IGE\": [\"VPS4B\", \"CENPW\", \"RPA1\", \"SSC5D\"],\n",
    "    \"SAT\": [\"CNPY3\", \"CABLES2\", \"CALU\", \"FAM149B1\"],\n",
    "    \"IL2\": [\"ZNF837\", \"SPAG5\", \"ZNF496\", \"ATG12\"],\n",
    "    \"MPC\": [\"ATP1B3\", \"GEM\", \"IKBKE\", \"ADCY4\"],\n",
    "}\n",
    "TITLE        = \"Strong Dependency Signatures by Module\"\n",
    "CBAR_LABEL   = \"Correlation\"\n",
    "OUT_BASENAME = \"Fig6A_StrongDeps_vertical\"\n",
    "\n",
    "# Typography\n",
    "plt.rcParams.update({\n",
    "    \"font.family\": \"Arial\",\n",
    "    \"axes.titlesize\": 22,\n",
    "    \"axes.labelsize\": 16,\n",
    "    \"xtick.labelsize\": 15,\n",
    "    \"ytick.labelsize\": 15,\n",
    "})\n",
    "\n",
    "# -------------------- LOAD & SHAPE --------------------\n",
    "df = pd.read_csv(CSV_PATH)\n",
    "df.columns = [c.strip().lower() for c in df.columns]\n",
    "if not {\"gene\",\"module\",\"rho\"}.issubset(df.columns):\n",
    "    raise ValueError(\"CSV must contain columns: gene,module,rho\")\n",
    "\n",
    "mat = df.pivot_table(index=\"gene\", columns=\"module\", values=\"rho\", aggfunc=\"mean\")\n",
    "mat = mat.reindex(columns=MODULES)\n",
    "\n",
    "row_labels, row_modules = [], []\n",
    "for m in MODULES:\n",
    "    for g in GENES_BY_MODULE[m]:\n",
    "        if g in mat.index:\n",
    "            row_labels.append(g)\n",
    "            row_modules.append(m)\n",
    "\n",
    "if not row_labels:\n",
    "    raise ValueError(\"No requested genes were found in all_dependencies.csv\")\n",
    "\n",
    "M = mat.loc[row_labels].to_numpy()\n",
    "\n",
    "# -------------------- PLOT --------------------\n",
    "fig, ax = plt.subplots(figsize=(7.0, 8.6))\n",
    "\n",
    "vmin, vmax = -1.0, 1.0\n",
    "im = ax.imshow(M, cmap=cm.get_cmap(\"coolwarm\"), vmin=vmin, vmax=vmax,\n",
    "               aspect=\"auto\", interpolation=\"nearest\")\n",
    "\n",
    "# ticks\n",
    "ax.set_xticks(np.arange(len(MODULES)))\n",
    "ax.set_xticklabels(MODULES)\n",
    "ax.set_yticks(np.arange(len(row_labels)))\n",
    "ax.set_yticklabels(row_labels)\n",
    "\n",
    "ax.set_title(TITLE, pad=12)\n",
    "\n",
    "# cell grid\n",
    "ax.set_xticks(np.arange(-.5, len(MODULES), 1), minor=True)\n",
    "ax.set_yticks(np.arange(-.5, len(row_labels), 1), minor=True)\n",
    "ax.grid(which=\"minor\", color=\"white\", linewidth=0.8)\n",
    "ax.tick_params(axis='x', bottom=False)\n",
    "\n",
    "# horizontal separators between module blocks\n",
    "start = 0\n",
    "for m in MODULES[:-1]:\n",
    "    start += len(GENES_BY_MODULE[m])\n",
    "    ax.axhline(start - 0.5, color=\"white\", lw=2.4)\n",
    "\n",
    "# ---- removed: vertical module labels on the left ----\n",
    "\n",
    "# layout (tighten left now that labels are gone)\n",
    "plt.subplots_adjust(left=0.12, right=0.84, top=0.92, bottom=0.08)\n",
    "\n",
    "# colorbar (0.5 increments)\n",
    "cax = fig.add_axes([0.86, 0.17, 0.03, 0.67])\n",
    "cbar = fig.colorbar(im, cax=cax, ticks=np.arange(-1.0, 1.01, 0.5))\n",
    "cbar.set_label(CBAR_LABEL, rotation=270, labelpad=16)\n",
    "cbar.ax.tick_params(labelsize=12)\n",
    "\n",
    "# save\n",
    "for ext in (\"png\", \"pdf\"):\n",
    "    try:\n",
    "        fig.savefig(f\"{OUT_BASENAME}.{ext}\", dpi=350, bbox_inches=\"tight\")\n",
    "    except Exception as e:\n",
    "        if ext == \"pdf\":\n",
    "            print(f\"⚠️ PDF save failed; PNG written. Reason: {e}\")\n",
    "plt.close(fig)\n",
    "\n",
    "print(f\"✅ Saved: {OUT_BASENAME}.png (+ PDF if available)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "8a50a437",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'matplotlib.cm' has no attribute 'register_cmap'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[76], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mseaborn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01msns\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtextwrap\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# ---------- CONFIG ----------\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/seaborn/__init__.py:9\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcategorical\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m  \u001b[38;5;66;03m# noqa: F401,F403\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistributions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m  \u001b[38;5;66;03m# noqa: F401,F403\u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmatrix\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m  \u001b[38;5;66;03m# noqa: F401,F403\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmiscplot\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m  \u001b[38;5;66;03m# noqa: F401,F403\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01maxisgrid\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m  \u001b[38;5;66;03m# noqa: F401,F403\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/seaborn/matrix.py:12\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcluster\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m hierarchy\n\u001b[0;32m---> 12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m cm\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01maxisgrid\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Grid\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     15\u001b[0m     despine,\n\u001b[1;32m     16\u001b[0m     axis_ticklabels_overlap,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     19\u001b[0m     _draw_figure,\n\u001b[1;32m     20\u001b[0m )\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/seaborn/cm.py:1582\u001b[0m\n\u001b[1;32m   1579\u001b[0m     _cmap_r \u001b[38;5;241m=\u001b[39m colors\u001b[38;5;241m.\u001b[39mListedColormap(_lut[::\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m], _name \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_r\u001b[39m\u001b[38;5;124m\"\u001b[39m)  \n\u001b[1;32m   1580\u001b[0m     \u001b[38;5;28mlocals\u001b[39m()[_name \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_r\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m _cmap_r\n\u001b[0;32m-> 1582\u001b[0m     \u001b[43mmpl_cm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mregister_cmap\u001b[49m(_name, _cmap)\n\u001b[1;32m   1583\u001b[0m     mpl_cm\u001b[38;5;241m.\u001b[39mregister_cmap(_name \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_r\u001b[39m\u001b[38;5;124m\"\u001b[39m, _cmap_r)\n\u001b[1;32m   1585\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m colors, mpl_cm\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'matplotlib.cm' has no attribute 'register_cmap'"
     ]
    }
   ],
   "source": [
    "# --- Figure 6C bubble-strip with clear MODULE encoding ---\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import textwrap\n",
    "\n",
    "# ---------- CONFIG ----------\n",
    "CSV_PATH   = \"module_vs_PRISM_top15.csv\"\n",
    "LABEL_MODE = \"truncate\"   # \"truncate\" or \"wrap\"\n",
    "WRAP_WIDTH = 18\n",
    "TRUNC_W    = 22\n",
    "Y_FONTSZ   = 7\n",
    "X_FONTSZ   = 10\n",
    "FIGSIZE    = (9.5, 8.2)\n",
    "OUT_PNG    = \"Figure6C_bubble_strip_byMODULE.png\"\n",
    "OUT_PDF    = \"Figure6C_bubble_strip_byMODULE.pdf\"\n",
    "\n",
    "module_order  = ['IGE','SAT','IL2','MPC']\n",
    "module_colors = {'IGE':'#3B6BA5', 'SAT':'#E49C3C', 'IL2':'#CA4949', 'MPC':'#60AD7D'}\n",
    "# light ribbons behind each module (same hues, high alpha)\n",
    "ribbon_alpha  = 0.08\n",
    "# --------------------------------\n",
    "\n",
    "def shorten(s, width=22):\n",
    "    return s if len(s) <= width else s[:width-1] + \"…\"\n",
    "\n",
    "def wrap(s, width=18):\n",
    "    return \"\\n\".join(textwrap.wrap(s, width=width)) if len(s) > width else s\n",
    "\n",
    "# Load + prep\n",
    "df = pd.read_csv(CSV_PATH)\n",
    "df['logp'] = -np.log10(df['pval'].clip(lower=1e-300))\n",
    "df['module'] = pd.Categorical(df['module'], module_order, ordered=True)\n",
    "\n",
    "# label compactness\n",
    "if LABEL_MODE == \"wrap\":\n",
    "    df['drug_label'] = df['drug'].apply(lambda s: wrap(s, WRAP_WIDTH))\n",
    "else:\n",
    "    df['drug_label'] = df['drug'].apply(lambda s: shorten(s, TRUNC_W))\n",
    "\n",
    "# Sensitivity/resistance marker\n",
    "df['effect'] = np.where(df['rho'] < 0, 'sensitive (ρ<0)', 'resistant (ρ≥0)')\n",
    "\n",
    "# sort so modules appear as contiguous blocks\n",
    "df = df.sort_values(['module','rho'], ascending=[True, True])\n",
    "\n",
    "plt.figure(figsize=FIGSIZE)\n",
    "ax = sns.scatterplot(\n",
    "    data=df, x='rho', y='drug_label',\n",
    "    hue='module', palette=module_colors,\n",
    "    style='effect', style_order=['sensitive (ρ<0)','resistant (ρ≥0)'],\n",
    "    sizes=(20, 220), size='logp',\n",
    "    edgecolor='k', linewidth=0.3\n",
    ")\n",
    "\n",
    "# neutral zone + axis styling\n",
    "ax.axvline(0, color='gray', lw=0.8)\n",
    "ax.axvspan(-0.1, 0.1, color='lightgray', alpha=0.18, zorder=-1)\n",
    "ax.set_xlim(-1.1, 1.1)\n",
    "ax.set_xlabel('Spearman ρ (drug–module correlation, negative = ↑ sensitivity)', fontsize=X_FONTSZ)\n",
    "ax.set_ylabel('', fontsize=Y_FONTSZ)\n",
    "ax.set_title('Module-specific PRISM drug–response correlations', fontsize=14, pad=10)\n",
    "\n",
    "# Smaller y labels\n",
    "ax.tick_params(axis='y', labelsize=Y_FONTSZ, pad=1)\n",
    "ax.tick_params(axis='x', labelsize=X_FONTSZ)\n",
    "\n",
    "# OPTIONAL: faint ribbons behind each module block\n",
    "# Need the y positions used by Matplotlib for each categorical label\n",
    "y_labels = [t.get_text() for t in ax.get_yticklabels()]\n",
    "ypos = {lab: i for i, lab in enumerate(y_labels)}  # 0 at bottom\n",
    "\n",
    "# Determine continuous ranges for each module\n",
    "for m in module_order:\n",
    "    labs = df.loc[df['module']==m, 'drug_label'].tolist()\n",
    "    if not labs:\n",
    "        continue\n",
    "    ys = sorted([ypos[l] for l in labs])\n",
    "    y0, y1 = ys[0]-0.5, ys[-1]+0.5\n",
    "    ax.axhspan(y0, y1, color=module_colors[m], alpha=ribbon_alpha, zorder=-2)\n",
    "    # module tag on right margin at band mid\n",
    "    ym = (y0 + y1)/2\n",
    "    ax.text(1.06, (ym - (-0.5))/(len(y_labels)), m, color=module_colors[m],\n",
    "            fontsize=10, fontweight='bold', rotation=0,\n",
    "            transform=ax.get_yaxis_transform())\n",
    "\n",
    "# Layout: room for labels + legend outside\n",
    "plt.subplots_adjust(left=0.36, right=0.77, top=0.92, bottom=0.08)\n",
    "leg = ax.legend(bbox_to_anchor=(1.02, 1.0), loc='upper left', frameon=True, borderpad=0.6, title=None)\n",
    "\n",
    "# Save (non-interactive safe)\n",
    "plt.savefig(OUT_PNG, dpi=300, bbox_inches='tight')\n",
    "plt.savefig(OUT_PDF, dpi=300, bbox_inches='tight')\n",
    "print(f\"Saved: {OUT_PNG} and {OUT_PDF}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "31fc00a6",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'drug'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pandas/core/indexes/base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3811\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3812\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32mpandas/_libs/index.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/index.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7088\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7096\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'drug'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[77], line 8\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i,a \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(modules):\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m b \u001b[38;5;129;01min\u001b[39;00m modules[i\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m:]:\n\u001b[0;32m----> 8\u001b[0m         shared \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m(\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmodule\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43ma\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdrug\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m) \u001b[38;5;241m&\u001b[39m \u001b[38;5;28mset\u001b[39m(df[df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodule\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m==\u001b[39mb][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdrug\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m      9\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m shared:\n\u001b[1;32m     10\u001b[0m             G\u001b[38;5;241m.\u001b[39madd_edge(a,b,weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(shared))\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pandas/core/frame.py:4113\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   4112\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 4113\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4114\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   4115\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pandas/core/indexes/base.py:3819\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3814\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[1;32m   3815\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[1;32m   3816\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[1;32m   3817\u001b[0m     ):\n\u001b[1;32m   3818\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[0;32m-> 3819\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3820\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3821\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3822\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3823\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3824\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'drug'"
     ]
    }
   ],
   "source": [
    "import networkx as nx\n",
    "G = nx.Graph()\n",
    "modules = ['IGE','SAT','IL2','MPC']\n",
    "for m in modules:\n",
    "    G.add_node(m)\n",
    "for i,a in enumerate(modules):\n",
    "    for b in modules[i+1:]:\n",
    "        shared = set(df[df['module']==a]['drug']) & set(df[df['module']==b]['drug'])\n",
    "        if shared:\n",
    "            G.add_edge(a,b,weight=len(shared))\n",
    "pos = nx.circular_layout(G)\n",
    "w = [d['weight'] for (_,_,d) in G.edges(data=True)]\n",
    "nx.draw(G,pos,width=[0.3*x for x in w],with_labels=True,node_color='white',edge_color='gray',node_size=1500)\n",
    "plt.title('Shared drug associations between modules')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "7e763857",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "':' expected after dictionary key (256565829.py, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[78], line 3\u001b[0;36m\u001b[0m\n\u001b[0;31m    moa_map = {'talazoparib':'PARP','alpelisib':'PI3K','HSP90 inhibitor':'HSP90', ...}\u001b[0m\n\u001b[0m                                                                                    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m ':' expected after dictionary key\n"
     ]
    }
   ],
   "source": [
    "import plotly.graph_objects as go\n",
    "modules = df['module'].unique()\n",
    "moa_map = {'talazoparib':'PARP','alpelisib':'PI3K','HSP90 inhibitor':'HSP90', ...}\n",
    "df['MOA'] = df['drug'].map(moa_map)\n",
    "links = df.groupby(['module','MOA']).size().reset_index(name='count')\n",
    "labels = list(modules) + list(links['MOA'].dropna().unique())\n",
    "src = [labels.index(x) for x in links['module']]\n",
    "tgt = [labels.index(x) for x in links['MOA']]\n",
    "val = links['count']\n",
    "go.Figure(go.Sankey(node=dict(label=labels),\n",
    "                    link=dict(source=src,target=tgt,value=val))\n",
    "          ).update_layout(title='Module-to-MOA drug-response mapping').show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51d654ec",
   "metadata": {},
   "source": [
    "## 5) Clinical cohorts — scoring, subtype comparison, survival"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "1919dda1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[COMPASS] paths missing; skipping.\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'module_scores_ssgsea' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[79], line 100\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[38;5;66;03m# Run cohorts\u001b[39;00m\n\u001b[1;32m     99\u001b[0m _ \u001b[38;5;241m=\u001b[39m score_cohort(COMPASS_EXPR, COMPASS_META, tag\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCOMPASS\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 100\u001b[0m _ \u001b[38;5;241m=\u001b[39m \u001b[43mscore_cohort\u001b[49m\u001b[43m(\u001b[49m\u001b[43mPULEO_EXPR\u001b[49m\u001b[43m,\u001b[49m\u001b[43m   \u001b[49m\u001b[43mPULEO_META\u001b[49m\u001b[43m,\u001b[49m\u001b[43m   \u001b[49m\u001b[43mtag\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mPULEO\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    101\u001b[0m _ \u001b[38;5;241m=\u001b[39m score_cohort(TCGA_EXPR,    TCGA_META,    tag\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTCGA\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    103\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mClinical analyses complete. Artifacts in:\u001b[39m\u001b[38;5;124m\"\u001b[39m, OUTDIR)\n",
      "Cell \u001b[0;32mIn[79], line 28\u001b[0m, in \u001b[0;36mscore_cohort\u001b[0;34m(expr_path, meta_path, tag)\u001b[0m\n\u001b[1;32m     25\u001b[0m EXP \u001b[38;5;241m=\u001b[39m EXP\u001b[38;5;241m.\u001b[39mloc[:, common]\n\u001b[1;32m     26\u001b[0m META \u001b[38;5;241m=\u001b[39m META\u001b[38;5;241m.\u001b[39mloc[common]\n\u001b[0;32m---> 28\u001b[0m scores \u001b[38;5;241m=\u001b[39m \u001b[43mmodule_scores_ssgsea\u001b[49m(EXP, MODULES)\n\u001b[1;32m     29\u001b[0m scores \u001b[38;5;241m=\u001b[39m scores\u001b[38;5;241m.\u001b[39mapply(pd\u001b[38;5;241m.\u001b[39mto_numeric, errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcoerce\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     30\u001b[0m scores\u001b[38;5;241m.\u001b[39mT\u001b[38;5;241m.\u001b[39mto_csv(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(OUTDIR, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtag\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_module_scores.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'module_scores_ssgsea' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "from typing import Tuple\n",
    "try:\n",
    "    from lifelines import KaplanMeierFitter\n",
    "    from lifelines.statistics import logrank_test\n",
    "    lifelines_ok = True\n",
    "except Exception:\n",
    "    lifelines_ok = False\n",
    "\n",
    "def infer_cols(meta: pd.DataFrame) -> Tuple[str,str,str]:\n",
    "    time = event = subtype = None\n",
    "    for c in meta.columns:\n",
    "        lc = c.lower()\n",
    "        if lc in (\"os_time\",\"os\",\"time\",\"days_to_death\",\"overall_survival\") and time is None: time = c\n",
    "        if lc in (\"os_event\",\"event\",\"status\",\"vital_status\",\"death_event\") and event is None: event = c\n",
    "        if any(k in lc for k in [\"subtype\",\"basal\",\"classical\",\"purist\",\"moffitt\",\"collisson\"]) and subtype is None: subtype = c\n",
    "    return time, event, subtype\n",
    "\n",
    "def score_cohort(expr_path, meta_path, tag):\n",
    "    if not (os.path.exists(expr_path) and os.path.exists(meta_path)):\n",
    "        print(f\"[{tag}] paths missing; skipping.\")\n",
    "        return None, None\n",
    "    EXP = pd.read_csv(expr_path, index_col=0)\n",
    "    META = pd.read_csv(meta_path, index_col=0)\n",
    "    common = EXP.columns.intersection(META.index)\n",
    "    EXP = EXP.loc[:, common]\n",
    "    META = META.loc[common]\n",
    "\n",
    "    scores = module_scores_ssgsea(EXP, MODULES)\n",
    "    scores = scores.apply(pd.to_numeric, errors='coerce')\n",
    "    scores.T.to_csv(os.path.join(OUTDIR, f\"{tag}_module_scores.csv\"))\n",
    "\n",
    "    # Subtype boxplots (matplotlib-only)\n",
    "    time_col, event_col, subtype_col = infer_cols(META)\n",
    "    if subtype_col:\n",
    "        S = scores.T.copy()\n",
    "        S[\"subtype\"] = META[subtype_col]\n",
    "        S = S.dropna(subset=[\"subtype\"])\n",
    "        if len(S):\n",
    "            plt.figure(figsize=(8,4))\n",
    "            modules = scores.index.tolist()\n",
    "            subtypes = S[\"subtype\"].astype(str).unique().tolist()\n",
    "            positions = []\n",
    "            data = []\n",
    "            pos = 1\n",
    "            for m in modules:\n",
    "                for st in subtypes:\n",
    "                    vals = S.loc[S[\"subtype\"]==st, m].dropna().values\n",
    "                    if len(vals):\n",
    "                        data.append(vals)\n",
    "                        positions.append(pos)\n",
    "                    pos += 1\n",
    "                pos += 0.5  # gap between modules\n",
    "            plt.boxplot(data, positions=positions, widths=0.6, showfliers=False)\n",
    "            # x ticks\n",
    "            xticks = []\n",
    "            xtlbls = []\n",
    "            pos = 1\n",
    "            for m in modules:\n",
    "                xticks.append(pos + (len(subtypes)-1)/2)\n",
    "                xtlbls.append(m)\n",
    "                pos += len(subtypes) + 1.5\n",
    "            plt.xticks(xticks, xtlbls, rotation=45, ha='right')\n",
    "            plt.title(f\"{tag}: Module scores by subtype\")\n",
    "            plt.tight_layout()\n",
    "            plt.savefig(os.path.join(OUTDIR, f\"{tag}_subtypes.png\"), dpi=200)\n",
    "            plt.show()\n",
    "\n",
    "    # Survival (KM median split) if available and lifelines present\n",
    "    if lifelines_ok and time_col and event_col:\n",
    "        DF = META[[time_col, event_col]].join(scores.T).dropna()\n",
    "        for mod in scores.index:\n",
    "            try:\n",
    "                m = DF[mod].median()\n",
    "                grp = (DF[mod] >= m).map({True:\"High\", False:\"Low\"})\n",
    "                if grp.value_counts().min() < 5:\n",
    "                    continue\n",
    "                km = KaplanMeierFitter()\n",
    "                plt.figure(figsize=(4,3))\n",
    "                for g in [\"Low\",\"High\"]:\n",
    "                    mask = (grp == g)\n",
    "                    km.fit(DF.loc[mask, time_col], DF.loc[mask, event_col], label=g)\n",
    "                    km.plot(ci_show=False)\n",
    "                try:\n",
    "                    lr = logrank_test(DF.loc[grp==\"High\", time_col], DF.loc[grp==\"Low\", time_col], DF.loc[grp==\"High\", event_col], DF.loc[grp==\"Low\", event_col])\n",
    "                    pval = lr.p_value\n",
    "                except Exception:\n",
    "                    pval = float('nan')\n",
    "                plt.title(f\"{tag} — {mod} (median split) p={pval:.3g}\")\n",
    "                plt.xlabel(\"Time\"); plt.ylabel(\"Survival probability\")\n",
    "                plt.tight_layout()\n",
    "                plt.savefig(os.path.join(OUTDIR, f\"{tag}_KM_{mod}.png\"), dpi=200)\n",
    "                plt.show()\n",
    "            except Exception as e:\n",
    "                print(f\"KM failed for {mod}: {e}\")\n",
    "\n",
    "    return scores, META\n",
    "\n",
    "# Run cohorts\n",
    "_ = score_cohort(COMPASS_EXPR, COMPASS_META, tag=\"COMPASS\")\n",
    "_ = score_cohort(PULEO_EXPR,   PULEO_META,   tag=\"PULEO\")\n",
    "_ = score_cohort(TCGA_EXPR,    TCGA_META,    tag=\"TCGA\")\n",
    "\n",
    "print(\"Clinical analyses complete. Artifacts in:\", OUTDIR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12c620c4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0672e16",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "850e74fa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
